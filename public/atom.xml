<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://v2.yashagarwal.in</id>
    <title>Yash Agarwal</title>
    <updated>2023-07-09T11:40:54.403Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <author>
        <name>Yash Agarwal</name>
        <email>yashagarwaljpr+blog@gmail.com</email>
        <uri>https://v2.yashagarwal.in</uri>
    </author>
    <link rel="alternate" href="https://v2.yashagarwal.in"/>
    <link rel="self" href="https://v2.yashagarwal.in/atom.xml"/>
    <subtitle>Developer, writer, and creator</subtitle>
    <rights>Copyright © 2016 - 2023 Yash Agarwal</rights>
    <entry>
        <title type="html"><![CDATA[2022 - The Year of Plentiful]]></title>
        <id>https://v2.yashagarwal.in/blog/2022-the-year-of-plentiful</id>
        <link href="https://v2.yashagarwal.in/blog/2022-the-year-of-plentiful"/>
        <updated>2022-12-31T13:25:03.000Z</updated>
        <content type="html"><![CDATA[
2022 is about to end. It is that time when I say goodbye to one more year in my
life and welcome a new one. 2022 was a hectic year for me. Many of my decisions
this year will have rippling effects for years to come. But there was also a
good realization that I must take action; sitting idle won't help.

As always, I have divided this review into those areas of my life where I have
been putting more focus throughout the year.

# Health

## Fitness

I wish I had put more focus on my fitness this year. My sedentary lifestyle may
put me at many health risks in years to come. My activity levels have been
abysmally poor for most of the year. A big reason behind this was my busyness in
other parts of my life. 2022 was an amalgamation of stress, fear, anxiety,
surprises, gratitude, and happiness. Fitness took a back seat due to the quick
turnaround of events throughout the year. Early in the year, I continued with
Yoga. However, I was a lot more irregular this year because I wanted to gain
muscles while keeping my weight constant. So, I decided to join a gym in the
second half of the year to focus on muscle building. However, due to the stress
of wedding preparations, I couldn't find the motivation to continue beyond two
months. There was one positive, though - whenever I committed to working out, I
could notice a boost of confidence spurting inside me. Unfortunately, I found it
challenging to maintain this motivation for long.

I didn't have to suffer from any significant illness this year. I occasionally
suffered from slight back pain, which can be attributed to my poor posture.
Doing Yoga keeps my back in shape, but whenever I stop doing Yoga, I start
feeling the pinch again in one or two months. This factor alone makes me realize
the importance of keeping my body active.

## Sleep

I managed to sleep around seven hours each day throughout the year. However,
this data doesn't include my afternoon naps, so my daily sleep duration is
undoubtedly higher than 7 hours. Sleeping in the afternoons has become a habit
that I never intended to develop. But now, it has become a permanent fixture in
my life. In 2023, I plan to keep my tendency to sleep in the afternoon in
control, but that will require sleeping enough at night, without which all my
efforts will remain useless.

![Sleeping in 2022](/images/posts/2022_average_sleep_duration.png "How much I slept in 2022?")

I slept the least in June, which is surprising. I was expecting it to be in
July, August, and September when I was in the midst of my courtship period.

I would have liked to put a graph showing my sleep and wake-up times as well,
but my graph plotting skills require some polishing, so for now, I will stop
here. Someday, I would like to analyze that data as well.

# Career

## Netskope

Joining Netskope was a good decision for my career. While I learned a lot at
Cisco, my experience at Netskope has been different. This year, after seeing the
turbulent market conditions, I kept on wondering if joining Netskope was a
financially prudent decision. If I keep this fact aside, my experience at
Netskope has been good.

## Learning

I have not been able to keep up with emerging technologies in the last two-three
years. While my basics are solid, I should invest some time in learning new
trends to stay relevant and employable in the future. The tech industry can be
fierce at times. With all the turmoil in the world, it becomes even more
important to keep myself updated. For the last four years, I have been lacking
in learning new things (irrespective of their connection to my work). That may
have put me behind my peers by a few years. Whenever I see my peers racing ahead
of me, I feel disappointed. I know that becoming part of this rat race will only
give me grief, but as a human, I am not immune to these emotions. However, I am
very well aware that taking action is the only way to come back on track.

## Future

For the first time in the last three years, I feel clarity in my thoughts about
my future direction, which may be a good sign. Going into 2023, this clarity can
prove miraculous for my career and personal life. I hope it is the case.

# Writing

## The Problem

Writing regularly was one of my primary goals this year. For the last couple of
years, I have been struggling with some mental block when it comes to writing.
It turns out that the problem was the lack of content. I either did not have
anything to write about, or needed to try harder to gather the material, or
procrastinated. I wrote less this year too, but I could get into the flow
whenever I wanted to.

## Journaling

Blogging was not a priority this year. However, journaling has proven to be a
wonderful experience for me this year. More so, it gave me a window into my
thought process when making the most critical decision of my life - whether to
marry or not. I wrote extensively around that time about what I was thinking,
what I liked in her, and what I didn't. When I reread those entries, it
immediately brings a smile to my face. Such has been the impact of journaling on
me. I plan to write many more journal entries next year. I hope these new
entries will also bring a smile to my face in the distant future.

## Hobby

I have a long-term wish to start a newsletter and grow my audience, but I wonder
if I am ready to put in the effort required for this task at this moment. Also,
I need to be more confident about whether I have good content/topic to write
about. Since I still hesitate to share my blog posts on social media, starting
and growing a newsletter will be an uphill task.

Getting committed this year meant that I finally had some inspiration to engage
with creative writing. And I thoroughly enjoyed writing for someone else. In the
last seven years since I started writing, I have never tried to write in Hindi.
But after doing it this year, I realized that I enjoy writing in Hindi. I plan
to continue this (even if sporadically) in 2023.

# Reading

## The failure

I have a feeling of disappointment while writing this section. I decided to read
24 books this year. I am ending it without reading a single book. Throughout the
year, I could not make up my mind about reading. A significant reason behind
this was the double thoughts in my mind about the objective for which I was
reading and whether I could retain whatever I was reading. I found myself
struggling to come to terms with the fact that no matter what I do, I will never
be able to recall everything I read. This realization was the root cause behind
my disillusion with reading. Unfortunately, I still need to find a definite
answer to this dilemma. However, I can still restart my reading journey with
fiction books, as I don't see the need to remember such books.

## But...

Having said this, it is not that I didn't read anything at all. I managed to
read the first three modules of Zerodha's varsity content. These modules are
such a valuable source to learn about the markets. I thoroughly enjoyed reading
them. Unfortunately, at least this year, I didn't use the knowledge gathered. To
start with the stock market again, I may have to reread the modules to recall
the concepts (this is one example of the issues I mentioned in the previous
paragraph).

# Media Consumption

## Bingeing

One side effect of not reading enough books was that my mind tried to find other
avenues to pass the time. In the first half of the year, I took refuge in movies
and TV series to relieve myself from day-to-day life. I watched 22 films and
three web series in the year's first half. Before getting married, I watched
only two movies between July and November. After getting married, in December, I
watched five movies.

| **Name**                                                       | **Type** | **Month** | **Rating** |
| -------------------------------------------------------------- | -------- | --------- | ---------- |
| Loki                                                           | Show     | January   | 7          |
| Eternals                                                       | Movie    | January   | 6          |
| Pushpa: The Rise - Part 1                                      | Movie    | January   | 7          |
| What If…                                                       | Show     | January   | 8          |
| Kingsman: The Golden Circle                                    | Movie    | February  | 8          |
| The King's Man                                                 | Movie    | February  | 6          |
| Mortal Kombat                                                  | Movie    | February  | 4          |
| Rudra                                                          | Show     | March     | 7          |
| Spider-Man: No Way Home                                        | Movie    | March     | 8          |
| Bell Bottom                                                    | Movie    | March     | 5          |
| Wanted                                                         | Movie    | March     | 4          |
| Housefull 4                                                    | Movie    | March     | 2          |
| Dasvi                                                          | Movie    | April     | 7          |
| National Treasure                                              | Movie    | April     | 7          |
| Badhaai Do                                                     | Movie    | April     | 6          |
| National Treasure: Book of Secrets                             | Movie    | April     | 6          |
| The Batman                                                     | Movie    | April     | 9          |
| Pirates of the Caribbean: The Curse of the Black Pearl         | Movie    | May       | 8          |
| Pirates of the Caribbean: Dead Man's Chest                     | Movie    | May       | 7          |
| The Lost City                                                  | Movie    | May       | 3          |
| The Chronicles of Narnia: The Lion, the Witch and the Wardrobe | Movie    | May       | 8          |
| The Chronicles of Narnia: Prince Caspian                       | Movie    | May       | 8          |
| The Chronicles of Narnia: The Voyage of the Dawn Treader       | Movie    | May       | 9          |
| K.G.F: Chapter 2                                               | Movie    | May       | 7          |
| Doctor Strange in the Multiverse of Madness                    | Movie    | June      | 8          |
| Brahmāstra Part One: Shiva                                     | Movie    | September | 7          |
| Thor: Love and Thunder                                         | Movie    | October   | 7          |
| Doctor G                                                       | Movie    | December  | 7          |
| Cirkus                                                         | Movie    | December  | 5          |
| Govinda Naam Mera                                              | Movie    | December  | 6          |
| Encanto                                                        | Movie    | December  | 7          |
| The Dictator                                                   | Movie    | December  | 6          |

## Social Media

I was in control of my social media usage in the first half of the year, but
Instagram caught me off guard after that. I have never been a fan of Instagram,
but this year, circumstances forced me to get into the rabbit hole. Currently, I
have managed to control my Instagram usage. Still, I need to keep my eyes open
to avoid any addiction.

## Phone

I don't have my phone usage data, but I am sure it has skyrocketed this year.
Since July, I have managed to use my phone for more than 6 hours every day on a
routine basis. I must figure out how to reduce this usage and focus on more
important things.

# Family

## Back to Office

Since the beginning of the pandemic, I have been staying with my family. It has
been three years, and with each passing day, I feel uncomfortable even thinking
about moving back to Bengaluru. With the feeling of belongingness combined with
the mess that Bengaluru is in, I find myself resisting moving back to Bengaluru,
at least in the near future. My employer supports remote work, which gives me
hope that I can spend a few more months here in Jaipur. Staying in Jaipur has
obvious monetary benefits, but I see long-term hindrances in career growth. I
may have to find a middle path to avoid stagnating in my career and satisfy my
emotional cravings towards my family.

## Fam

On the family front, this year has been incredible. Several long-term wishes of
my family got fulfilled this year. My mother came back home after a successful
recovery from a severe ailment. We shifted to a new house. I got married. My
brother got a government job. What else could I have asked for?

## Vishi

As the latest entrant into my family, she has been a welcome addition. When 2022
started, the idea of getting married was completely absent from my mind. There
were other _more_ _important_ stuff in my life that required immediate
attention. But life had its plans. And I am glad that life had its way. Though I
was not rooting to get married, I found a person with whom my thoughts match. I
have not been a people-friendly person in my personal life, so it will take some
time to adjust to another person's presence. Still, the way we have spent the
last five months together, this will be a fun journey together.

# What in 2023?

My experience says I could improve following up with my new year's resolutions.
However, that is not going to stop me from resoluting some more goals this year
as well. Even if I don't achieve any of these, they will linger around in the
back of my mind and remind me to take at least one step toward them.

## Fitness

I don't know of any method to quantify my fitness progress, but I aim to keep my
weight under 65 kgs while transferring some of my weight from fat to muscles.

## Reading

I have decided to read **at least** 24 books (2 books per month) this year. A
combination of fiction, non-fiction, Hindi, and technical books would be ideal
and help me avoid the sudden lack of interest. You can track my progress
[here](https://www.goodreads.com/user/show/63354397-yash).

## Writing

Some journal entries, [FutureMe](https://www.futureme.org) letters, and a few
blog posts should be enough for this year. I am writing more than ever
privately, but as a side effect, public writing has taken a back seat for now. I
will write on this blog whenever I have something important to share.

I enjoyed journaling in 2022, so this is also high on my priority list for 2023.
I intend to write only sometimes, but doing it once in a while - on important
events of my life - should be doable.

## Travel

Now that I have a partner-in-crime, I plan to travel extensively (while keeping
financial and professional commitments in mind). The resurge of COVID is
threatening to spoil one of my trips early next year, so I also need to keep an
eye on that. However, I will travel as and when possible. Expect some travelogue
posts on this blog in the near future.

---

2022 was a good year for me. I achieved many goals this year. After a long time,
I have some clarity in my mind about my future course of action. I hope to
execute some (or all) of my plans in 2023.

This year taught me a vital lesson - every time you plan something, there will
be a lot of apprehensions. All it takes to proceed further is to take one step.
Everything else automatically falls into place.

Thank you, 2022, for this critical lesson. Adios, I will never forget you for
bringing so many new memories into my life.

And welcome to you, 2023!!!
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[I Got Engaged 💍]]></title>
        <id>https://v2.yashagarwal.in/blog/i-got-engaged</id>
        <link href="https://v2.yashagarwal.in/blog/i-got-engaged"/>
        <updated>2022-08-06T12:05:24.000Z</updated>
        <content type="html"><![CDATA[
Life sometimes takes such unexpected turns that we humans can only stand still
and wonder. That's what happened to me. Just two months back, I was urging my
father to stop talking to me about my marriage plans, and here I am today,
announcing my engagement. It is how the sequence of events has been in my life
in the last two months. However, I am not at all troubled with all these sudden
turns and twists.

Coming to the topic of the discussion, the name of my fiancée is Vishakha. Our
roka-cum-engagement ceremony took place on 30th of July. We exchanged rings
before a small family gathering and had our first pooja together. Now, we are
officially in our courtship period. We both belong to slightly different
educational backgrounds and academic interests. However, that doesn't seem to be
a barrier between us, and we share many views about life, family, society, and
other things in general.

I have been timid in talking to strangers, but right from our first meeting, I
struck a strange connection with her. Our first meeting lasted for around one
and a half hours, which astonished our families, given that she and I don't talk
much, even among family members. Since then, we have spoken for uncountable
hours, discussing our priorities, ambitions, goals, thoughts about life, likes,
dislikes, etc.

It may be initial excitement or infatuation, but I can feel the emotions of care
and love blossoming in me. These are some unfamiliar emotions for me. I have
never attached to any human being other than my parents. Now having the same
feelings for a stranger is difficult to digest. I don't know if love can blossom
so quickly. But if it does, then I am definitely in love. And if it doesn't, it
will happen soon.

When I broke the news on Instagram, many people asked me one question - Why so
early? While there were no particular reasons behind my decision, in retrospect,
I think this was an excellent decision to take at this juncture of my life.

1. I am currently stagnating in my life and career. I am going through that
   phase where I don't see any yield of my work on both personal and
   professional fronts. Although I am confident that I will reap the results of
   this work in the future, the present appears to be the best time to welcome
   another person into my life. I hope her entry into my life and the resultant
   influence will help me come out of this slump phase. I must mention that this
   is a double-edged sword, and I am taking a huge risk here. But that is
   something only time will tell.
2. My parents would have started forcing me to get married in the next year or
   two. I preferred not to juggle between Bengaluru (or elsewhere) and Jaipur,
   hoping to find a match. I have seen my cousins struggling with that.
3. I had planned to go for a corporate-sponsored graduate program. But then I
   left Cisco, and since Netskope doesn't have any such program; I had to put
   this plan on hold for a couple of years. So, I am relatively free at this
   point in my life. I believe there couldn't have been a better time to hook up
   than this.
4. After the pandemic began, I came back to my hometown. Since then, my life has
   become highly monotonous, and I was looking for some respite from it. I was
   feeling the need for another person in my life who could push me out of my
   comfort zone while also respecting my boundaries.
5. Perhaps I was also looking for lady luck.

![Vishi and Yash](/images/posts/vishi_and_yash.jpg "Vishi and Yash")

Marrying means leaving your bachelorhood behind, and that has its downsides.

1. Time spent on your family means you can't spend time on your career and other
   outside-of-work activities. But I think, at some point, I had to find a
   balance anyway.
2. The responsibility to maintain a family is not an easy one. It comes with its
   challenges. Bachelorhood is relatively easy; you are on your own. But in
   married life, someone else is looking up to you for constant support,
   dedication, and love. I wonder how long it will take me to adjust to this.
3. Your goals and ambitions are not only yours anymore. They get shared with
   your spouse. And if the spouse is not supportive, life can take a downturn
   quickly.
4. You can't just think about yourself selfishly. You need to consider the
   effect of every decision of yours on your spouse as well. It can get clumsy
   sometimes.

As usual, I have spoiled this post by talking about ups and downs 🤣. My habit
of weighing everything in pros and cons will not die so quickly 🤓. But I want
to clarify one thing: I am thrilled and content with my decision.

I am looking forward to this alliance and spending more time getting to know
Vishi 💗. I hope I will be a worthy partner to her.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[ISRO interview experience and takeaways]]></title>
        <id>https://v2.yashagarwal.in/blog/isro-interview-experience-and-takeaways</id>
        <link href="https://v2.yashagarwal.in/blog/isro-interview-experience-and-takeaways"/>
        <updated>2022-01-29T09:01:58.000Z</updated>
        <content type="html"><![CDATA[
**Note:** This post was originally written on Jan 29, 2022 but I never posted
it. Posting it now keeping the original authoring date, but with commit date of
Aug 05, 2022.

This post was on my bucket list for almost one year, but I kept ignoring it for
one or another reason. Anyway, I wanted to write this post to add my experience
to several other interview experiences to help others. Another intention was to
document this experience for my own consumption in the future to relive one of
the greatest moments in my life and career without worrying about diminishing
memory.

I had decided to take the ISRO exam as part of my GATE preparation strategy. The
paper was apparently very lengthy and came with time-consuming calculations.
With some difficulty, I could solve a fair number of questions. Then, I forgot
about this and started focusing on my GATE preparation again. The GATE journey
is also memorable, which I may describe in a future post. While I was waiting
for results for both ISRO and GATE, the pandemic hit the country, and I made a
quick jump back to my hometown. The pandemic also delayed the ISRO results. But
when it was announced, it was a surprise for me. I was selected for further
interview rounds. Then, a long wait ensued. I had to wait till February 2021 to
get an interview call. I attended the interview for the post of 'Scientist' in
ISRO on March 4, 2021, in New Delhi.

I had been part of very few interviews in my life until ISRO's interview. I
could count them on fingers -

1. SSL admin interview at NITC (which I rocked :P)
2. The Directi interview (where I reached till last round), and
3. The Cisco interview (I rocked this one too).

I haven't been part of any other interview in my life, so far. So, I am notably
less experienced in giving interviews. But, unlike other fields in my life, I
have never felt nervous while giving interviews. I am not yet sure of the exact
reasons behind this confidence. Perhaps, I am not an introvert as I think I am.

Anyway, the decision to attend or not attend the interview was tough. There were
many reasons -

1. What if I get selected for the interviews! The pressure to join ISRO will be
   enormous.
2. What if I get COVID during the journey or stay in New Delhi!
3. If I am not interested in joining ISRO, why should I waste money on travel
   and accommodation!

My parents didn't know that I had taken the ISRO exam. So, it was a pleasant
surprise for them. I decided to attend the interviews because my parents looked
ecstatic about this opportunity. My brother accompanied me to Delhi; we stayed
in a nice hotel, ate good food, and visited some excellent locations in Delhi
together.

Coming to the primary purpose of this post, how was my interview experience?
Well, it was a mixed bag. I wasn't satisfied with some of my answers, but I
could feel that the interview panel liked my answers. Like all other interviews
I have given, this interview revolved mostly around Linux, Networking, OS, and
Security. One good thing about ISRO interviews is that ask your preferred
subjects before starting the discussion. I said that my favorite subjects are
OS, Security, and Networking. They did ask me why I don't like DBMS. I told them
that I had never worked with DBs until now, so I am not very familiar with its
practical aspects. After that, they asked me questions from my preferred domains
only. As expected, I had absolutely no issues answering most of the questions
accurately. There were some tricky questions where they tried to stress-test me,
but I was able to deflect them.

Although I had to be physically present at the ISRO center, the actual interview
happened virtually on Cisco WebEx (!).

Below is an inaccurate version of the converstaion -

**Interview Panel (IP):** Please introduce yourself.

**Me:** Introduced myself. The panel specifically asked about my graduation
details and final project details.

**IP:** So, you work in Cisco. What are you doing there?

**Me:** Explained my work in Snort and FTD team

**IP:** What purpose does FTD serve?

**Me:** Explained in brief, as I had just joined the FTD team at that time.

**IP:** We are using FTDs in ISRO. It is giving us too many issues. How do we
fix it?

**Me:** Suggested some solutions, including Hardware and Software ones. They
tried to stress-test me on this. Thankfully I didn't lose my patience and kept
giving them some answers.

**IP:** What happens behind the scenes when you type a web address in the
browser?

**Me:** Explained

**IP:** How does the router know where to forward the packet?

**Me:** I fumbled a bit on this one because I did make a mistake in the previous
question. Anyway answered it correctly in the end.

**IP:** What is page fault and context switch? Does a page fault require a
context switch?

**Me:** Answered. Don't remember the answer now. It is very clearly explained in
OSTEP.

**IP:** How is kernel mode switched?

**Me:** Explained

**IP:** What is a trap? What does the trap handler do? How is it invoked?

**Me:** Explained

**IP:** Explain Linux File Permissions? How to interpret directory 555 and file
777 permissions?

**Me:** Explained

**IP:** Do you know about the security of OS?

**Me:** Explained some concepts. I mentioned Linux Hardening, then they asked
many questions on the overall idea of hardening of the OS.

**IP:** How to modify a Kernel to work with resource-constrained devices?

**Me:** I explained some modifications, like removing unnecessary drivers and
blobs used for generic purposes, etc.

**IP:** What is a TCP wrapper? Do you know about Netstat?

**Me:** I didn't know about TCP wrappers, so I said I don't know. Explained
Netstat briefly.

**IP:** How can we improve the security of an OS?

**Me:** I explained some ways to secure OS connected to a network by installing
some tools and firewalls, like Fail2Ban, FTDs, UFW, etc. They were expecting
IPTables, so they asked about it next.

**IP:** What are IPTables? Do you know about chains in IPTables?

**Me:** I explained IPTables, but couldn't answer the concept of chains.

**IP:** Explain some common web attacks?

**Me:** I explained OWASP Top 10 and a few attacks like SQL Injection, XSS, etc.

**IP:** Which attacks are possible in an OS?

**Me:** Explained buffer overflow, heap overflow, stack smashing, etc.

In the end, they asked some general questions about Linux Kernel, which I don't
remember now. Then they concluded the interview and asked me to leave. The
interview took around 30-45 minutes. The discussion entirely revolved around the
systems side of things, which worked in my favor.

I analyzed my performance after the interview. There were some things that I
would like to fix in the future.

1. While preparing for GATE, I didn't focus on making notes. Having short notes
   helps at the last moment. I suffered because I had to go through the entire
   syllabus again, even for a quick revision.
2. I have improved my communication skills significantly, but they are still not
   up to the mark. My inherently introverted nature keeps pulling me back.
   During this interview, I fumbled quite a bit. It may be that seeing myself on
   camera on screen made me self-conscious. Still, I need to work on this aspect
   of my soft skills because I am sure that I will need to use communication
   skills a lot in the coming future.
3. My knowledge of Linux, Networking, and OS is invaluable. I need to make sure
   that I don't neglect them in the future and keep myself up to date with the
   latest trends in the field.
4. I severely lack focus and motivation. Even during the interview, I faced
   issues with focusing on the questions. My mind keeps on having distracting
   thoughts. I need to find some ways to improve my focus significantly.
   Otherwise, my mind will lose its capabilities even faster with growing age.
5. My understanding of Cisco products is severely limited. I spent three years
   in Cisco. Still, I don't know much about any Cisco product lines completely.
   I don't even know about all Cisco's Security unit's products, even after
   spending my entire 3 years there. This is a difficult situation.
   Unfortunately, now that I have left Cisco, there is no way/reason to get that
   understanding.

The results came in September 2021, and to my surprise, I was selected for the
post with AIR 30. My final marks in the written exam were 110/216 (some
questions were canceled), and I scored 83.18/100 in interviews. However, I
decided not to join ISRO because the center assigned to me didn't align with my
interests and other reasons that I mentioned in a
[separate post](/blog/why-i-decided-to-not-join-isro/). My parents were
delighted with my achievement; however, they supported my decision not to join
ISRO.

August 2018 to February 2020 was a very frustrating yet fruitful phase of my
life. The knowledge I acquired during this time helped me overcome my self-doubt
due to my failures in academics in NITC. Getting selected for ISRO made the
entire process memorable in the end. I will always cherish this achievement of
mine.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why I decided to not join ISRO?]]></title>
        <id>https://v2.yashagarwal.in/blog/why-i-decided-to-not-join-isro</id>
        <link href="https://v2.yashagarwal.in/blog/why-i-decided-to-not-join-isro"/>
        <updated>2022-01-26T15:19:58.000Z</updated>
        <content type="html"><![CDATA[
**Note:** This post was originally written on Jan 26, 2022 but I never posted
it. Posting it now keeping the original authoring date, but with commit date of
Aug 05, 2022.

Sometimes, life presents you with some choices that it becomes tricky to choose
any one of them. Last year, my turn came when I was selected for a prestigious
job at Indian Space Research Organization (ISRO). I was chosen for the post of
Scientist in the organization. The pay was top notch with the pay grade
equivalent to that of new bureaucrats. The pride that comes with the service to
the nation was also associated with the job. I could have enjoyed my life
without any worry about layoffs, pay cuts, workload, always having to learn new
things, etc. But I decided to leave the offer and continue with what I was
doing.

Why did I do that? Was I mad? It has been almost one year since my final
interview and nearly 3 months since I declined the offer. In this post, I intend
to publicize my reasons for not joining ISRO. You may or may not agree with a
lot of these reasons (even I doubt some of my decisions), but don't hesitate to
voice your opinion. Perhaps, it will give me another perspective to think about
similar situations in the future.

## The job profile and assigned ISRO center

I studied Computer Science during my undergraduate and have been working in the
software industry since then. I know I can learn any new field (aerospace
engineering, in this case) if I want to. Still, it was not a financially
lucrative choice, and also it was not in alignment with my interests.

I was assigned to NRSC, Hyderabad, which would be my base for the rest of my
career. NRSC stands for National Remote Sensing Center. As I understand it, the
NRSC primarily works on analyzing the images and media received from various
ISRO satellites. I have never been an enthusiast of the field of computer vision
and image processing (perhaps because of the maths associated with it). So I
wasn't very keen on doing something which does not align with my current
interests. Although, one can say that you start loving anything if given enough
time. But I wasn't very sure about taking chances.

Of course, I queried about the possibilities of transfer to some other center. I
was told that the chances of a transfer are slim unless there are exceptional
circumstances or a mutual transfer.

## The location

As I mentioned earlier, if I had accepted the offer, I would have been bound to
Hyderabad for the rest of my career. This was totally unacceptable to me. Many
things have changed globally since the pandemic started, and the work location
flexibility is one of the positive changes. Earlier, it was challenging to work
from home, but now, it is/will be accepted as an industry norm. ISRO, being a
government organization and from a national security perspective, will not allow
its employees to work from home, rightly so. At present, I would perhaps be okay
with the idea of exploring the world and staying away from the family. Still, I
would like to settle down at some familiar place in the longer run. Joining ISRO
would have stolen that possibility from me ultimately, if not immediately.

I have been staying at my home for the last 2 years due to COVID lockdowns. This
has affected my psyche at a deep level. I no longer wish to stay away from my
parents. The detachment caused by my 7 year-long explorations ended with COVID
lockdown. It will be tough for me to stay away from them for any long duration
now. Air travel has reduced the distances drastically, but the possibility of a
WFH-friendly future has spoiled me. ISRO is unlikely to provide this kind of
option in the foreseeable future.

## Money

Money always plays a part in every decision a working adult takes. While the
starting salary given by ISRO is comparable to private sector companies, the
yearly increments are peanuts. One gets 18% conditional increment + possible
promotions every four years, which looks terrible compared to MNCs. Although
joining ISRO comes with certain other perks which will definitely match or even
outshine the overall CTC offered by MNCs in some cases.

Suppose I had decided to join ISRO in an alternate universe. In that case, I
could have given you a lot of reasons why money should not be a factor in
deciding whether to take the job or not. So, I will stop discussing the
importance of money in a job offer here.

## Not my kind of government job

Government jobs are lucrative in India. They pay decent, have excellent perks,
give life-long job security, and calm and peaceful life on most days. However,
you can divide the government jobs into three categories -

1. Those with power, status, money, meaningful work, and hectic life
2. Those with meaningful work, money, and peaceful life but no power and status
3. Those with peaceful life (?), nothing else

In my opinion, ISRO's job falls into category 2, where you have good work,
money, and life but no power or status. I have good work and money in the
private sector (life is a hit or miss). So, I couldn't find any reason good
enough to join ISRO. If I had the option to choose a job from category 1 (for
example, all India services), I wouldn't have given a second thought to the
idea. My current thinking is that if I have to live someplace other than my
hometown, I would like to have either big money or power and social status.

## It wasn't my original target

I attempted the ISRO exam to get some additional practice for the GATE exam. I
had plans to get into some good colleges (IISc!) for further studies. ISRO's
exam format coincides very much with the GATE's. So I thought that it would be
an excellent opportunity to get some much-needed real exam experience. There was
no other aspect to this fact. If I had taken the exam intending to join ISRO on
selection, it would have been effortless to convince myself. But, in my
scenario, I could not convince myself about the opportunity. Some may say that
not everybody gets this opportunity, and I should have accepted it happily. I am
sorry, but I don't subscribe to this viewpoint. I understand that the gods were
kind enough to provide me with this opportunity. But I firmly believe that the
same gods would also appreciate my reasoning about the decision to decline the
offer.

For some people, these reasons may seem non-important. My personal circumstances
and professional ambitions, and my self-confidence (perhaps over-confidence)
contributed to my final decision to decline the ISRO offer. It is very much
possible that I may regret this decision in the future when my life takes a
downturn. I hope that this post will remind me of my present situation and bring
me out of my grief. The decision taken is what matters now. I should focus on
the next minute, hour, day, month, and years to come.

Wish me luck 🍀
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Things I learned in Cisco]]></title>
        <id>https://v2.yashagarwal.in/blog/things-i-learned-in-cisco</id>
        <link href="https://v2.yashagarwal.in/blog/things-i-learned-in-cisco"/>
        <updated>2022-01-22T16:15:24.000Z</updated>
        <content type="html"><![CDATA[
**Note:** This post was originally written on Jan 22, 2022 but I never posted
it. Posting it now keeping the original authoring date, but with commit date of
Aug 05, 2022.

After three years at Cisco, I finally decided to explore other opportunities
in 2021. 22/01/2022 was my last day in Cisco. It has been an exhilarating
journey. Even more so because it was my first such journey. I thoroughly enjoyed
my time at Cisco, both professionally and personally.

Cisco provided me ample chances to work on a variety of problems. I started in a
totally independent role exploring various open-source products and developing
POCs integrating multiple open-source tools to the Cisco product line. I worked
with OPA, ModSecurity, OpenRASP, etc. along with evaluation of Signal Sciences,
K2 etc. We also worked on identifying differences between Snort's http module
and ModSecurity, apart from developing POCs to identify supply chain attacks by
evaluating the build artefacts generated in a CI pipeline.

Later I got a chance to work with a typical product development team when I
switched to Snort team where I worked on the FTD integration for Snort, and
helped in shipping high-quality code enhancing legacy Cisco firewalls. I also
got an opportunity to contribute to some significant components to the very
early stage Secure Firewall Cloud Native (SFCN) – Cisco's own cloud-based
security solution – where I introduced an important component required for
health monitoring in the SFCN clusters. Throughout my tenure at Cisco, I got
opportunities to work on both the legacy (Lina ASA - a 20-year-old product) and
the latest tools and technologies – Kubernetes, Docker, Terraform, Prometheus
etc.

But, work was not the best thing about Cisco. The work was, of course,
excellent, but what makes Cisco a dream company for many is its people. The
culture that Cisco imbibes is pure gold. I don't know how the rest of the
industry operates in this department, simply because of my inexperience. But for
a novice like me, Cisco provided an ideal launchpad. I have many regrets about
my time at Cisco, more on this later in the post. The people I met and worked
with throughout my time in Cisco were exceptional in their work and, at the same
time, were quite humble and down to earth in their dealings with me. I have also
heard about some bad experiences from people working in Cisco, so I may have
been fortunate in this aspect. Exceptions are everywhere, but they should not be
the norm. And the toxicity is definitely not the norm in Cisco.

While I learned a lot of things in Cisco, there were a lot of opportunities that
I didn't utilize while in Cisco. There used to be many hackathons, patentothons,
cultural, literary, technical clubs, and sporting facilities in Cisco. Many of
my friends were part of these activities, and some even led the organizing teams
of these event. I never tried to contribute to any of these events. I had some
personal and professional reasons behind this lack of enthusiasm. One of my
colleagues criticized me **privately** for this on my last day - "Yash, I wish
you had shown more involvement during the team building activities." I have been
an introvert throughout my life, and changing one's personality is not easy. But
this is something I will actively try to avoid repeating.

Now, you may ask, if everything was so rosy about Cisco, why did you leave,
Yash?

Well, the reasons are many folded -

1. I am only 25. It is not a time to settle for me.
2. I was trying to break away from the traditional network security domain. I
   have been interested in distributed systems and cloud security. Still, my
   current team was not an ideal place for this. Switching to some other team
   inside Cisco was an option. But I decided to explore the industry from
   another perspective by changing the company.
3. Few more reasons that are not as important to mention here.

Anyway, Cisco will always have a special place in my heart for introducing me to
the corporate world.

It is farewell for now. Au Revoir, Cisco!
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[2021 - A Bullish Year]]></title>
        <id>https://v2.yashagarwal.in/blog/2021-a-bullish-year</id>
        <link href="https://v2.yashagarwal.in/blog/2021-a-bullish-year"/>
        <updated>2022-01-04T16:55:24.000Z</updated>
        <content type="html"><![CDATA[
2021 was a year of realigning priorities for me. I started the year with a set
of goals, expectations, and an enthusiasm to achieve these, and here I am,
ending the year with entirely different objectives and perspectives. There were
a few ups and downs throughout the year, but collectively, these have
transformed me into a more fitter, confident, enthusiastic, and curious version
of my past self.

## Health

If you read this blog regularly, you may know that I have been struggling to
make health a priority in my life for the last few years. This year also started
on the same note. I started with 65 kgs of weight, and by the end of July, my
weight had increased to 71 kgs. I have been underweight for most of my life, but
I probably became obese for the first time on the BMI scale this year. And I am
not very proud of this, even though I always desired to gain some weight while
growing up. I have long realized the importance of exercise in daily life but
never acted on it seriously.

Nonetheless, this year I finally managed to work on it. Since September, I have
reduced my weight from 71 kgs to 62 kgs. More importantly, I could bring my BMI
down to an optimum level.

Another important aspect of health that I am working on is sleep. For some years
now, I have been working on regulating my sleep timings and the time I spend
sleeping at night. I have data about my sleep duration for the entire year.
Using that, I produced the chart below, which shows that I have managed to sleep
at least 8 hours on average (this also includes afternoon naps).

![Sleeping in 2021](/images/posts/2021_average_sleep_duration.png "Sleeping in 2021")

One of my last year's goals was -

I feel that I have managed to achieve this goal with a good level of accuracy.

## Career

This year, I completed three years in Cisco. It has been a wonderful experience.
However, I had a feeling that I should move on and start exploring the industry
from a different perspective. So, I decided to go back to the interview table.
In 2022, I will be joining a late-stage US-based cloud-security startup. I will
write a separate post describing my experience preparing and attending the
interviews.

I had to make a rather tough decision about my career this year. When I was
preparing for GATE, I also decided to take the ISRO exam. The idea was to get
some additional practice from the GATE perspective. After clearing the written
test and the interviews, I got an all-India rank of 30 in the exam. As a result,
I was offered a Group-A post of Scientist in NRSC Hyderabad. However, it didn't
align with my vision and plans for the future, so I decided to decline the
offer. I hope to write a long-overdue post about my experience with this
sometime in 2022.

## Blogging and Writing

The fact that I could not post this review on the first day of the year is a
testament that I am struggling with writing. I am not in the proper mindset to
write anything. I have tried to start small, but writing even a single sentence
seems like a burden. Throughout 2021, I had a nagging feeling that I should
write, but I couldn't find the enthusiasm to sit down and get going.
Unfortunately, I don't even see myself writing anytime in the foreseeable
future.

I notice that the procedure used to publish anything on this blog is very
complex. Unlike WordPress, I have to battle with markdown, git, code editor,
etc., to publish a post and make subsequent updates. The complexity associated
with the static sites seems to have created a block in my mind. Unfortunately,
developing a new website is no longer a priority for me. And I am not yet ready
to accept the tradeoff between spending money on WordPress hosting and the
comfort of writing in Wordpress's editor.

I planned to journal regularly in 2021. I started with that, but soon it turned
into a logbook kind of activity. Instead of introspecting over my day, I started
tracking each hour of the day, which was not the intention. So around July, I
stopped doing it.

## Reading

I had set a target to read five books this year. I completed that goal. I read a
lot of PDFs this year, which can't be classified as books, so my reading
statistics are very much skewed for the year. However, I didn't plan properly
this year, so my efforts seem scattered and unfocused.

To be very honest, I was distracted throughout the year by the continuous
flooding of information. My tendency to do everything with perfection further
made things complicated. Another troubling issue was my resistance to making
notes or summarising the books I read. I consider this an important activity
because I find it challenging to recall otherwise.

I dabbled with Zettlekasten for some time this year. It is an exciting idea, but
the time required to set it up is a big hurdle. It takes considerable effort to
summarise a piece of knowledge, link it with other information, and then revise
all of it. I may not be ready for it yet, but I will be trying it again in 2022
because I am very confident about the potential of this system.

I have reduced (or stopped) my Twitter usage to minimize information overload. I
felt that passively reading others' views distorts my thinking and ability to
generate original ideas. Although I am not really producing any exciting ideas,
I want to keep my mind clean and free from distraction as much as possible.

## Media Consumption

I logged my sleep data, work schedules, perceived productivity levels, perceived
sleep efficiency, mobile usage patterns, etc., in a Google Sheet document.
However, around mid-year, I started to get impatient with the whole manual setup
and stopped logging my data. So, unfortunately, I don't have any way to analyze
all these patterns now. I am totally disappointed with the lack of any standard
tool that can collect at least mobile usage data while also ensuring privacy.
Rescue time is something I have thought about, but I cannot convince myself to
use that app due to privacy issues.

Below are my media consumption habits from 2021 -

![Media consumption in 2021](/images/posts/2021_media_consumption.png "Media consumption in 2021")

For some reason, I watched a lot of content in the last two months of 2021.
Possible reasons may be my acceptance of the new job offer or my truce with the
weather. For whatever reason, I consider this year a controlled one in the
binge-watching department.

## What in 2022?

- Build muscles - Now that my weight is at an appropriate level, it is time for
  me to build some muscles.
- Read 24 books - I plan to read 24 books this year. I am yet to decide if I
  want to focus on a particular subject or diversify my reading.
- Phone usage - Planning to keep it under 3 hours. However, I need to figure out
  how to export this data out of my phone.

As you might have noticed, most of my failures in 2021 have something to do with
my habit of doing things perfectly. While it is good to perform any task as
cleanly as possible, it sometimes becomes a big hurdle in starting up. In 2022,
I hope to keep this tendency at bay as much as possible.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[25, it is!!!]]></title>
        <id>https://v2.yashagarwal.in/blog/25-it-is</id>
        <link href="https://v2.yashagarwal.in/blog/25-it-is"/>
        <updated>2021-06-06T00:00:00.000Z</updated>
        <content type="html"><![CDATA[
I turned 25 in the week gone by. I have been on the earth for a quarter of a
century now, and the feelings are mixed. I love to write about myself, even at
the risk of overexposing myself to the general world. This helps me in
remembering my younger self. That, I think, is the best yardstick to judge
myself against. Unfortunately, while I should write positive things, the tone of
most of my personal experience articles tends to be negative. It is instinctive
and something that I have not learned to control just yet. Nevertheless, I will
consider myself successful when I look back at my life, and the memories make me
smile. Some of my previous posts do make me smile.

The last one month or so has been tough on me. Suddenly, all my plans started to
collapse, I started feeling depressed, and the feeling of being an imposter hit
me hard once again. All this coincided with the second wave of COVID-19 in
India, and it is easy for me to blame COVID. But there are certainly other
reasons that have been building up for the last few years. The eruption of these
accumulated worries from time to time drains me down. This has been the essence
of my life for the previous few years since I started having an idea of
self-ownership.

### Borrowing from future and past

I see many of my friends and colleagues opting for higher studies abroad or in
top institutes of India. While I also had such plans in the past, circumstances
forced me to kneel down. I had hoped that I have adjusted to this reality. But a
constant wave of social media posts from friends and people leaving the
workplace has negatively affected my subconscious mind. Given that I decided
with maturity and complete understanding of the situation, I don’t know who or
what to blame for my current mental state. I guess I just need to give it some
time, and it will subside on its own.

I often tend to compare myself against others and feel low seeing people doing
better than me. It is definitely not jealousy, but being competitive has so
intrinsically become part of me that I can’t help. Somewhere deep down, I also
know that this comparison is futile. Different people can have different life
situations, and life is not the same for any two persons. A better option for me
is to compare against my younger self and see how much I have changed. That
should be easy to do, given my habit of writing my experiences frequently. I
don't know what is holding me back.

When I look back at my childhood, I see a weak, frail boy bullied by good and
bad alike. Unfortunately, I never mustered the courage to fight them back. The
bullying and my subsequent retreat into a cocoon have had a lasting impact on my
life. I am still trying to reverse it. On the other hand, I still think that I
am a born introvert. My life experiences might undoubtedly have given my
personality its current shape, but it didn't all start with a blank slate.

### The struggles of the present

One thing I am very proud of myself is that I never lost my curiosity. I am
still inquisitive. I love to learn anything and everything that I can put my
hands on (perhaps except artistic stuff). But what kills my enthusiasm is the
fact that I don’t utilize my learnings in any way. I tend to live my life in the
same way I have been living it till now. There is no adventure whatsoever in my
life, as I see it. It is as if whatever new I learn doesn’t make any impact on
my day-to-day life. When I think about it deeply, it appears to be a very
unfortunate aspect of my quest for knowledge.

For instance, let us talk about reading. I agree that we should not read to
remember, and that way, definitely reading has given me some new perspectives. I
have read anywhere between 90-100 good quality books in the last one and half
years. During a typical day, I get many insights related to whatever I have
read. But when I sit down to articulate them in the form of a blog post or a
personal note, I go blank. According to my introspection, it seems that most of
my learnings are just superficial and I suffer from so-called illusion of
knowledge. This reminds me of a quote by Daniel J. Boorstin -

Another thing is my short attention span. I can’t focus on one thing for more
than a couple of minutes now. This is one thing that has deteriorated over the
years as I become more and more connected. I know that meditation will
definitely help me with this issue. Still, I can’t find the motivation to keep
meditating continuously. I can start meditating any day. I can continue it for
some days by using my willpower, but this is not sustainable. With a limited
stock of willpower, I am bound to fail unless I make meditation a habit. I have
almost cut myself from social media, instant messaging apps, and all other forms
of communication to focus on the important stuff in my free time. Still, somehow
my attention betrays me every single time.

For a couple of years now, I have been blaming my undecidedness to write
regularly on so-called “writer's block.” This is a complete sham. It has just
served as a cover for my laziness and unwillingness. I often convince myself
saying that I should first acquire knowledge. Then, one fine morning, I will
wake up and write world-shaking articles. Of course, this is never going to
happen, but why not, it is a good excuse to keep me happy with my comfort zone.

### Conundrums of asking for help

There have been many people in my life who have offered to guide me and help me
realize my goals. However, my reserved nature and the feeling of being an
imposter have stopped me from opening up to anyone. I have been struggling with
imposter syndrome for the last 3-4 years. I am not sure about the reasons yet.
Still, I think my hesitation in requesting a “familiar” person for mentorship
arises from the feeling that I might not perform as they would expect me to do.
That would shatter my image in front of them. Therefore, my subconscious mind
has decided that it is more optimal to keep the (false?) impression intact
instead of getting the required help. That might also answer why I never share
my articles with anyone. It is a fact that I don’t feel very confident about
myself and my work. It has affected me at the workplace, and perhaps it will
continue affecting me in the coming years. The only way I can think of to get
rid of this problem is to face it.

I have also often struggled to take criticism constructively. Somehow my
egoistic nature and perfectionistic tendencies mixed with imposter syndrome make
it challenging to learn from criticism. Just to clarify, I don’t mean that I
harbor any ill thoughts for the criticizer. It is something personal, and I
don’t have any words to describe it right now.

### The illusion of competence

While reading has given me new and unique perspectives to think about the world,
it has also given me an illusion of competence. I feel like I know a lot, but
when it comes to utilizing the “earned” knowledge, I cannot interconnect my
thoughts. I have seemingly different areas of interest, and that is reflected in
my reading habits. My expectation is that diverse reading habits will result in
a future me who will gather ideas from multiple fields and interconnect them to
build a novel abstraction. I am not sure if this is a far-fetched desire and
even possible for an average human. But I can’t push myself away from this
thought. Over the years, this has become one of many ambitions to get to that
state. I don’t know if I will ever reach that point, but I don’t see any harm in
keep trying. My only worry is how to stay away from the illusion of expert-level
competence in a field, while I don’t know actually have any expertise.

### The political me

Those who know me in my personal life will attest that I am not able to stay
loyal to any one side of the political spectrum. I have always see-sawed between
left and right. Of course, this see-sawing has subjected me to "gentle" bashing
from my friends adhering to either ideology. Famous Hindi poet Ramdhari Singh
Dinakar very accurately points out the situation -

Now, this is one of the paradoxes that troubles me quite frequently. While
taking sides mean losing some of your individuality, not taking sides is also
equivalent to not having a clear goal in mind, in a way.

Since when I started reading profusely, I have tried to keep this balance
intact. I have made conscious efforts not to form _strong_ opinions and not
adhere to one particular ideology without looking at facts and data. The
engineer's mind weighs everything in terms of data and facts and filters out
personal opinions.

I read a lot about foreign policy, society, culture, caste, religion, economy,
history, and the constantly evolving political structure of India and the World.
But, unfortunately, most of the quality media is dominated by the left. I don't
want to engage with keyboard-warriors on Twitter, WhatsApp, and elsewhere, so
that leaves me with significantly less material to know the genuine viewpoint of
the other side.

Over the years, I have realized that socially I tend to be on the center-left
and economically, on center-right. But sharing political views in the public
domain without proper research is not ideal. I want to consolidate my learnings
and form well-informed and well-analyzed opinions on happenings in the world in
general and India in particular before I participate in political discourse. It
does not mean that I don't have any political opinions. Most events cannot be
categorized as good or bad; it is just how one wants to perceive the world.
Therefore, I constantly try to avoid getting influenced by what a random
journalist with certain motives, sitting in a high-rise AC office, might want me
to believe.

### The CS guy!

Though I hated Computer Science a couple of years back, I have worked on my
fears. Now, at least I don’t have any understanding issues with the core CS
subjects (except DBMS, perhaps. I don’t like it; at all!) I didn’t focus on
understanding whatever CS theory was taught during my undergraduate (again, a
lack of proper mentorship.) Although this doesn’t harm me in my professional
life, I want to get some kind of research experience at some point in my life.
Unfortunately, it seems unlikely for me to enroll in a full-time graduate
program in the foreseeable future. So, I am weighing my options to go for a
Systems course via online studies. Assuming I get admission, one option is a
sponsored graduate program (such as this
[one](https://iken.iisc.ac.in/mtech-online/) offered by IISc.) Another option is
to go for an online [MS degree](https://omscs.gatech.edu/) provided by some US
universities. I will surely miss the unique campus experience, but I hope it
will still quench my intellectual thirst. I currently have some other stuff on
my plate. I will try to finish them before deciding if and when I should opt for
these options. I hope to make a call in the next two years in the worst-case
scenario.

### Originality

By originality, I mean a way to build upon something existing — some kind of
improvement upon an already existing thing, idea, or abstraction. Almost
everything humans have created has been an improvement over something preceding
it, either man-made or natural. In my opinion, originality is a creative process
to generate novel ideas improving upon existing processes, things, tools, and
knowledge systems to make them more desirable, optimized, user-friendly, and
insightful. Original need not be "original" in its literal sense.

While I have been working on my CS skills, it is not the field where I get my
most original thoughts and ideas, despite being the subject where I spent 4
years of my life. I have met many amazing people in Cisco over the last 3 years.
I am often awestruck by their ability and passion for continuously generating
new ideas. Whether it is a Hackathon or a Patentothon, I have been fortunate to
team up with people who can generate exciting ideas with surprising depth.
However, I have thought about it and realized that I am not yet at that level
where I can generate original ideas worthy of patenting or publication. Some
people are just born with that kind of talent, and some acquire skills superior
to any talent. With growing experience, I might get to that level someday, but
currently, I am yet another average Indian software engineer. Read the last
section of this article to know why I am content with this situation for now.

On the other hand, the fields where I tend to get many ideas nowadays are
religion, politics, and history. One possible reason behind this might be that
these subjects are my area of interest nowadays, and I read related books during
my non-work day. So my mind gets a lot of time to consolidate this stuff.

It is such a contentious issue for me that I feel embarrassed talking about it.
In fact, this is the first time I have actually given any thoughts on this
topic. And I am glad that I did it. I wrote above my initial impressions about
an issue I was unaware of until a few moments ago. I hope to get more clarity
and insights into the real reasons behind my lack of enthusiasm to produce new
ideas in the coming time.

---

Even if not entirely by choice, I am trying to embrace the slow-growth mindset,
taking short-term hits for long-term gains. I hope this gamble will pay off, as
I think it will be the right approach. Long-term gains far outweigh short-term
benefits when it is a matter of whole life.

While I keep whining about my future and past and try to piece together my
present, this quote sums up the way forward succinctly —
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thoughts on the Family Man 2]]></title>
        <id>https://v2.yashagarwal.in/blog/thoughts-on-the-family-man-2</id>
        <link href="https://v2.yashagarwal.in/blog/thoughts-on-the-family-man-2"/>
        <updated>2021-06-05T11:45:02.000Z</updated>
        <content type="html"><![CDATA[
![The Family Man 2](/images/posts/the-family-man-2-cover.jpg "The Family Man 2")

I binge-watched the second season of The Family Man (TFM) 2 last night. I was
eagerly waiting for this season of TFM for a long time, especially after the
highly gripping season 1. And I am not disappointed. While I watch digital
content very selectively (young-adult fantasy depicting a dark and mid-age
Europe and Russia and spy-genre Indian shows for occasional patriotic doses),
very few shows have such excellent cinematography. It is the plot of TFM2 that
made me ask some questions myself. While I don’t have clear answers to them yet,
I thought I will just list them down, along with some of my raw thoughts.

The plot is about the resistance of Eelam Tamils of Sri Lanka against the Sri
Lankan government. The topic is riddled with complex matters of morality,
humanity, human rights, ethnicity, language, majority-minority conflicts, and
the right to self-governance. Sri Lankan conflict is familiar to most Indians
because of India’s involvement in the struggle in the early 1980s and 90s and
the subsequent assassination of Rajiv Gandhi during an election campaign in
Chennai. Many such issues are spread throughout the world — e.g.,
Israel-Palestine conflict, Rohingya issue in Myanmar, Nagaland in India.
Specific questions that perplex me about these conflicts are -

1. Why do people fight for their ethnicity? How difficult is it to live
   alongside other people under a defined constitution prepared with a mutual
   agreement?
2. Why are modern nation-states reluctant to give autonomy or independence to
   such groups just to avoid bloodshed?
3. What are the causes of the origins of such conflicts?
4. Are there any examples where the final settlement was acceptable to both
   sides, and nobody left the table feeling betrayed?

I look for academic (Sociology, Anthropology, and Political Science, to be
precise) answers to these questions. I understand that ground realities are
often very different than what we learn from news media and books. Humans tend
to have a natural connection to their perceived kinsmen. Why do you think nature
has decided to keep a human baby dependent on her parents for almost 1/4th of
her average lifetime? The bond we generate with our society, tribe, kin, and
family stays with us forever, and we strive to keep them safe and secure at any
cost.

I will give a controversial example - the Indian freedom struggle is a revered
movement for most Indians, including myself. Still, for the then British rulers,
it was a rebellion that had to be suppressed at any cost to save their empire.
We despise the atrocities performed by the British on Indian people. How is that
different from the horrors seen in the conflicts of the modern world (not just
the people in power, rebels everywhere have also committed unspeakable
atrocities). As I understand it, it is not a binary problem; there is no black
and white in this. There are shades of grey and what amount of black you see
depends on a lot of factors. Just be aware of the fact that the more powerful
side need not be the necessary evil. Resolving any conflict requires some
compromises from both sides. Until both sides are leaving the table feeling that
they won, no negotiation will be successful. Remember -
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Looking back at 2020]]></title>
        <id>https://v2.yashagarwal.in/blog/looking-back-at-2020</id>
        <link href="https://v2.yashagarwal.in/blog/looking-back-at-2020"/>
        <updated>2021-01-03T10:19:58.000Z</updated>
        <content type="html"><![CDATA[
While I thought of writing this review on 31st December, I couldn't overcome my
laziness. It has been a persistent problem with me in 2020, which I haven't been
able to fix as of now. On average, the year 2020 was a good year for me. It
wasn't equally forgiving to me on every issue of my life, but it was most
undoubtedly lenient on the issues I consider most important at this phase of my
life. As for most people, it was a year of self-retrospection for me as well. I
identified some new goals in my life, forgot some others, compromised with some
failures, and learned the value of loved ones.

Like previous years, I have identified some critical areas of my life, where I
am putting more focus year after year. It is easier to focus on one topic at a
time. I have decided to omit some parts of my life from this write-up because I
am not yet ready to reveal them to a specific set of people (although very few
people read this blog now, thanks to my irregularity, I prefer to stay
risk-averse).

## Health

2020 belonged to the pandemic. So it is most prudent to start with the topic of
health. For the last some years, I have been struggling with a lot of
health-related issues. Although this year was a much better one for my body and
mind, I am still petrified of my health issues. It seems that I am a
worry-magnet, and the worry of catching coronavirus was the biggest of them all
this year. I spent almost 3-4 months in this worry. It took some toll on my
health, but in the end, I was able to come out of it, thanks to family.

I should give part of the blame to my laziness. I had stopped all my learning
activities in the mid-to-late year (perhaps I was exhausted). And that gave way
to evil thoughts in my mind. As they say, "An idle mind is the devil's
workshop!". Thankfully I got hold of the situation while it was still
manageable.

![Sleeping in 2020](/images/posts/2020_sleep_hours.jpg "How much I slept in 2020?")

This graph shows how my sleeping times changed throughout the year. I lost track
in the third quarter of the year. Anyway, in December, I seem to have come back
to the correct path.

This chart doesn't convey certain things very clearly. First, it shows the
average amount of time I slept in a particular month. However, that time
includes the afternoon nap also. And in the mid-year months, where you see 9+
hours of sleep, it means that I was sleeping quite a lot in the afternoon and
less at night. In the last three months of the year, I have been trying to
regulate my sleep timings at night, and I am quite satisfied with my progress. I
have observed over the years with my sleep experiments that whenever I start
sleeping less at night, I tend to exhaust myself in the next couple of months.
This theory got validated this year when I exhausted myself from June onwards,
and my health issues reappeared after sleeping significantly less in April and
May (night sleep).

I _actually_ did some exercise this year. I bought a gym subscription this year,
but unfortunately, that became my worst financial decision in the last several
years because I left Bengaluru before the government imposed the lockdowns.
However, I did some light exercise at home. That didn't do wonders, but at least
I was able to keep my BMI constant throughout the year. Even after eating
delicacies prepared by Mom all year!!! :heart_eyes: Hopefully, I will be able to
start running in 2021, even if only on weekends.

In November, I suffered from severe back pain. After getting an ergonomic chair,
things seem to be in control. But that incident reminded me of the importance of
exercise. I will try to include some simple back exercises in 2021.

## Family

The year 2020 was quite an unusual year on this front. Since I started at NITC
in July 2014, I have been away from my family for most years. But thanks to
lockdown, I got to spend time with my family this year. I had anticipated
lockdowns in India quite early, so I left Bengaluru in March just before the
government imposed lockdowns in a "shock and awe" manner. So I reached home on
time, and that was the best decision I have taken this year. If not for my
family, I don't think I would have been able to handle pandemic-induced health
issues.

I have been away from my brother for almost seven years now. More importantly,
these seven years were the life-defining years for both of us. It turns out that
he and I think very differently. I guess that our thinking results from the
different environments where we spent our early adulthood. It was initially very
tough to agree on something, but we slowly learned to agree to disagree. Staying
away from family has made me more careful and risk-averse in some sense. I tend
to (over) analyze everything, and that causes delays in decision making. On the
other hand, he is quite free-minded and rebellious. How different we both have
turned out to be!!!

I don't mind this variety, though.

## Reading

I had set a target to read 20 books this year. In the end, I managed to read a
lot more than 20. Mid-year, Around July/August, I started losing track of the
books I was reading. As I mentioned in my last year's review, I was getting
disillusioned with Goodreads for some time. This year I tried to use it, but
ultimately I didn't log the majority of my reading anywhere. I don't know if
this is a good thing to do. I will try to keep it this way for some more time
and then analyze the data-collection pros and cons.

I have identified some issues with my reading pattern. I tend to read the books
passively. That makes it quite challenging to retain knowledge for the long
term. On top of that, I don't make notes as well. So, I cannot even revise the
content quickly without going through the whole book again, which is
counter-productive. It is a childhood habit, and I assume it will be tough to
break this habit. However, whenever possible, I now actively remind myself to
question the book and not take everything written in the book for granted. It
will take some time (perhaps years), but I am confident about changing this
tendency.

I read a variety of books this year. Most of these books were related to
humanities subjects like political science, history, etc. I got interested in
tech quite late in my life. Before that, humanities was my favorite pastime.
Once I entered the tech field, I somehow couldn't continue this. But this year,
I found myself distancing from technical topics somewhere around June. There is
a reason behind that disinterest that I would like to keep private for now. At
the same time, I struggled with my health issues, so I decided to start with
humanities again. Looking back at that decision, I feel it was a superb choice.
I have learned so much about India, its history, and the present. Somehow, I was
able to ask questions about why a particular thing was done the way it was done.
I was never able to think like that while reading a technical book. Does that
make my knowledge about tech hollow? I don't know yet. But I will be actively
looking for an answer in the coming times.

One subject, where I expected to glide through was Economics. I
[mentioned](/blog/2018-year-in-review/#reading) in my 2018 review that I find
Economics interesting and want to learn more about it. I couldn't do that in
2019, but this year I decided to pursue that goal. So I started with the most
fundamental books - NCERT class 12th Microeconomics and Macroeconomics. The
result is that I have lost my interest in learning economics now (hopefully
temporarily). Either the books are written horribly, or I didn't put enough
effort. It took me ages to complete these two books, and still, I don't
understand a lot of the concepts. I think it was the wrong strategy to start
with these books. I should have watched video lectures by some University
professors. Perhaps I will do that this year, whenever I get time from my other
goals.

Another subject, which caught my interest was Anthropology. I had
[read](https://highlights.yashagarwal.in/posts/2019-02-16-sapiens/) the
excellent "Sapiens" book by Yuval Noah Harari a couple of years back, and that
was a thought-provoking read for me. So I decided to read further on the topic
to answer some of the questions that I had about human society and why certain
cultural elements got evolved in the way they are at present. It is quite an
interesting subject, specifically social and cultural anthropology.

Below are some of the superficial statistics about the books that I read this
year -

|              | Year Goal | Achieved |
| ------------ | --------- | -------- |
| Read/to-read | 20        | 69       |
| Numpages     | 7000      | 16279    |
| pages/day    | 19.13     | 44.48    |
| days/book    | 18.30     | 5.30     |
| book/month   | 1.67      | 5.75     |

Once again, these numbers are not accurate indicators of the quality of reading.
Not all of the books were worth reading. I consider around 25 of these books as
a waste of my time. Some books were as small as 100 pages, while some were so
good that I wanted more even after reading 800+ pages.

Now, the question is how many of these books benefited me. I plan to reread some
of these books and prepare some notes after/along with the second reading. I
have tried writing on paper, but my perfectionistic tendencies stop me from
"spoiling" the paper. So I will make the notes on Onenote this time and write
them down on paper later. Rewriting on paper is a compulsion because my mind
seems to be having issues recalling digitally-read content. It is one reason why
my Kindle is inside my drawer for a very long time.

One of my wishes for 2021 is to read
[The Story of Civilization](https://www.goodreads.com/book/show/78159.The_Story_of_Civilization).

## Blogging and Writing

It is quite evident from this blog's activity in 2020 that I didn't write very
actively. I am going through a challenging phase (imposter syndrome?) in my tech
journey that is difficult to describe. I started this blog when I was actively
learning new things in tech. But now, I have almost hit a plateau. If I phrase
it in another way, I am not learning enough technical content now. I don't think
it is related to my work, but somehow, my attention has been on other things
lately.

I have not been able to write anything on paper as well. I did some analysis on
this issue, and it turns out that I have perfectionist tendencies, as I
mentioned in the last section. I try to do everything with perfection, and that
doesn't work most of the time. You can't always have everything perfect in real
life, although aiming for perfectionism is not a bad thing. But when this goal
becomes the process, it starts creating problems. And I am facing the same
issue. Now, whenever I sit to write anything, I remind myself at regular
intervals that I don't have to be perfect all the time. It seems to work till
now.

Anyway, in 2021, I will write a lot on paper and perhaps on this blog. I am
still contemplating if I should write long-form essays on some contemporary
issues on this blog. Maybe I will create a new WordPress blog for that kind of
stuff and keep this blog for my technical content and everyday life-related
posts.

I figured out one more issue with my thought process. Given a topic, if you ask
me to write a summary of it, I wouldn't be able to articulate my thoughts.
Something that Richard Feynman was very good at. In other words, I struggle in
explaining my knowledge to others. I guess this means that I don't understand
the topic well enough to write anything about it. It might also mean that I have
some issues in thinking clearly. I hope, with practice, more active reading, and
regular writing practice, I will win over this issue.

## Work

It isn't easy to summarise my work experience. It's my third year at Cisco now.
The team in which I was working for the last two years got dissolved. However,
higher management was quite helpful in transitioning to a new team working on
Snort development. So, I will be getting a much-needed product development
experience now. Till now, all is good; however, product development is slightly
weird. I need to give it more time before drawing any conclusions. Since I have
joined the new team, I feel that my day-to-day learning has suffered during work
hours. I hope it is a temporary phenomenon and I would be able to overcome it
soon.

The COVID outbreak has spoiled some of my plans, and I am unsure if my familial
circumstances would allow me to opt for those plans in the near future. I
reoriented my goals to adjust to the changing conditions. But whatever happens,
I will try to utilize the available resources to the maximum extent possible.
Hopefully, everything will settle in the right place soon.

## Media Consumption

I seem to have been able to conquer the addiction to social media. I had been
trying to do this for 3-4 years, and this year, I feel that I was in control for
most of the time. Whenever I lost myself in Twitter/Quora/Reddit, I found it
easy to cut-off myself from these websites without any withdrawal symptoms,
which is a very pleasing experience.

Facebook deserves a special mention here. I have been entirely out of touch with
Facebook for the last couple of years, partly due to self-control and partly due
to the bad press Facebook has recently gotten. One thing that has helped me is
that I don't have any content on my newsfeed because I took some time to
unfollow everyone. As there is no content to scroll, I don't feel the urge to
stay longer on the website. I log in occasionally to the website just for
checking the notification and friend requests.

Coming to the media content consumed by me, these are the movies that I watched
this year. I did a lousy job logging this stuff, so this data is not
comprehensive. Of course, I watched a lot more movies than this.

![Movies in 2020](/images/posts/2020_movies_watched.jpg "Movies in 2020")

I watched many web series during the July-October period. I can recall a few
right now - Sacred Games 1 and 2, She, Flesh, Bard of Blood, Mirzapur 1 and 2,
The Witcher, Sex Education, and Paatal Lok. In short, I wasted a lot of time
watching useless content. Sensory satisfaction, peer pressure, and the urge to
run away from my boredom are to blame for this binge-watching time.

I am using [Letterboxd](https://letterboxd.com/yagr/) to log the movies, but
there does not seem to be a _free_ service that offers both movies and web
series logging. I wish somebody will make one in 2021.

I use an Android phone and use Digital Wellbeing to monitor my phone usage.
Unfortunately, I can't export my usage data from the Digital Wellbeing app. This
data gets lost because I switch ROMs frequently. However, according to my
liberal estimate, I was able to keep my per day phone usage under 4 hours on
most of the days. There were some outliers, but mostly, my phone addiction was
relatively under control. However, I would have liked to keep it around 3 hours
per day.

## What in 2021?

This section is a new addition to this year's review. I usually don't set
explicit targets and certainly don't share them in public. So this is something
different. I am sharing my goals here. I will take this as a benchmark when I
sit to write my year review for 2021. I am hoping for at least a 60% success
rate.

- **Publish six long-form essays** - The plan is to learn the skill of
  articulating thoughts. I don't have any particular topic in mind. Perhaps a
  mix of History, Political Science and Tech. It can be in the form of essays or
  an explanatory post, or anything else. Ideally, every two months.
- **Read five fiction books** - To learn how other people write fantasy. I hope
  to be able to read it for learning, not just for fun. You can follow my
  progress [here](https://www.goodreads.com/user/show/63354397-yash).
- **Sleep at proper times** - Now that majority of my work meetings are expected
  to get scheduled during IST, I will try to sleep by 10 PM and sleep for at
  least 8 hours every day. I am aiming for an 80% success rate in this aspect.
- **Phone Usage** - Keep it under 3.5 hours per day (Aiming for 80% success)
- **Write a Journal** - I have tried it earlier also but failed. This year, I
  will try to document only important events in my life. At least once a month
  should be good enough. The more the merrier!
- **Regular exercise** - I need to reduce my BMI to 22 from 23.3. That requires
  me to shed at least 4 kgs of weight.
  - Weekend running (Aiming to do it on 50/104 weekends, accounting for winters)
  - Mild 15-minute exercises at home two days a week (Aiming for 80% success)
  - Meditation on the two days of the week (Aiming for 90% success)
- ██████ (redacted) - I want to achieve this one badly.

**Note**: A number of these goals depend on how many more months I get to spend
at home, after June.

---

2020 was quite a year. I hope humanity has learned its lessons. While
industrialization and globalization have brought us a couple of hours away from
each other, it has become equally easy for pathogens and germs to travel and
reach farther ends of the world. I like to equate this situation to the
disease-carrying Europeans who went to the Americas in the 17th century. Nations
could practice some carefulness and proactivity in dealing with such problems.
It is not the last pandemic to ravage the world, for sure.

_I expect to achieve some of my goals in 2021, but I won't deny a potential role
of luck or chance (whatever you like to call it). Hopefully, the gods of chance
will be on my side._
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Two Years at Cisco]]></title>
        <id>https://v2.yashagarwal.in/blog/two-years-at-cisco</id>
        <link href="https://v2.yashagarwal.in/blog/two-years-at-cisco"/>
        <updated>2020-09-16T16:33:46.000Z</updated>
        <content type="html"><![CDATA[
I completed two years at Cisco in August recently. I think it is a good time to
jot down my learnings and experiences from the past two years. It was my first
corporate job; however, I did not land up in a typical software development job.
Hence, my experiences are quite different and unique in a sense.

I joined Cisco in 2018. As it usually happens with university recruits, I was
also randomly assigned to a team in the Office of CTO in Security Business Group
(SBG) in Cisco. I got assigned to a non-product team that worked in a
semi-research environment to develop PoCs demonstrating the integration of
future-looking technologies with the existing Cisco portfolio. The nature of
this work gave me some exciting skills and exposure to latest trends in
industry, but it came with its own set of disadvantages. I will discuss some of
them at the end of this article.

## Take Ownership of your work

Every member worked on a reasonably independent project in my team, directly
supervised by a Principal Engineer or a Technical Lead. Most of my superiors
(including my manager) were located in the USA, so there were many early-night
meetings involved. This also meant that nobody watched (micromanaged 🙊) me, and
I was given quite a bit of autonomy. I really appreciate this aspect.

I learned how to come out of a problem when there is nobody to help or guide
you. Of course, I asked for help whenever needed; the freedom I enjoyed at work
was unparalleled.

During two years, there were many occasions when some of my design and
development choices were questioned. I successfully defended some of them and
had to change the others. In the process, I learned the caveats in my
understanding and the importance of others' perspectives while solving difficult
problems.

## Developers should have experience with operations

As I mentioned above, most of my projects were individual projects. Naturally,
the responsibility of setting up and maintenance of the build-environment also
fell on my shoulders. My experience with Linux system administration from
college time came to my rescue here. In the process, I learned how invaluable
the skills of DevOps can be for a developer.

There is a lot that I don't know yet, but my basics have grown strong enough to
grasp any new technology in a reasonable amount of time over the past two years.

## Communications

I have never been a good speaker, and talking to strangers has been one of my
weakest skills. After joining Cisco, this aspect of my personality has changed
considerably. Attending regular meetings and speaking about my ideas and work
gave me confidence. There are still some caveats with my public speaking skills.
I hope that I would be able to overcome these challenges with more experience.

## Innovation

The industry provides you access to the best minds in your field. You get to
meet wise people working and using their knowledge and expertise to generate
ideas that can change the world (or at least the industry). It motivates you to
compete with them. Although I have been unable to generate any patentable idea
in the past two years, I have been invited to participate in the discussions,
which led to patent applications. My biggest takeaway from these discussions was
that breadth is more useful than depth when it comes to idea generation. Knowing
various fields and connecting two seemingly different domains is a skill whose
importance cannot be overemphasized.

Another thing I learned is that aiming for perfection doesn't help anyone. To
keep waiting for that best idea to pop up in your mind is illusionary and will
never happen. I have been a victim of this tendency to perfectionism the whole
of my life. For the past couple of months, I have been actively trying to avoid
this habit. My inconsistency in regularly writing on this blog can also be
attributed to my search for the _ideal_ blog post.

In my opinion, quantity is better than quality. The same is true with the
generation of ideas. If you keep waiting that you will get the ultimate idea one
day, believe me, it will never happen.

## Take a step back & rethink

It happened quite a few times that I started looking for a solution to a problem
in one direction. After spending a considerable amount of time, I figured out
that the direction was wrong or worse, my understanding of the problem was
wrong. In such situations, it is better to backtrack and think again. It also
helps to ask someone for help. Sometimes, others can give you a different
perspective that you might not be able to see.

## Don't hesitate to brag about yourself

When I joined Cisco, my colleagues suggested me to set up 1-1 with my manager to
stay in touch with him and showcase my work. I hesitated. I thought that what is
the point of talking about my work when it is visible to everybody through
weekly meetings. Now I understand, it is such a crucial step which shouldn't be
ignored at all. Keep a [brag](https://jvns.ca/blog/brag-documents/) document and
use it to keep records of your work, achievements, and accomplishments. I never
needed it till now, but I plan to use it in the future.

---

Coming to downsides, I have only one qualm. As I mentioned above, my team was
not a product team. So I missed out on some of the necessary product development
experience. I believe that having some experience developing and shipping
production-ready code is an absolute requirement to move towards my career
goals. Thankfully, I have switched my team now, and now I will be working on a
full-fledged security offering of Cisco.

---

So, these are some of my insights from the past two years at Cisco. I want to
share a lot of other thoughts, but their time hasn't come yet. I will definitely
share more of these as I spend more time in the industry and tech.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cassandra - A Decentralized Structured Storage System]]></title>
        <id>https://v2.yashagarwal.in/blog/cassandra-a-decentralized-structured-storage-system</id>
        <link href="https://v2.yashagarwal.in/blog/cassandra-a-decentralized-structured-storage-system"/>
        <updated>2020-05-08T01:51:55.000Z</updated>
        <content type="html"><![CDATA[
Cassandra is a distributed storage system that can spread over thousands of
nodes and store terabytes of structured data. Cassandra was developed at
Facebook to solve performance issues during searches in Facebook Inbox.
Cassandra can provide a highly available service without a single point of
failure.

Cassandra borrows some of its architecture choices from Google's
[BigTable](https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf)
and Amazon's
[Dynamo](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf).
In some ways, Cassandra resembles the traditional databases, yet it does not
support the relational data model completely.

## Data Model

Cassandra uses a tabular data structure like relational databases. A table in
Cassandra is a distributed multi-dimensional map indexed by a key. Every row
operation is atomic per replica, no matter how many columns are being read or
written into. Cassandra groups columns into sets called column family. A column
family is of two types - Simple and Super (column family within column family).
Cassandra can sort columns using name or time. Time-based sorting is useful when
used in a setting like Inbox searches where most recent messages should be
displayed first.

Cassandra provides following methods -

1. $insert(table, key, rowMutation)$
2. $get(table, key, tableName)$
3. $delete(table, key, tableName)$

## Architecture

A data storage system should satisfy some requirements - data persistence,
scalability, membership, failure detection and handling, data partitioning,
request routing, among others. Cassandra uses a variety of techniques to solve
these issues.

### Routing

Any node can attend an incoming read/write request with a key. Each node in the
Cassandra cluster knows about other nodes. The serving node uses this
information and the request's key to determine the route of the request to the
appropriate node.

In the case of write requests, the system routes the request to all replicas and
waits for a quorum of replicas to acknowledge the completion of the writes.

For reads, the system either routes the requests to the nearest replica with
required data or forwards the request to all the replicas and waits for a quorum
of responses before replying. Which method, the system utilizes, depends on the
consistency requirements of the client.

### Partitioning

Cassandra uses
[consistent hashing](https://en.wikipedia.org/wiki/Consistent_hashing) with an
order-preserving hash. The consistent hash function is used to hash the data key
to generate identifiers. The output range of the hash function is treated as a
ring (the largest hash value generated wraps around the smallest hash value).
Each node is assigned a random hash, which becomes its position on the ring.
Each node is responsible for the region in the ring between it and its
predecessor node.

For each data item with a key, its hash is generated using the key. The ring is
traversed clockwise, and the first node with the position hash value greater
than the item's hash value is assigned to the data item. This node is deemed the
coordinator of the key.

However, consistent hashing can result in an imbalance in the load distribution
and non-uniformity of data distribution. Cassandra solves these issues by
periodically analyzing the load information in the ring and repositioning the
lightly loaded nodes on the ring to alleviate high load nodes.

### Replication

Each data item is replicated at $N$ nodes in the ring. As mentioned above, each
data item's key is assigned to a coordinator node, which is responsible for the
replication of data items falling within its range (the region between it and
its predecessor node). For fault tolerance, in addition to locally storing keys,
the coordinator node replicates these keys at the $(N-1)$ replicas on the ring.
Replication policies such as Rack aware, Rack unaware, Datacenter aware are used
for this purpose.

### Leader Election

Cassandra uses Zookeeper for leader election and fault tolerance. Whenever a new
node joins the cluster, it contacts the leader who tells them what ranges the
node is responsible for. The metadata about ranges of a node is cached locally
as well as on the Zookeeper instance.

### Membership

Cassandra uses Scuttlebutt - an anti-entropy Gossip based protocol to
disseminate the membership information inside the ring. Whenever a new node
joins the system, it calculates a token for itself. This token is gossiped
around the cluster. That's how each node in the system knows about the
membership and positions of other nodes in the system.

### Failure Detection

Failure detection is a mechanism by which a node can locally determine if any
other node in the system is up or down. Cassandra uses a modified version of
$\phi$-Accrual Failure Detector. The basic idea is that the failure detection
module emits the suspicion level of a node instead of a binary up/down status.
This suspicion level is $\phi$. The idea is to represent $\phi$ on a dynamically
adjustable scale, which reflects network and load conditions at the monitored
nodes.

Every node in the system maintains a sliding window of inter-arrival times of
gossip messages from other nodes in the cluster. The distribution of these
inter-arrival times is determined, and $\phi$ is calculated. Cassandra uses
exponential distribution as an approximation for determining $\phi$. The
original $\phi$-Accrual Failure Detection Algorithm used Gaussian distribution.

### Scaling

Whenever a new node joins the system, its token is generated such that it falls
within the range of an existing heavily loaded node. This results in the new
node splitting the range of the old node. The old node transfers some of its
data to the new node using kernel-kernel copying techniques.

### Local Persistence

Cassandra uses a commit log as well as an in-memory data structure to store the
data. Each write is first committed to the commit log. Only after successful
write into the commit log, the data is saved in the in-memory data structure.
When the in-memory data structure crosses a predefined threshold, it is dumped
to the disk along with an index file for fast lookups. A merge process runs
periodically to merge these disk files.

A read operation first queries the in-memory store. If data is not found there,
then a disk lookup is required. To avoid looking into multiple files, a bloom
filter, summarizing the keys in the file, is also used. The bloom filter can
also be used to check the key existence.

Paper Link:-
[Cassandra - A Decentralized Structured Storage System](http://www.cs.cornell.edu/Projects/ladis2009/papers/Lakshman-ladis2009.PDF)
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Epidemic/Gossip Protocols]]></title>
        <id>https://v2.yashagarwal.in/blog/epidemic-gossip-protocol</id>
        <link href="https://v2.yashagarwal.in/blog/epidemic-gossip-protocol"/>
        <updated>2020-04-14T03:08:15.000Z</updated>
        <content type="html"><![CDATA[
Last week, while reading the book
[Designing data-intensive applications](https://www.goodreads.com/book/show/34646879-designing-data-intensive-applications),
I came across the term "Gossip Protocols." The title was quite intriguing; hence
I search for it on Google. It turns out that it is a communication protocol. It
is sometimes also called the "Epidemic Protocol."

We are facing an ongoing pandemic called COVID-19. The term "Epidemic Protocol"
caught my attention, and I started wondering how the knowledge of epidemics is
going to be useful in computer systems. It turns out; these protocols try to
emulate the spread of a virus to effectively communicate the information to all
nodes in a distributed network.

A virus spread quickly and robustly. Our goal in a distributed system is to
spread the information/updates as quickly as possible without burdening the
network. The epidemic protocols try to bring these ideas from epidemiology to
distributed systems.

I use both terms (Gossip and Epidemic) interchangeably in this post.

## Analogy to a real epidemic

Let' take a close look at how a virus spreads. I'll explain it using a small
sample of five people. We assume that, initially, none of these people is
infected. Now, because of some external factors, one of these (say $A$) got
infected with the virus. We say that $A$ is **_infected_**, and the remaining
four people are **_susceptible_** to infection. $A$ followed the advice of
doctors and isolated itself from the group. Now we say that $A$ is **_removed_**
(either because he has the infection, but is not spreading it, or because he is
recovered).

Now, let's extend this analogy to a network. In a network, we have multiple
nodes. These nodes are classified using the terms -- infected, susceptible, and
removed. The infected nodes try to spread some information by periodically
selecting some peer nodes from the network. If a node is susceptible, that is,
it does not know the said information, then after the selection and transmission
of information by an infected node, the susceptible node also gets infected and
starts spreading the information. A node is said to be removed, if it already
knows the said information, but is not spreading it because, for example, all
its peers already know the information, so there is no need to keep spreading it
-- the so-called herd immunity).

## Some theory

The concept of the Gossip Protocol is not something new. The 1987
[paper](https://dl.acm.org/doi/10.1145/41840.41841) Epidemic algorithms for
replicated database maintenance is considered seminal on this topic. The Gossip
Protocols were initially used to maintain consistency in replicated databases
for efficient data communication. Later, these protocols found their usage in
other areas such as service discovery in a distributed environment and
maintaining node memberships as well.

Usually, these protocols work as follows -

1. A node ($A$) in the network randomly selects another node with which it wants
   to share information. Here, the assumption is that each node in the network
   either maintains a list of all the other nodes or gets the information from a
   centralized server.
2. On receipt of information, the receiving node ($B$) processes the
   information.
3. In the next round of this process, both $A$ and $B$ again select nodes
   randomly and transmit the information.
4. These steps repeat periodically until the information is disseminated to
   every node in the network.

## Methods

In the paper mentioned above, two schemes of epidemic protocols were analyzed -

### Anti-entropy

In this scheme, a node $p$ randomly contacts a random partner $q$ from the
current population. The nodes $p$ and $q$ engage in information exchange to
resolve any differences between them. The updates known to $p$ but not known to
$q$ are transferred using different strategies (push, pull, and push-pull).

As it turns out, anti-entropy requires significant network bandwidth, because it
needs to send the complete database contents to other nodes for resolving any
differences. There are many approaches, such as sharing checksums, Merkel trees,
maintaining a recent update list, etc. that can be used to reduce the bandwidth
requirements in the anti-entropy algorithm. These strategies allow the sending
node to know what updates the receiving nodes require to become consistent.

It can be proven that this algorithm guarantees the eventual dissemination of
information. The number of updates sent in this scheme is not bounded, so there
is no termination.

This scheme is equivalent to the SI model (simple epidemic) from epidemiology.
The term SI stands for susceptible-infected (same as explained above). A node is
always susceptible or infected.

### Rumor mongering

As the name suggests, this scheme works similarly to how rumors spread.
Initially, all nodes are ignorant of a rumor. When a node learns about some
updates, it becomes a "hot rumor." While a node holds a hot rumor, it
periodically chooses another node at random and pushes the rumor to the other
site. When a node has tried to share a hot rumor with too many nodes that have
already seen it, the node stops treating the rumor as hot and retains the update
without propagating it further. Rumor-mongering requires very less network
bandwidth because it needs to send only recent updates to other nodes.

The equivalent of this in epidemiology is the SIR model (complex epidemic),
which stands for susceptible-infected-removed. A node can be susceptible or
infected or removed.

Because of the removal of nodes, the number of messages transmitted in this
algorithm is bounded. However, because of this, there is a slight chance that
some updates might not reach all nodes. So it does not guarantee eventual
consistency.

There are two strategies to decide when a node should be removed -
{/* TODO: - Random - Removed with probability $\frac{1}{k}$ after each unsuccessful attempt. */}
{/* TODO: - Counter - Removed after $k$ unnecessary contacts. */}

The analysis of gossip algorithms focuses on designing strategies on how to
select the best peer group to share the information with.

If you want to get started with this topic, here I recommend some papers that
are quite fundamental when it comes to an understanding of how gossiping works:

1. [Epidemic Algorithms For Replicated Database Maintenance](https://dl.acm.org/doi/10.1145/41840.41841)
2. [Gossiping in Distributed Systems](https://www.distributed-systems.net/my-data/papers/2007.osr.pdf)
3. [Randomized Rumor Spreading](http://archive.cone.informatik.uni-freiburg.de/pubs/rumor.pdf)
4. [The Promise, and Limitations, of Gossip Protocols](https://research.cs.cornell.edu/projects/Quicksilver/public_pdfs/2007PromiseAndLimitations.pdf)
5. [Gossip-based Protocols for Large-scale Distributed Systems](http://www.inf.u-szeged.hu/~jelasity/dr/doktori-mu.pdf) -
   Read the first chapter of this book to get a basic understanding of Gossip
   protocols)
6. [A gossip protocol simulator](https://flopezluis.github.io/gossip-simulator/)

---

**P.S.** - This is my first attempt to read and summarize CS research papers. I
have intentionally covered only a small part (first few pages) of the paper
(first reference in the above list) here, as I am still figuring out the best
way to read and summarise. I am confident that with time and practice, I will
get better.

If you find any scope of improvement in current content, please let me know
through email or comment box below.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[2019 - Year in Review]]></title>
        <id>https://v2.yashagarwal.in/blog/2019-year-in-review</id>
        <link href="https://v2.yashagarwal.in/blog/2019-year-in-review"/>
        <updated>2020-03-31T06:09:47.000Z</updated>
        <content type="html"><![CDATA[
It has been three months since 2020 started. I was not able to keep up with my
yearly habit of posting year reviews due to some reasons. One primary reason
behind my negligence is my disinterest in writing on this blog. I felt that it
was because the old layout of this blog had been too recurrent for me. So, I
decided to fix that issue before thinking about writing.

The year 2019 was not a great year for me on many fronts. It was a year that
reminded me of my limitations and brought me out of the bubble, that self-help
books created for me. In retrospection, I find that I started a lot of things,
with the intention of learning, but couldn't achieve any of the targets.

Like, I structure these posts every year, I have divided this post too in many
sections. It makes it easier for me to focus on various aspects of my life in
the past year. I will start with the best parts of my life.

## Reading

I had decided to read 26 books in the year. I finished the year with 28 books.
Out of 12 months, I did not read any book in January, November, and December. I
finished two of the fiction series that I wanted to read for years - Harry
Potter, and Percy Jackson. These two books are the reasons that I was able to
finish 28 books in 9 months. It took me very little time to finish these book
series. Other books (mostly non-fiction) took me ages to complete.

I am not sure if I am getting any value out of non-fiction books _right now_. I
do not take notes and forget most of the lessons in a few days. Not sure if this
is the right strategy while reading such books. Hence I have decided that I will
reduce the number of non-fiction books _for some time_ and put more attention to
technical publications and CS books.

Though I am confident that my note-taking skills will not help in reading
technical books either, I do hope to improve over time.

One of my reading goals from last year was to read a research paper every 15
days. I succeeded in the first quarter of the year and failed miserably after
that. I started with a good intention and kept reading for some months. Then
self-doubts began popping out. _What value am I getting out of this?_, was the
question in my mind. I started this exercise because I have specific goals in my
mind, and I wanted to improve myself academically. But when you are not able to
answer such a question even to yourself, then something is wrong.

This failure has taught me some crucial lessons. I tend to start things without
thinking about the end goal. It is the right approach when _learnings_ from the
process is more important than the result. But I was not able to focus on either
of them. I lost my focus when I realized this.

I have come to understand the value of proper note-taking. I have read so many
good books, but I do not remember any lessons from these books, because -

- I read passively and try to finish the book as quickly as possible.
- I did not try to implement the lessons in my day to day life while reading.

I lost my interest in reading news and blog articles also. I lost my interest
from social media and, in general, the Internet entirely. I preferred to sleep
as much as possible. That has its side-effects. Read on.

## Blogging and Writing

I had decided to write regularly in 2019. I didn't. It seems that failing was a
norm for me in 2019. This section was my worst hit interest in 2019. Somehow, I
was not able to gather the concentration required for writing. I used to get
sudden motivations for a few days, I wrote during those periods. The rest of the
time, I just thought that I should write. I think I suffered from the so-called
_Writer's Block_.

## Health

My analysis says that all my failures last year can be traced to this section. I
was sick for almost a quarter of the year. Repeatedly getting ill and the time
required for recovery took a toll on my body and mind. I lost all my focus and
will power to do anything.

The exercise was again an issue. I certainly put more effort than last year, but
that effort was scattered throughout the year, for small periods. So, I do not
notice much difference. However, I continued to walk whenever I got time.

## Work

It was not a very exciting year on the work front. I continued to work in Cisco
this year. The work was neither very interesting nor very dull. The nature of my
job is such that the exciting work shows up from time to time. With no fixed
deadlines and no fixed way of doing things, it can be quite satisfying and quite
frustrating at times.

## Social Media

I lost my interest in social media altogether. I opened Facebook only to see the
notification once in a while, sometimes after months. I got disillusioned by
Twitter this year, because of the toxic political content there. I was never a
regular user of YouTube anyway, so that was never a concern. However, I went to
great lengths to delete every Google app from my phone, especially Gmail and
YouTube. The email had become a new Facebook for me. I was checking emails every
15 minutes. So I signed out of Google account in my primary browser and
restricted my email activities to a secondary browser. It helped me in keeping
the urge to check email in control.

But this sudden disinterest has created a void in my typical day, which is quite
reasonable given how much my life depends on the Internet. I am yet to figure
out how to fill this void. Reading books did not help, however sleeping and
watching movies helped for sure (however, not without its own set of problems).

## Travel

I was somewhat dissatisfied with myself for not traveling enough. This year, I
had decided to travel extensively. But my health betrayed me. Out of 365 days, I
was able to take the time of 4 days for travel. I went to Coorg and Chikmagalur
with friends. Both trips happened during the wrong weather conditions. But the
circumstances were such that I could not deny to my friends.

## Miscellaneous

My daily routine, more or less, remained the same. Though I couldn't wake up
early in the morning most of the time, the reality is that I was not trying. My
only intention behind waking up early in the morning was to meditate. I did
that, however sporadically.

One other goal in 2019 was to get rid of procrastination. I did not care about
it at all. Somehow, I was too busy fixing other issues in my life, that this
seemed like a minor problem. Anyway, I did not attempt to do anything on a
personal level, where procrastination would affect me. On the work front, at one
point or another, you have to work and show results. So there it was never
apparent. I tried many things to reduce the impact and influence of _technology_
in my life. Although I consider myself successful to an extent, there is still
scope for improvement.

In 2018, I was in full praise for to-do lists and the concept of maintaining
goals. 2019 has busted all those praises. This year, these techniques did not
work for me at all. Anyway, 2019 was one of those times when nothing worked for
me, so this failure does not come as a surprise to me. Though, I still believe
that this is something that can genuinely help me with some of my issues.

---

_If I had written this post at the beginning of the year 2020, I would have
written some wish for the year 2020 at this place, as I always do, but this time
is so gloomy that I am not able to think of anything good. I just pray to God
that everything gets all right soon._

_Being with family during this time, has given me some mental stability. But, it
is also true that facing such circumstances and coming out triumphant, is what
shows the human character._
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic HTTPS Certs Using GoDaddy and Gitlab APIs]]></title>
        <id>https://v2.yashagarwal.in/blog/automatic-https-certs-using-godaddy-and-gitlab-apis</id>
        <link href="https://v2.yashagarwal.in/blog/automatic-https-certs-using-godaddy-and-gitlab-apis"/>
        <updated>2019-07-23T11:10:28.000Z</updated>
        <content type="html"><![CDATA[
Before I start, here is some technical information about my website -

- Hosted on Gitlab and usage its CD for automatic deployment, which is triggered
  on a git commit.
- The domain name registrar is GoDaddy.
- Let's Encrypt as the TLS certificate provider for my domain name.

Let's Encrypt provides certificates for 90 days only, so I was forced to set up
the `certbot` every three months, then generate the certificate and _manually_
deploy the certificates to GitLab. It was frustrating because in three months,
my shell probably will not remember the command I used last time, and I was too
lazy to document the process somewhere.

Then I came across a [project](https://github.com/pallavagarwal07/NamesiloCert),
which was trying to do a similar thing with other domain name registrar. I
thought that this is an excellent setup to adapt and modify it to suit my needs.
So I decided to write my module for automatic deployment of Let's Encrypt
certificates to GitLab.

## How does Let's Encrypt work?

Before Let's Encrypt can generate the certificate for the domain, it requires
the user to prove domain ownership. Let's Encrypt provides two
[methods](https://letsencrypt.org/docs/challenge-types/) to do this task -

- Updating the DNS records of the domain registrar (DNS-01 challenge)
- Adding an HTTP resource under a well-known URI on the website (HTTP-01
  challenge)

Using the second method requires me to add a file on my website, and I did not
want to do that. Moreover, if in the future, I decide to host some other
service, which does not have a website, then this method will fail.

The first method requires that the domain configuration on the domain registrar
is modified. GoDaddy provides a robust API, and it is not difficult to utilize
that API to automate specific tasks. The probability of changing the registrar
is quite low, at least for the next few years. It will be easier to generate the
certificates for any subdomains, as all the subdomains will also be hosted under
the same domain registrar.

## How does the tool work?

So here are the steps:

1. Call `certbot` with all the domain names
2. Invoke GoDaddy API to update the DNS records as indicated by Certbot
3. Wait for 10 minutes for DNS changes to propagate
4. Let `certbot` verify the DNS changes
5. Use the GitLab API to deploy the generated certificates to GitLab pages

### Step 1: Invoking certbot

In step 1, we call `certbot` will the preferred method DNS. We also need to
supply an email id (used by Let's Encrypt to notify domain expiration). The
`EMAIL_ID` environment variable can be used to store the email id of the user.

Certbot runs in an interactive mode by default. It is not desired in a scripted
environment. Certbot also provides mechanisms to deploy the certificates to a
local server automatically, but as we are hosting our website on Gitlab, we do
not want the automatic deployment facility. So we need to invoke the `certbot`
command with `--manual` and `certonly` modes.

```bash
certbot   --manual \
          --preferred-challenges dns \
          --agree-tos \
          --email "${EMAIL_ID}" \
          --no-eff-email \
          --expand \
          --renew-by-default \
          --manual-public-ip-logging-ok \
          --noninteractive \
          --redirect \
          --config-dir ${DIR}/generated/config \
          --work-dir ${DIR}/generated/work \
          --logs-dir ${DIR}/generated/logs \
          --manual-auth-hook ${DIR}/auth_hook.sh \
          -d yashagarwal.in \
          certonly
```

The explanation for most of the flags used in the above command can be found by
running the following command -

```bash
certbot --help
```

The `--manual-auth-hook` flag is worth looking. This hook provides a mechanism
to specify the executable, which can be used to facilitate domain ownership
validation. In this case, the hook points to a script `auth_hook.sh`, which then
calls a Go client, which interacts with GoDaddy API.

### Step 2: Adding DNS entry to GoDaddy DNS manager

Certbot supplies two environment variables `CERTBOT_DOMAIN`, which contains the
domain name to be verified and `CERTBOT_VALIDATION`, which includes a random
string corresponding to `_acme-challenge TXT` entry. What this means is that, if
I have

```text
CERTBOT_DOMAIN=yashagarwal.in
CERTBOT_VALIDATION=6VNg5kDVI_BF1S9N5s74LTBHQnwDpQqKlblKRjIzBwM
```

Then the DNS manager should contain a TXT entry `_acme-challenge.yashagarwal.in`
with the value of `6VNg5kDVI_BF1S9N5s74LTBHQnwDpQqKlblKRjIzBwM`.

The `auth_hook.sh` file calls the Go client with the abovementioned environment
variables. The relevant code can be found
[here](https://github.com/yashhere/GoDaddy-GitLab-Certs/blob/master/auth_hook.sh).

Once all the DNS entries are added, the `auth_hook.sh` script will sleep for 10
minutes. It is to allow DNS changes to propagate throughout the Internet. It is
a random duration as I could not find any GoDaddy support page mentioning the
exact period used by them.

### Step 3: Generation of certificates

Once the `auth_hook.sh` script returns successfully, `certbot` will verify the
DNS records. If the verification is successful, `certbot` will generate the
certificates in `./generated/config/live/{CERTBOT_DOMAIN}` directory.

### Step 4: Deploying the certificates to GitLab

I use the following command to deploy the certificates to Gitlab pages where my
website is hosted -

```bash
curl  -vvv \
      --request PUT \
      --header "Private-Token:${GITLAB_TOKEN}" \
      --form "certificate=@${key_dir}/fullchain.pem" \
      --form "key=@${key_dir}/privkey.pem" \ "https://gitlab.com/api/v4/projects/yashhere%2Fyashhere.gitlab.io/pages/domains/yashagarwal.in"
```

where

```bash
key_dir="./generated/config/live/yashagarwal.in"
```

Moreover, `GITLAB_TOKEN` is an environment variable that contains the API token
generated from the Gitlab settings page.

## Automatic Deployment using Travis CI

It is not automation if I have to run this script manually every three months.
So I created a Travis CI job to automate this process. The job will run every
month and deploy my certificates automatically. It has been four months, and I
have not faced any issues with this setup.

The code for this post can be viewed at
[Github](https://github.com/yashhere/GoDaddy-GitLab-Certs).

Thanks for reading. Cheers :smile:
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Setting Up ModSecurity on Ubuntu]]></title>
        <id>https://v2.yashagarwal.in/blog/setting-up-modsecurity-on-ubuntu</id>
        <link href="https://v2.yashagarwal.in/blog/setting-up-modsecurity-on-ubuntu"/>
        <updated>2019-07-01T12:50:18.000Z</updated>
        <content type="html"><![CDATA[
Recently, I am experimenting with Web Application Firewalls a lot. ModSecurity
is one of them. It is the most famous and useful open-source Web Application
Firewall (WAF) in existence. It is supported by various web servers such as
Apache, Nginx, and IIS.

The job of ModSecurity is to sit in front of the application web server and
check the incoming requests and outgoing responses to filter out malicious
content. It does so by the use of powerful and complex regular expressions.
ModSecurity uses a rule language for its rules. The rule language has variables
and operators defined to aid in the process of parsing HTTP requests.

ModSecurity, in itself, cannot block or allow requests. It is just a rule
engine. It requires rules to operate appropriately. That's where its sister
project, Core Rule Set (CRS), comes into the picture. CRS is a rule set
developed to be used with ModSecurity. It has been in active development for
several years now and is very mature. Together, ModSecurity and CRS form a
formidable defense against the widespread web application attacks.

Now that you know, what a WAF is, let's proceed to install ModSecurity on
Ubuntu. I will be compiling ModSecurity's latest version on Ubuntu 18.04. We
will also configure ModSecurity to use Core Rule Set.

## Installing Dependencies

ModSecurity requires some dependencies to work correctly. Let's install them -

First, upgrade the Ubuntu system.

```sh
sudo apt-get -y update
sudo apt-get -y upgrade
```

Now install the dependencies.

```sh
sudo apt-get -y install git libtool dh-autoreconf pkgconf gawk libcurl4-gnutls-dev libexpat1-dev libpcre3-dev libssl-dev libxml2-dev libyajl-dev zlibc zlib1g-dev libxml2 libpcre++-dev libxml2-dev libgeoip-dev liblmdb-dev lua5.2-dev iputils-ping locales apache2 apache2-dev ca-certificates wget
```

_Optional_: clean up the Ubuntu caches.

```sh
sudo apt-get clean && sudo rm -rf /var/lib/apt/lists/*
```

Install `SSDeep` as well (as done
[here](https://github.com/coreruleset/modsecurity-docker/blob/bf60dcb29fad101c5b90edf272909742e4e85929/v2-apache/Dockerfile))

```sh
cd ~
git clone https://github.com/ssdeep-project/ssdeep
cd ssdeep
./bootstrap
./configure
make
sudo make install
```

## Compiling ModSecurity

Let's clone ModSecurity from Github.

```sh
cd ~
git clone -b v3/master --single-branch https://github.com/SpiderLabs/ModSecurity
cd ModSecurity
git submodule init
git submodule update
./build.sh
./configure
make                # takes ~8 minutes on AWS t2.micro
sudo make install
```

## Compiling ModSecurity-apache connector

To configure it with Apache, we will require ModSecurity-apache connector. Let's
install that as well.

```sh
cd ~
git clone https://github.com/SpiderLabs/ModSecurity-apache
cd ModSecurity-apache
./autogen.sh
./configure --with-libmodsecurity=/usr/local/modsecurity
make
sudo make install
```

## Setting up CRS rules

Now, let's download CRS rule set as well.

```sh
cd ~
git clone -b v3.2/dev https://github.com/SpiderLabs/owasp-modsecurity-crs
sudo mv owasp-modsecurity-crs/ /usr/local/
```

Rename CRS configuration file -

```sh
sudo mv /usr/local/owasp-modsecurity-crs/crs-setup.conf.example /usr/local/owasp-modsecurity-crs/crs-setup.conf
```

## Setting up ModSecurity

Now, we need to create a file in the Apache modules directory, so that Apache
can know, how to activate ModSecurity.

Create `/etc/apache2/mods-enabled/security3.conf` file and paste the following
contents -

```apache
LoadModule security3_module /usr/lib/apache2/modules/mod_security3.so
modsecurity on
modsecurity_rules_file '/etc/apache2/modsec/main.conf'
```

As you can see, the last line in the above code block reference a file
`main.conf` in a folder `modsec`. This folder will not be present by default. We
need to create that.

```sh
sudo mkdir -p /etc/apache2/modsec
```

Setup ModSecurity configuration file -

```sh
# enables Unicode support in ModSecurity
sudo wget -P /etc/apache2/modsec/ https://raw.githubusercontent.com/SpiderLabs/ModSecurity/v3/master/unicode.mapping

sudo wget -P /etc/apache2/modsec/ https://raw.githubusercontent.com/SpiderLabs/ModSecurity/v3/master/modsecurity.conf-recommended
sudo mv /etc/apache2/modsec/modsecurity.conf-recommended /etc/apache2/modsec/modsecurity.conf
```

Change the SecRuleEngine directive in the configuration to change from the
default "detection only" mode to actively dropping malicious traffic.

```sh
sudo sed -i 's/SecRuleEngine DetectionOnly/SecRuleEngine On/' /etc/apache2/modsec/modsecurity.conf
```

Change the location of `modsec_audit.log` file to Apache log directory.

```sh
sudo sed -i 's/SecAuditLog \/var\/log\/modsec_audit.log/SecAuditLog \/var\/log\/apache2\/modsec_audit.log/' /etc/apache2/modsec/modsecurity.conf
```

To configure ModSecurity to use CRS rule set, put the following text in
`/etc/apache2/modsec/main.conf` file.

```apache
Include "/etc/apache2/modsec/modsecurity.conf"
Include "/usr/local/owasp-modsecurity-crs/crs-setup.conf"
Include "/usr/local/owasp-modsecurity-crs/rules/*.conf"
```

Also enable some Apache modules for better functioning of ModSecurity.

```sh
sudo a2enmod unique_id headers rewrite actions dav dav_fs
```

Now restart the Apache server

```sh
sudo systemctl restart apache2
```

## Fixing some common issues

Sometimes, I had encountered errors when ModSecurity was not able to append logs
to its log file. I figured out that ModSecurity did not have enough permissions
to write that file. We can fix this issue quickly.

First, test if you really have this issue or not.

```html
$ curl 'http://localhost/?q=">
<script>
  alert(1)
</script>
'
<!DOCTYPE html PUBLIC "-//IETF//DTD HTML 2.0//EN">
<html>
  <head>
    <title>403 Forbidden</title>
  </head>
  <body>
    <h1>Forbidden</h1>
    <p>You dont have permission to access / on this server.<br /></p>
    <hr />
    <address>Apache/2.4.29 (Ubuntu) Server at localhost Port 80</address>
  </body>
</html>
```

Now go to Apache log directory and check the contents of `modsec_audit.log`
file.

```sh
cd /var/log/apache2
tail modsec_audit.log
```

You should see the following content -

```text
---0LzdyETA---A--
[01/Jul/2019:14:42:41 +0000] 156199216179.666171 127.0.0.1 41824 ip-xxx-xx-xx-xx.ap-south-1.compute.internal 80
---0LzdyETA---B--
GET /?q="><script>alert(1)</script> HTTP/1.1
Host: localhost
User-Agent: curl/7.58.0
Accept: */*

---TqjMwy7h---D--

---TqjMwy7h---F--
HTTP/1.1 403

---TqjMwy7h---H--
ModSecurity: Warning. detected XSS using libinjection. [file "/usr/local/owasp-modsecurity-crs/rules/REQUEST-941-APPLICATION-ATTACK-XSS.conf"] [line "37"] [id "941100"] [rev ""] [msg "XSS Attack Detected via libinjection"] [data "Matched Data: XSS data found within ARGS:q: "><script>alert(1)</script>"] [severity "2"] [ver "OWASP_CRS/3.1.0"] [maturity "0"] [accuracy "0"] [tag "application-multi"] [tag "language-multi"] [tag "platform-multi"] [tag "attack-xss"] [tag "OWASP_CRS/WEB_ATTACK/XSS"] [tag "WASCTC/WASC-8"] [tag "WASCTC/WASC-22"] [tag "OWASP_TOP_10/A3"] [tag "OWASP_AppSensor/IE1"] [tag "CAPEC-242"] [hostname "localhost"] [uri "/"] [unique_id "156198848361.198287"] [ref "v8,27t:utf8toUnicode,t:urlDecodeUni,t:htmlEntityDecode,t:jsDecode,t:cssDecode,t:removeNulls"]
....
....

---TqjMwy7h---I--

---TqjMwy7h---J--

---TqjMwy7h---Z--
```

If you do not see the following content, and the file is empty or it does not
exist, then ModSecurity was not able to open this file for writing. Use the
following fix -

```sh
# find out the user, Apache is running as
apache_user="$(ps -ef | egrep '(httpd|apache2|apache)' | grep -v `whoami` | grep -v root | head -n1 | awk '{print $1}')"
```

Add this user to `adm` group which owns the Apache logs directory in Ubuntu.

```sh
sudo usermod -G adm www-data
```

Now, change the owner of Apache log directory to `apache_user`.

```sh
sudo chown -R $apache_user:$apache_user /var/log/apache2/*
```

Now, ModSecurity should be able to append logs to the file `modsec_audit.log`.

## _Bonus_: Enabling JSON logs

**Note:** Honestly speaking, I was not able to make it work every time. I do not
know what is the issue, but it works with some of the installations, and with
some of the installations, it just doesn't log anything to the `audit`
directory. If anyone has managed to make it work consistently, please let me
know.

**Edit (13/07/2020):** The JSON logging works fine. The issue was that
ModSecurity did not have permission to create subdirectories in the Apache log
directory. I suppose it is something related to SELinux. However, a simple
solution is to add the user under which the Apache process runs to the `adm`
group. It might not be the right solution security-wise. However, from a quick
remediation point of view, it works. Please let me know if you identify any
better solution to fix the problem.

Anyway, if you are like me, who do not like the default ModSecurity log format,
ModSecurity provides an option to generate logs in JSON format as well. To
enable JSON support, the YAJL library should be installed. We already installed
this package when we were installing dependencies, so our ModSecurity setup is
compiled with JSON support. Let us now configure ModSecurity to generate JSON
logs.

Open the `/etc/apache2/modsec/modsecurity.conf` file and find the following
lines -

```apache
SecAuditLogType           Serial
SecAuditLog               /var/log/modsec_audit.log
```

Once you have found the following lines, replace these lines with the following
lines

```apache
SecAuditLogFormat         JSON
SecAuditLogType           Parallel
SecAuditLog               /var/log/apache2/modsec_audit.log
SecAuditLogStorageDir     /var/log/apache2/audit/

SecAuditLogFileMode       0644
SecAuditLogDirMode        0755
```

Restart Apache server

```sh
sudo systemctl restart apache2
```

Now, go to `/var/log/apache2/` directory and create `audit` folder.

```sh
sudo usermod -G adm $apache_user

cd /var/log/apache2
sudo mkdir audit

# make `apache_user` owner of this directory as well...
sudo chown -R $apache_user:$apache_user /var/log/apache2/audit
```

Now, ModSecurity should be able to generate JSON logs in this directory.
ModSecurity generates logs in the following format -

```sh
ubuntu@server:/var/log/apache2$ tree audit
audit
└── 20190701
    ├── 20190701-1132
    │   ├── 20190701-113225-156196094515.868593
    │   └── 20190701-113226-156196094691.154769
    ├── 20190701-1211
    │   ├── 20190701-121122-156196328239.048942
    │   └── 20190701-121122-156196328243.018882

    ....
    ....
```

Now, your site should be relatively more secure than before.

## A warning, though

CRS is known to generate a lot of false-positive when enabled completely. We
have not touched CRS paranoia levels. By default, it is set to paranoia level 1,
which is known to produce false positives rarely, but still, as a measure of
precaution, monitor your site's traffic for some time, and then decide if you
need to disable some of the CRS rules or not.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Travelogue - Chikmagalur]]></title>
        <id>https://v2.yashagarwal.in/blog/travelogue-chikmagalur</id>
        <link href="https://v2.yashagarwal.in/blog/travelogue-chikmagalur"/>
        <updated>2019-06-29T00:40:03.000Z</updated>
        <content type="html"><![CDATA[
South India is blessed with nature throughout the year, but monsoons bring a
different flavor and ethereal quality to some places. Although the rainy season
might not be the best time to travel, there is a certain charm in holidaying
during the downpour.

We (I and my flatmates in Bengaluru) were planning a trip to Chikmagalur since
the beginning of June. One of my friends knows driving, so we decided to rent a
car and drive ourselves to a distance of approximately 250 KMs. We booked the
car through Drivezy. They had promised a Mahindra KUV100, but at the last
moment, that couldn't keep their commitment and gave us a Honda Amaze with
automatic transmission. My friend who was driving had never driven such a car,
so we all got scared of our fate for the next two days, but we decided to go
ahead with it, trusting our friend.

_I too know driving, but like every other aspect of my life, I never gained
enough confidence to go on such a long drive. It was a similar case this time as
well._

The way to Chikmagalur from Bengaluru is the well-maintained NH75 (it has a
total of four tolls, so maintenance is expected). We started early on the
morning of Saturday, 22nd June to avoid Bengaluru's traffic. Nature was
accommodating that day, and the Sun 🌞 stayed hidden behind clouds for most of
our journey. That made our 6-hour drive very enjoyable.

![Somewhere on NH75](/images/posts/2019-06-29/bdiyaFI.jpg "Somewhere on NH75")

We were not in any hurry and wanted to enjoy every moment of our trip to the
fullest. With Punjabi beats playing in our car, we stopped at various places on
the highway.

> Chikmagalur means "The town of the younger daughter" in the Kannada. The town
> is said to have been given as a dowry to the younger daughter of Rukmangada,
> the legendary chief of Sakkarepatna and hence the name.

We stopped at Adyar Ananda Bhavan 🏨 for breakfast. I have tasted sweets from
A2B, and the taste was the best that I could get in the South. So I decided to
eat Masala Dosai and Idli Sambhar there. The food did not disappoint me at all.

After breakfast, we resumed our journey. The first stop in our trip was the
gorgeous Sri Chennakeshava Temple. _Chenna_ means beautiful and _Keshava_ refers
to Lord Vishnu. That should give you an idea, the presiding deity of the temple
is the _Handsome Vishnu_.

The whole premises of the temple is filled with sheer poetry on the walls in the
form of stone sculptures. I was completely mesmerized by its intricate but
aesthetically pleasing carvings.

On the entrance of the temple, a vast golden Gopuram welcomes the devotees. I
was amazed by the level of details on the sculptures engraved on the Gopuram. My
phone's camera will not be able to do justice to this intricate artistry.

![The Gopuram of Sri Chennakeshava Temple](/images/posts/2019-06-29/V6AAfuv.jpg "The Gopuram of Sri Chennakeshava Temple")

The one specialty of the main temple is that it does not feature a dome. I have
not seen any major Hindu temple without a dome over the idol of the main deity.
It seems like an aberration to me, but a welcoming one. A disclaimer, I am not
an architecture buff, so I do not know how correct my facts are here.

The inside of the temple is pretty dark. There are several pillars inside the
temple. Each of the pillars is decorated with various types of sculptors.

![A pillar inside the temple](/images/posts/2019-06-29/jhqoSTE.jpg "A pillar inside the temple")

However, the fascinating thing is at the ceiling. The carvings done on the
ceiling of the temple is just amazing.

![The ceiling of the temple](/images/posts/2019-06-29/074g3uO.jpg "The ceiling of the temple")

As I mentioned above, I am not an architecture buff, so I would not be able to
write a lot about the architecture of the temple. However, enjoy some more
photos.

![A Ganesha statue](/images/posts/2019-06-29/KknscQQ.jpg "A Ganesha statue")

![Carvings on walls](/images/posts/2019-06-29/jb3McxQ.jpg "Carvings on walls")

![Temple](/images/posts/2019-06-29/WQGjwur.jpg "Temple")

![Another temple](/images/posts/2019-06-29/jUYDuQd.jpg "Another temple")

After this temple, we continued our journey to Chikmagalur. We had booked a
homestay option. The name of the homestay was Sunshine Palm Retreat, if I recall
correctly. It was one of the best stays I have experienced on any trip till now.
It was not crowded, the staff was co-operative, and the ambiance was excellent.

![The Silver Palm Retreat Homestay](/images/posts/2019-06-29/JUTwVEN.jpg "The Silver Palm Retreat Homestay")

On the evening of Saturday, we decided to go for our second destination of the
day - the so-called _shooting point_. When we searched on Google maps, we found
one location with a similar name. We started driving in that direction. However,
it turned out that we were going to the wrong place. We tried asking locals, but
language was an issue. Most of the signboards are also in Kannada only. Somehow
we ended up getting on the right track and reached the correct location on time.
After reaching there, Google Maps shows that the place is called Bagmane Sunrise
Point. Even this name does not seem to be right.

As soon we reached there, I realized that all the efforts that we put in
reaching there were worthwhile. It was an open ground area on top of a small
hill at one end of a small village. I started roaming here and there, enjoying
the serenity of nature. I am not a very photogenic person, so I prefer to click
pictures of objects and nature more than standing in front of a camera at
different angles.

![A view at shooting point](/images/posts/2019-06-29/c84g6tX.jpg "A view at shooting point")

We spent around 1.5 hours there and then came back.
[India vs. Afghanistan](https://www.cricbuzz.com/live-cricket-scorecard/20264/ind-vs-afg-match-28-icc-cricket-world-cup-2019)
cricket match was live on TV, and we fixed ourselves in front of the TV for the
next 4 hours. India somehow won that match. Thank God!

The next day, it was raining from the early morning. We did not want to take any
risk by driving on the steep and narrow zig-zag roads. So we dropped our plan to
go to Butter Milk Waterfalls and instead decided to go to Mullayanagiri peaks as
our last destination. We again lost our way, but somehow managed to reach the
place.

It was drizzling there. However, we were at such a high altitude that we had to
bring our sweaters out. Surprisingly, I found vendors selling Maggi there. I was
not expecting the taste to be good, but I was wrong. For that sort of place, the
Maggi was delicious.

{/* TODO: {{< youtube F9SpC8nFF0A >}} */}

Despite the weather conditions, we decided to climb to the top of the hill. As
we were going up, the weather was turning more and bleaker. Out of five of us,
only three managed to reach the top, including me. The view from the top of the
hill was just amazing. Wherever I saw, I saw just the mountain mist. My clothes
were wet, and my spectacles were completely covered in fog.

![An inscription](/images/posts/2019-06-29/WSP3EE6.jpg "An inscription")

I shot a video when we were coming down from the hilltop.

{/* TODO: {{< youtube So_UD2tpRic  >}} */}

<br />

---

To summarise, the timing of this trip was not appropriate, but I do not regret
it. I have gone to other hill stations after the monsoons get over, but it is a
different experience altogether to go in a rainy season. Chikmagalur is worth
more than one visit. Do try to go at an appropriate time if you want to visit
more places.

Thanks for reading. Cheers :smile:
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Go + gRPC + OPA - A Perfect Union - Part 3]]></title>
        <id>https://v2.yashagarwal.in/blog/go-grpc-opa-a-perfect-union-part-3</id>
        <link href="https://v2.yashagarwal.in/blog/go-grpc-opa-a-perfect-union-part-3"/>
        <updated>2019-02-18T01:17:15.000Z</updated>
        <content type="html"><![CDATA[
I finished my last [post](/blog/go-grpc-opa-a-perfect-union-part-2/) with the
following issue -

> Now, here one problem arises, how to make sure that the search results will
> not return any book which the user is not authorized to access. We will solve
> this problem using OPA in the next and last post of this series.

Let's solve this issue now. We will use OPA's declarative language, Rego, to
implement policies which will decide on the basis of some user-provided data,
which all objects are to be returned to the user.

We will also define a list of all the users who are part of this library. Here
we are hardcoding this data, as I did not want to waste my time in implementing
a user registration service, but this functionality is not very important from
our point of view. We will require only one field from this users data - the
`user_type` field. This field will determine what the access level for the user
is. We have already added the `access_level` field in the `Book` definition of
our proto file.

When the user wants to search for a particular book, it will provide its
`user_type` the ISBN of the book to our service. Our service will take that ISBN
and pass it to the OPA server. OPA server already has the `Book` data and the
`User` data. Now it has the required ISBN to query the Book data. The Rego
policy will query the Book data by ISBN. It will also check for the
`access_level` condition. Moreover, after this operation, it will return the
resultant set of books that satisfy both the requirements.

Here is the Rego policy -

```go
package library

import data.books
import data.users
import input

search_books[book] {
  input.book.isbn:= books[i].isbn
  input.user.user_type >= books[i].access_level
  book: books[i]
}

list_all_books[books[i]] {
  input.user.user_type >= books[i].access_level
}
```

The user data is
[here](https://github.com/yashhere/go-library-service/blob/master/OPA/users.json)
and the book data is
[here](https://github.com/yashhere/go-library-service/blob/master/add_books.sh).

A sample `input` request is shown below -

```json
{
  "input": {
    "book": {
      "isbn": "1128959038"
    },
    "user": {
      "user_type": 3
    }
  }
}
```

The `input` is the data that the user is providing. In `search_books` function,
the input ISBN is matched with the ISBN of all books one by one. Then the
resultant set of books is filtered by `user_type` and `access_level` (these two
fields are essentially the same). In the last, the resultant set of books is
assigned to the variable `book` which will be returned to the gRPC service.

The `list_all_books` function is implemented similarly. The only difference is
that we do not need to filter the books by ISBN. Filtering by `access_level` is
enough.

Now our library service is completed. It is a very basic service. The intention
was to show that the decision-making process can be offloaded to the OPA to
reduce the complexity of the services. In this example, the advantages might not
be obvious, but in large production environments, where many services are
running, it can make a significant difference.

The code for this series can be found on my
[Github](https://github.com/yashhere/go-library-service) account.

I hope you liked the article. Share your views and suggestions in the comments.

Thanks for reading. Cheers :)
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Go + gRPC + OPA - A Perfect Union - Part 2]]></title>
        <id>https://v2.yashagarwal.in/blog/go-grpc-opa-a-perfect-union-part-2</id>
        <link href="https://v2.yashagarwal.in/blog/go-grpc-opa-a-perfect-union-part-2"/>
        <updated>2019-02-17T09:14:56.000Z</updated>
        <content type="html"><![CDATA[
In the last [post](/blog/go-grpc-opa-a-perfect-union-part-1/), we discussed
about the structure of our library application. In this post, we will define the
data definitions using protobuf, and then we will use these definitions to
create a Go service. We will also add a REST interface to the service. So let's
get started.

## Defining Proto Definitions

gRPC uses protocol buffers for serializing structured data. To define the
structure of the data that you want to serialize, we use a _proto_ file - it is
a simple text file that contains all the logical pieces of your data in the form
of _messages_, and the methods that will be called over the network. To know
more about the syntax of proto files, visit [this](https://grpc.io/docs/guides/)
link.

I have defined the following proto file -

```go
syntax: "proto3";
package library;
import "google/api/annotations.proto";

service LibraryService {
  rpc ListAllBooks(QueryFormat) returns (Books) {
    option (google.api.http): {
      post : "/listBooks"
      body : "*"
    };
  };
  rpc AddBook(QueryFormat) returns (Response) {
    option (google.api.http): {
      post : "/addBook"
      body : "*"
    };
  };
  rpc SearchBook(QueryFormat) returns (Response) {
    option (google.api.http): {
      post : "/searchBook"
      body : "*"
    };
  };
}

// the library
message Library { Books books: 1; }

message Books { repeated Book books: 1; }

// metadata about a book
message Book {
  string title: 1;
  string author: 2;
  string isbn: 3;
  int32 no_of_copies: 5;
  int32 access_level: 6;
}

// details about a user
message User {
  enum UserType {
    // https://github.com/golang/protobuf/issues/258
    GARBAGE: 0;
    Student: 1;
    Administration: 2;
    Faculty: 3;
  }

  string name: 1;
  int32 id_no: 2;
  UserType user_type: 4;
}

message QueryFormat {
  Book book: 1;
  User user: 2;
}

message Response {
  string action: 1;
  int32 status: 2;
  string message: 3;
  oneof value {
    Book book: 4;
    User user_data: 5;
  }
}

message Empty {}
```

To compile it, run the following commands -

```bash
protoc -I/usr/local/include -I. \
-I$GOPATH/src \
-I$GOPATH/src/github.com/grpc-ecosystem/grpc-gateway/third_party/googleapis \
--go_out=plugins=grpc:. \
api/library.proto
```

```bash
protoc -I/usr/local/include -I. \
  -I$GOPATH/src \
  -I$GOPATH/src/github.com/grpc-ecosystem/grpc-gateway/third_party/googleapis \
  --grpc-gateway_out=logtostderr=true:. \
  api/library.proto
```

It will generate corresponding Golang definitions of the messages and services
defined in the Proto file. These definitions can be used by the server and
client stubs to communicate with each other.

## Implementation of Go service

Now we can start implementing the code for our services `AddBook()`,
`ListAllBooks()` and `SearchBook()`. It is going to be a very naive
implementation of a library system, but it will be sufficient to learn all the
concepts.

My implementation of the server stub is hosted
[here](https://github.com/yashhere/go-library-service/blob/master/pkg/librarylib/server.go).
A basic flow diagram of this implementation will look like this -

![Architecture](/images/posts/OPA_Service_Flow_Diagram.jpeg "Architecture")

The gRPC server will listen on port `:50051`, and a REST HTTP server will listen
on port `:8181`. The OPA server is running on port `:8182`. The REST server is
implemented using
[gRPC-Gateway](https://github.com/grpc-ecosystem/grpc-gateway). There are three
methods - `AddBook()`, `ListAllBooks()`, and `SearchBook()`. These methods can
be called using either gRPC methods or using the REST endpoints `/addBook`,
`/listBooks` and `/searchBook`. By design, the library gRPC service will not
implement the authentication part of the service. The main purpose of using gRPC
here is to provide a scalable and secure medium where all the communication
between client and server is happening in binary format, which is slightly more
secure than the traditional mediums. In the current form, this gRPC server will
accept requests from everyone and execute the desired functions. That is not
desirable. What if a student tries to add a book to the library. Only Admins
should be allowed to execute such functions. What if someone who is not a
student of the University tries to access the service. How to stop them?

There are two steps to solve this issue -

1. **Authentication** - It mainly deals with the question - who are you? It is a
   way to gain access to the system by verifying your identity. In our case, a
   user will provide its username and password to access the library service.
   Without this authentication, the user will not be able to access the system.
   We will not be implementing authentication functionality in our application.

2. **Authorization** - It deals with the question - which resources are you
   allowed to use? OPA can be used here to define various rights based on the
   access levels of the users.

If you have noticed, I have defined an `access_level` field in the proto
definition of the `Book`. This field will tell us what is the minimum access
level required for a user to access this book.

Again, in the proto definition of the `User`, I have defined a `user_type`
field. This field will serve as an indicator of the access rights of the user.
In the real world, these access rights will be decided after the user has
authenticated herself to the system, but here, we will hardcode the access
rights.

So, only users with access rights equal to `Administration` will be allowed to
add books to the system. Here we do not care who the user is. If the user is
supplying the correct access right, she will be allowed to operate. The
authentication logic in real-world scenarios will determine the _who_ part.

There are some books in the library, which have access rights equal to that of a
`Faculty`. It means that only faculties will be allowed to access those books.
The students will not be able to access these books, even while searching for
books using ISBN. This kind of mechanism can be implemented using OPA very
quickly. We will see the implementation of the OPA part in the next post.

While querying the service, users are required to supply their identity (at
least `user_type`) and the book ISBN if they are searching for some book. The
administrators are supposed to provide the name, author, access level, number of
copies, and ISBN while adding the books. I have not added the error checking
functionality in the code, but it should be easy enough to implement such
functionality.

The
[main.go](https://github.com/yashhere/go-library-service/blob/master/cmd/main.go)
file is the starting point of this service. It will spawn two servers in two Go
Routines. Ideally, some synchronization mechanisms should be implemented in the
code to avoid race conditions in some cases - for example, what will happen if
two or more clients are trying to add the same book simultaneously. Here in our
case, nothing serious will happen, as OPA will take only one book per ISBN, and
discard all the other books with the same ISBN even if the other metadata is
different (I designed the service in this way to keep the code easy enough to
understand), but if there are other operations like DeleteBook and IssueBook,
then the race conditions can cause issues.

In the `AddBook()` function, the user provided book details will be sent to the
OPA server using a REST call. OPA will store this information in its in-memory
store at a unique place determined by the ISBN of the book. In actual cases, the
data should be stored in some persistent storage, such as a DB. OPA will take
the information from the DB. Again, to keep the implementation easy enough to
understand, we are not using any such persistent storage. If any other book with
different metadata but the same ISBN comes, then OPA will overwrite the existing
book with the new one.

In the `SearchBook()` function, the user will provide the ISBN of the desired
book. The gRPC service will call the OPA using REST API and find if any such
book exists or not.

The `ListAllBooks()` is different in the way that it does not need any ISBN.

Now, here one problem arises, how to make sure that the search results will not
return any book which the user is not authorized to access. We will solve this
problem using OPA in the next and last post of this series.

I hope that this post was helpful. If you have any doubts or want to say
anything else, please comment. It will be a great motivation and appreciation
for me.

Thanks for reading. Cheers :smile:
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Go + gRPC + OPA - A Perfect Union - Part 1]]></title>
        <id>https://v2.yashagarwal.in/blog/go-grpc-opa-a-perfect-union-part-1</id>
        <link href="https://v2.yashagarwal.in/blog/go-grpc-opa-a-perfect-union-part-1"/>
        <updated>2019-02-10T08:59:08.000Z</updated>
        <content type="html"><![CDATA[
**TL;DR** -- In a series of blog posts, I will be implementing a simple library
application supporting both gRPC and REST interfaces using Go, gRPC, and OPA. My
approach might not be the most optimal one, but I am learning these technologies
currently. Please give your valuable suggestions and be kind :)

I have been learning the basics of microservices and Golang lately. On the work
front, I got a chance to work on Go, gRPC, and Open Policy Agent as my first
professional project. In this post, I will be demonstrating what I learned in
the last few months. We will be implementing a simple gRPC based library
service, which will be able to serve requests using both gRPC and REST calls. It
will also incorporate the Open Policy Agent (OPA) to provide the authorization
to users. Let's begin with a quick introduction to gRPC and OPA.

## gRPC

gRPC is Google's implementation for Remote Procedure Calls(RPC). RPC is mainly
used in building scalable distributed systems. While REST has a limited set of
verbs, RPC can define any function calls, including synchronous and asynchronous
calls.

In gRPC, the client can make procedure calls as if the requests are made to some
local function. However, the underlying client stub (auto-generated) will send
the call to the server. The server will have a similar server stub, which will
be able to handle the requests coming from the client. The server will send the
response to the client using similar mechanisms over the network. All the
communication is serialized to binary format, so it is ideal for distributed
systems as binary format tends to be on the faster side for large amounts of
data.

For more info about gRPC, visit the official [website](https://grpc.io/).

## Open Policy Agent (OPA)

OPA gives us the ability to define a fine-grained policy control mechanism.
However, I think the most critical benefit of using OPA is that it gives you the
ability to decouple your services and the definition of policies from the
enforcement of it.

There are mainly two parts of OPA -

1. A JSON document store where you can define anything from your users, access
   roles, permission levels, etc.
2. A policy is written in a declarative language. This policy gives you new
   derivative data from the original JSON document store evaluated by the
   policy. The declarative language is called Rego, and these policies are also
   documents that generate results according to the defined policy. The users
   query these results.

This info will be sufficient for our use case. More info about it can be found
at the official [website](https://www.openpolicyagent.org/).

## The skeleton of our Application

We will be building a command-line library application. This application will
support adding, deleting, searching, issuing, and returning of books. There are
three types of users -- student, faculties, and staff. Not all users have a
similar kind of access level. There are some books which are only reserved for
students, and some are exclusively reserved for faculties and so on.

I think emulating the
[library](https://harrypotter.fandom.com/wiki/Hogwarts_Library) at Hogwarts will
be a good idea here. Students and ordinary people were not allowed inside the
restricted section of the library. We will emulate that restricted section using
the authorization mechanisms provided by OPA.

The gRPC protocol will handle the communications part in our app, but not
everyone in Hogwarts is using gRPC. Wizards are still in love with REST (not a
bad thing, though), so we will provide them alike the REST interface to interact
with our service. We do not want to face the wrath of the wizards, after all.

OPA can either be used as a standalone application or be embedded in the Go
service as well. Both approaches have their pros and cons. I have decided to use
OPA as an independent service, as it will be more comfortable that way for us to
push authorization data and policies to it if such a need arises in the future.

One more issue remains - where to store the added books. Shall we persist them?
In practical scenarios, persistence is always a good idea, but here I do not
want to complicate things too much. We could use any Object storage servers
(e.g., Minio) to store the JSON data generated from our gRPC methods, but that
will unnecessarily add complexity to our simple scenario. Wizards do not like
complicate stuff, you know!

In the next posts, we will define our gRPC proto file and build the Go service
around it. Then we will add a REST interface to our service for simple CRUD
operations in our application. Then we will add OPA authorization to restrict
our users from adding and viewing books which they are not supposed to access.

Thank you for reading. Cheers 😊
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[2018 - Year in Review]]></title>
        <id>https://v2.yashagarwal.in/blog/2018-year-in-review</id>
        <link href="https://v2.yashagarwal.in/blog/2018-year-in-review"/>
        <updated>2018-12-31T16:32:08.000Z</updated>
        <content type="html"><![CDATA[
The year 2018 has been quite a roller coaster year for me. I saw many ups and
downs, many successes, and many failures faced many challenges on the personal
front and struggled to keep myself on track. I have been working hard on
improving my lifestyle (not materialistically) for the last few years, and the
benefits have begun to show up now. This year was a pinnacle in that aspect. A
lot of micro changes happened in my life this year.

I often read my blog posts from last year. Reading these posts give me a good
feeling about the improvements that I could bring in myself during the previous
three years. Writing year [reviews](/blog/2017-the-best-till-now/) and posts
like [this](/blog/beginning-a-new-journey/),
[this](/blog/mistakes-that-i-made-in-nitc/) and
[this](/blog/deactivated-my-fb-account/) serve as documents of my deeds from
past for my future. It helps me in not repeating the same mistakes. As a human
being, I cannot run away from committing mistakes, but I can always make sure
that I do not repeat the same mistakes.

> Those who cannot remember the past are condemned to repeat it.

## Blogging & Writing

I had set a target to write 15 blog articles at the beginning of this year. In
the end, I managed to achieve this goal. I managed to write 17 blog posts and
six book reviews. My blog managed to get much traffic this year, mainly thanks
to some of my technical posts.

I got some good responses from people about my technical blog posts. My aim to
start writing technical posts was to keep an account of what I learn. It feels
very nice when I go back to my posts to read how I did something last time. So I
consider myself successful that at least I could benefit from my writing.

Though, in 2018, after leaving college, the frequency of technical posts on this
blog has dipped to almost zero. It is probably because I am not exploring enough
after joining the corporate world. In college, I used Linux all the time, but
now it is nearly four months since I last booted Linux in my system. I think it
is yet another phase of my learning, and I will take some time adjusting with
this. I have some _lovely_ technical post ideas, and I hope that I will be able
to articulate them soon next year.

## Reading

For most of the year, I did not pay any heed to books, and I was never very
interested in buying books. However, at the end of October, I purchased a Kindle
Paperwhite. I consider this to be the
[best](https://twitter.com/yash__here/status/1075396841267752963) investment
done by me this year. Since buying it, I have read eight books. I finally
managed to finish my
[Goodreads reading challenge](https://www.goodreads.com/user_challenges/10979019)
of 10 books. Although I could not finish one book and included one
[audiobook](https://www.goodreads.com/book/show/31284204-the-millionaire-booklet)
to this challenge to complete my target on time.

This year, I discovered my interest in Economics. I am reading some
economics-related literature lately. It is a subtle shift from my all-CS life. I
plan to read a lot of economics-related books in 2019 to gain more expertise in
this domain. But I still need to figure out a way to stop it from interfering
with my first (or second, maybe!) love.

Some of my favorite reads from this year (not in any particular order) -

- **Technology / CS**

  1. [Branch Prediction](https://danluu.com/branch-prediction/)
  2. [The Anatomy of a Large-Scale Hypertextual Web Search Engine](https://research.google/pubs/pub334/)
  3. [In defence of swap: common misconceptions](https://chrisdown.name/2018/01/02/in-defence-of-swap.html)
  4. [A few things I've learned about computer networking](https://jvns.ca/blog/2018/03/05/things-ive-learned-networking/)
  5. [Using Go as a scripting language in Linux](https://blog.cloudflare.com/using-go-as-a-scripting-language-in-linux/)
  6. [Maximize Cache Performance with this One Weird Trick: An Introduction to Cache-Oblivious Data Structures](https://rcoh.me/posts/cache-oblivious-datastructures/)
  7. [IBM PC Real Time Clock should run in UT](https://www.cl.cam.ac.uk/~mgk25/mswish/ut-rtc.html)
  8. [The ``Clockwise/Spiral Rule''](http://c-faq.com/decl/spiral.anderson.html)
  9. [A successful Git branching model](https://nvie.com/posts/a-successful-git-branching-model/)
  10. [So, should you do a CS degree?](http://mattjolson.github.io/2017/12/07/benefits-of-a-classical-education.html)
  11. [Accidentally Turing-Complete](http://beza1e1.tuxen.de/articles/accidentally_turing_complete.html)
      {/* 12. [You Can’t Sacrifice Partition Tolerance](https://codahale.com/you-cant-sacrifice-partition-tolerance/) */}
  12. [How Apple’s New Lineup and iPhone XR will Influence Android Trends, for Better and Worse](https://www.xda-developers.com/apple-new-iphone-xr-influence-android-trends/)
  13. [Perfect Forward Secrecy - An Introduction](https://scotthelme.co.uk/perfect-forward-secrecy/)
  14. [zxcvbn: realistic password strength estimation](https://dropbox.tech/security/zxcvbn-realistic-password-strength-estimation)
  15. [How can I turn photos of paper documents into a scanned document?](https://askubuntu.com/questions/638382/how-can-i-turn-photos-of-paper-documents-into-a-scanned-document)
  16. [Chatbots were the next big thing: what happened?](https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61)
  17. [The AI revolution has spawned a new chips arms race](https://arstechnica.com/gadgets/2018/07/the-ai-revolution-has-spawned-a-new-chips-arms-race/)
  18. [How Firefox is using Pocket to try to build a better news feed than Facebook](https://www.theverge.com/2018/6/13/17446660/mozilla-firefox-pocket-recommendations-ceo-nate-weiner-interview-converge-podcast)
  19. [Countdown to the Singularity](https://www.diamandis.com/blog/countdown-to-the-singularity)
  20. [What the hell is going on with Apple?](https://qz.com/1366350/what-the-hell-is-going-on-with-apple/)
  21. [Why Chinese Artificial Intelligence Will Run The World](https://interestingengineering.com/why-chinese-artificial-intelligence-will-run-the-world)
  22. [Inside Europe’s quest to build an unhackable quantum internet](https://www.technologyreview.com/2018/10/22/139629/europes-quest-for-an-unhackable-quantum-internet/)
  23. [The Case Against Quantum Computing](https://spectrum.ieee.org/computing/hardware/the-case-against-quantum-computing)

  {/* <br/> */}

- **Economics**
  1. [Why It's Hard to Escape Amazon's Long Reach](https://www.wired.com/story/why-hard-escape-amazons-long-reach/)
  2. [The Race to a Trillion](https://www.aboveavalon.com/notes/2018/7/11/the-race-to-a-trillion)
  3. [Ambani Is Ready for His Triple Play Close-Up](https://www.bloombergquint.com/opinion/ambani-is-ready-for-his-triple-play-close-up)
  4. [Penalty kicks and behavioural economics](https://www.livemint.com/Opinion/M0oJYwIP1OxJWnzaz6Eo8H/Penalty-kicks-and-behavioural-economics.html)
  5. [The Psychology of Money](https://www.collaborativefund.com/blog/the-psychology-of-money/)
  6. [Apple’s Trillion-Dollar World](https://www.bloomberg.com/features/2018-apple-trillion-dollar-world/)
  7. [How to Beat Mid-Career Malaise](https://hbr.org/2018/08/how-to-beat-mid-career-malaise)
  8. [The staggering rise of India’s super-rich](https://www.theguardian.com/news/2018/jul/10/the-staggering-rise-of-indias-super-rich)
  9. [Jeff Bezos’s $150 Billion Fortune Is a Policy Failure](https://www.theatlantic.com/business/archive/2018/08/the-problem-with-bezos-billions/566552/)
  10. [How 2,000-year-old roads predict modern-day prosperity](https://www.washingtonpost.com/business/2018/08/06/how-year-old-roads-predict-modern-day-prosperity)
  11. [How Subscription Business Models are Changing Business and Investing (the Microeconomics of Subscriptions)](https://25iq.com/2018/08/11/how-subscription-business-models-are-changing-business-and-investing-the-microeconomics-of-subscriptions/)
  12. [What it means to be rich: The difference between income and wealth](https://www.getrichslowly.org/income-vs-wealth/)
  13. [The Dark Decade Ahead](https://seekingalpha.com/article/4205122-dark-decade-ahead)
  14. [The iPhone Franchise](https://stratechery.com/2018/the-iphone-franchise/)
  15. [The Real Cost of the 2008 Financial Crisis](https://www.newyorker.com/magazine/2018/09/17/the-real-cost-of-the-2008-financial-crisis)
  16. [How to Get Rich (without getting lucky)](https://twitter.com/naval/status/1002103360646823936?lang=en)
  17. [The Approval Economy](https://zandercutt.com/2018/08/23/the-approval-economy/)
  18. [Five myths about capitalism](https://www.washingtonpost.com/outlook/five-myths/five-myths-about-capitalism/2018/09/27/3f0b72f6-c06f-11e8-90c9-23f963eea204_story.html)
  19. [How Amazon’s Retail Revolution Is Changing The Way We Shop](https://www.theverge.com/2018/10/23/17970466/amazon-prime-shopping-behavior-streaming-alexa-minimum-wage)
  20. [Why Wealth Is Determined More by Power Than Productivity](https://evonomics.com/wealth-power-productivity-laurie-macfarlane/)
  21. [Let's Talk About Startup Costs](https://justinjackson.ca/costs)
  22. [How Companies Get You to Pay More for the Same Product](https://www.bloomberg.com/news/articles/2018-11-16/how-companies-get-you-to-pay-more-for-the-same-product)
  23. [Why is art so expensive?](https://www.vox.com/the-goods/2018/10/31/18048340/art-market-expensive-ai-painting)
  24. [Stock Markets Are Wild, but Bond Markets Can Be Dangerous](https://www.nytimes.com/2018/12/18/business/bond-market-risks.html)
  25. [British Raj siphoned out $45 trillion from India: Utsa Patnaik](https://www.livemint.com/Companies/HNZA71LNVNNVXQ1eaIKu6M/British-Raj-siphoned-out-45-trillion-from-India-Utsa-Patna.html)
  26. [How to spot the next recession](https://theweek.com/articles/809324/how-spot-next-recession)

{/* <br/> */}

- **Misc**
  1. [In an Era of ‘Smart’ Things, Sometimes Dumb Stuff Is Better](https://www.nytimes.com/2018/02/21/technology/personaltech/smart-things-dumb-stuff.html)
  2. [Einstein, Aristotle, and Ockham on how real geniuses solve difficult problems](https://www.theladders.com/career-advice/einstein-aristotle-and-ockham-on-how-real-geniuses-solve-difficult-problems)
  3. [Your smartphone📱is making you👈 stupid, antisocial 🙅 and unhealthy 😷. So why can't you put it down❔⁉️](https://www.theglobeandmail.com/technology/your-smartphone-is-making-you-stupid/article37511900/)
  4. Indian Nationalism: The Memories Of History -
     [Part I](https://swarajyamag.com/ideas/indian-nationalism-the-memories-of-history-part-i),
     [Part II](https://swarajyamag.com/ideas/indian-nationalism-nehruvian-and-marxist-conception-of-india-part-ii),
     [Part III](https://swarajyamag.com/ideas/indian-nationalism-the-nationalist-conception-of-india-part-iii)
  5. [Take Your Time](https://blog.ncase.me/take-your-time/)
  6. [What Google Learned From Its Quest to Build the Perfect Team](https://www.nytimes.com/2016/02/28/magazine/what-google-learned-from-its-quest-to-build-the-perfect-team.html)
  7. [The Friendship That Made Google Huge](https://www.newyorker.com/magazine/2018/12/10/the-friendship-that-made-google-huge)
  8. [You are what you write](https://www.linkedin.com/pulse/you-what-write-harry-shum/)
  9. [Being DK In The Age Of MSD](https://swarajyamag.com/ideas/being-dk-in-the-age-of-msd)
  10. [The growing legacy of Rahul Sharad Dravid](https://scroll.in/field/868038/post-retirement-rahul-dravid-is-now-getting-the-unconditional-love-he-always-deserved-as-under-19-world-cup-triumph-showed)
  11. [The Only Real Way to Acquire Wisdom](https://www.theladders.com/career-advice/the-only-real-way-to-acquire-wisdom)
  12. [Personal Sprints: Applying Design Thinking to Your Life](https://fortelabs.co/blog/personal-sprints-applying-design-thinking-to-your-life/)
  13. [Smarter, Not Harder: How to Succeed at Work](https://fs.blog/2018/06/succeed-at-work/)
  14. [Real-Life Schrödinger’s Cats Probe the Boundary of the Quantum World](https://www.quantamagazine.org/real-life-schrodingers-cats-probe-the-boundary-of-the-quantum-world-20180625/)
  15. [Which traits predict graduates’ earnings?](https://www.economist.com/graphic-detail/2018/06/15/which-traits-predict-graduates-earnings)
  16. [The Power User Curve: The best way to understand your most engaged users](https://andrewchen.co/power-user-curve/)
  17. [What if people were paid for their data?](https://www.economist.com/the-world-if/2018/07/07/data-workers-of-the-world-unite)
  18. [Graduate Student Solves Quantum Verification Problem](https://www.quantamagazine.org/graduate-student-solves-quantum-verification-problem-20181008/)
  19. [It doesn’t matter how hard you work – just how busy you look](https://www.spectator.co.uk/article/the-price-of-looking-busy)
  20. [How to Do What You Love](http://www.paulgraham.com/love.html)
  21. [Finding It Hard to Focus? Maybe It’s Not Your Fault](https://www.nytimes.com/2018/08/14/style/how-can-i-focus-better.html)
  22. [First Mover Disadvantage](https://avc.com/2018/08/first-mover-disadvantage/)
  23. [The ShareChat Phenomenon](https://the-ken.com/story/the-sharechat-phenomenon/)
  24. [Atal Bihari Vajpayee and his Achilles heel: Excerpts from Vinod Mehta’s memoirs](https://scroll.in/article/890631/vinod-mehta-on-atal-behari-vajpayee-and-the-1998-nuclear-tests-how-a-tired-pm-became-a-bold-pm)
  25. [Work-life balance is an unhealthy myth](https://medium.com/the-ascent/is-work-life-balance-a-myth-c328377966de)
  26. [Who controls your data?](https://www.engadget.com/2018-09-04-who-controls-your-data.html)
  27. [Your First Ninety Days in Hell](https://www.newyorker.com/humor/daily-shouts/your-first-ninety-days-in-hell)
  28. [The internet can’t handle functioning like a democracy](https://qz.com/1422925/the-public-internet-was-almost-a-democracy/)
  29. [How to Pick a Career (That Actually Fits You)](https://waitbutwhy.com/2018/04/picking-career.html)
  30. [The Surprising Power of The Long Game](https://fs.blog/2018/10/long-game/)
  31. [Why the world needs deep generalists, not specialists](https://www.jotform.com/blog/the-world-needs-polymaths/)
  32. [10 Types of Odd Friendships You’re Probably Part Of](https://waitbutwhy.com/2014/12/10-types-odd-friendships-youre-probably-part.html)

I used [Instapaper](https://www.instapaper.com) extensively throughout the year
to manage and save the articles that I liked. Although I was never very
consistent in reading those saved articles, it was still a good exercise. I
finished all my pending pile of saved articles by the end of the year. Moreover,
for this post, it became straightforward for me to recollect those links. This
list grew excessively large, but I did not want to lose any of these links
because of some random third-party service shutting down, so I am adding them
here for easy reference in the future.

Next year onwards, I plan to read one academic paper from my favorite areas of
CS in every two weeks and summarise them to improve my understanding of the
domain (the [readings](/readings) section of my blog was initially intended for
this purpose). Moreover, seeing my experience in the last two months, I feel
encouraged to increase my Goodreads reading challenge to 20 books.

## Work

The year 2018 was a pivotal year for me on this front. It was the year when I
had to come out of the comfort zone of my parents' protection. My professional
life began this year, and I started earning MONEY. It feels delightful when you
see the money gets deposited to your bank account every month for the hard(!)
work that you have done for the last one month. But

> With great power comes great responsibility.

I believe that I have been able to control this feeling of power quite nicely
until now. Probably being an _Agarwal_ helped :P

Coming back to work, those who do not know, I joined Cisco Systems this year as
a Software Engineer. The job is pretty good for my initial expectations. I made
some good friends. First time in my life, I managed to make a group of friends.

Quite an achievement.

## Studies

This year was officially my last year in formal education.
{/* May I convert all the opportunities that God is going to give me soon in this regard */}
Although I failed to finish my bachelors with a satisfactory final GPA (at least
I am not happy with it), I am very much satisfied with all my learnings from
college. I learned many life lessons, kept myself in check, built some useful
contacts, learned a lot about many CS-related things, and ended up with a decent
job in the end.

However, I sense that this is not the happy ending of my journey towards
learning, and I have a lot more to learn. I recently read the book "The
Alchemist," and the central theme of this book is to keep looking for your
legend. I am still searching for my legend. In 2019, I expect to find new ways
to keep learning and explore new areas both in CS and other fields of life.

## Relationships

Before this year, I had an assumption that I lack social skills. I hesitated in
talking to people. I decided to change it this year. I was waiting for a change
in my life, probably because NITC had become too monotonous for me. It was one
of my new year's resolution that I will change myself and become more
approachable to people.

I do not know if I have changed or not, but I feel much more confident now than
ever in communicating with people. I hope I will continue to improve in 2019 as
well.

## Social Media

I was trying to get rid of Facebook for quite some time. This year, I finally
managed to control my addiction. For a good part of the year, either my Facebook
account remained deactivated, or I was logged out of it. In the past, I used to
feel a strong urge to open Facebook every ten minutes, but this year, I was able
to keep this urge in control. When my account was not deactivated, I kept myself
so busy in other works, that I did not even think of Facebook.

Moreover, the good thing is that I did not notice any symptoms of withdrawal
symptoms because of this sudden quitting of Facebook. A friend's advice worked
nicely. It was quite tricky, indeed.

I was never addicted to any other social media platform, but I decided that I
can use Twitter for my benefit. I feel Twitter is a useful tool if utilized
correctly. I followed many people who tweet regularly about CS related stuff. I
open Twitter once every 2-3 days for a very short duration to collect some
articles and tips. Nowadays, these articles, along with a few blog articles from
Feedly, mainly form my Instapaper feed. Though Instapaper recently switched to
commercial model again, I decided to keep using it for the time being until I
find some other alternative.

## Miscellaneous

I had decided to exercise for at least 90% part of 2018. I failed miserably.
Leave alone every day; I could not even do it continuously for one month. I need
to make this a top priority. Otherwise, it is going to create trouble for me
soon.

For the last two years, I am trying to get up early in the morning every day. My
body does not seem to care, though. It seems a classic example of the struggle
between mind and body. My brain says that I am an early bird, but my body
straightforwardly rejects this idea. I have felt the positives of waking up
early, so I am still trying my best so that my body can adjust to this change. I
will keep working on this habit in 2019 as well.

I noticed a bad habit in myself - procrastination. I procrastinated a lot
in 2018. Things that I could have finished well within the deadlines took me
ages to complete. I was always late in my BTech project deadlines, I could not
finish one of my hobby projects, I could not finish my study targets on time,
and many other such examples haunted me this year. It is one of my most
important goals of 2019 that I need a way to find how to concentrate on one
thing at a time. Many things distract me while I am working. Technology itself
is a significant distraction, but because I am a CS professional, this is one
thing from which I cannot run away. However, I will still try to avoid getting
distracted by my _curiosity_ and put more focus on doing work.

I am writing more than ever. However, with my increased writing, my English
vocabulary is not enough anymore. This year, it happened many times that I
wanted to write something, but because of the lack of proper words in my
vocabulary, I had to settle with _inferior_ words. I tried multiple times this
year to work on improving my vocabulary, but I failed badly. I will increase my
focus on improving my knowledge of English in 2019 so that such small issues do
not stop me from adding something to my skills.

This year, I experimented and tried to organize myself with to-do lists. It was
a fruitful exercise, and it had a lot of sound effects on my productivity. The
days when I made a to-do list, I felt very energetic and encouraged to finish
all the tasks on my list. However, then I noticed one thing, I could not
continue doing this for more than a few days at once. For initial days, I felt
encouraged to complete my tasks, but soon it began to appear as a burden, and I
felt exhausted. So it seems that something in the middle will work for me. This
year, I will continue using to-do lists (I use Google Keep for this) but for
short durations of time. I will refrain from using it every day to avoid getting
exhausted. I am considering a switch to [Notion](https://www.notion.so/) to
maintain my monthly and long-term goals. Probably that will also help me in
keeping track of my goals without feeling the heat.

All of my friends love to travel. It seems a common habit in most of my friends.
However, I am an exception. I'm not particularly eager to go on trips. I
attribute it to my issues with motion sickness. For the whole year of 2018, I do
not have a single trip memory other than my travels to Bengaluru and Jaipur
airports. Oh yeah, after thinking for some time, I recalled that I went on one
trip from Bengaluru to Calicut to attend my convocation ceremony. That's all! I
will _consider_ accepting trip invitations from my friends in 2019. Up until
now, I keep refusing to join them in their trips due to my health issues, my
desire to stay in solitude and partially because of my unwillingness to explore
anything outside technology. However, it is time I start changing myself.

It was a grave mistake that during my four-year stay in Kerala, I did not try to
learn Malayalam. I feel that I missed an excellent opportunity to learn a new
language. Although I am as bad as other north Indians when it comes to knowing
multiple languages (correct me if I am wrong, I do not intend to generalize all
north Indians), I think that learning a new language can be very beneficial for
_some parts of my brain_. Now I am in Karnataka, yet another south Indian state
and with yet another language. It is an excellent opportunity, and I am not
going to repeat my mistake this time. Even if I do not succeed in learning
Kannada, it will provide enough challenges to my brain for the short term. Who
knows, it might also give me a new skill!

**Welcome 2019, I hope that you will help me in taking a step closer to
discovering myself. Give me new experiences, keep me grounded and help me in
contributing to the progress of my India.** :blush:
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Beginning a New Journey]]></title>
        <id>https://v2.yashagarwal.in/blog/beginning-a-new-journey</id>
        <link href="https://v2.yashagarwal.in/blog/beginning-a-new-journey"/>
        <updated>2018-08-25T15:46:41.000Z</updated>
        <content type="html"><![CDATA[
When I was in eighth (or was it ninth?) class, one of our teachers asked in the
class, what do you want to become in your life? People said a lot of things.
When my turn came up, I stood up and said, _“Mein software engineer banana
chahta hu”_ (I want to become a software engineer). It was not that I was
genuinely interested in Computers. When I look back now, I realize that it was
my cousins who affected my choice (in an indirect way), and their achievements
fascinated me to aim at this particular career choice.

My whole life for the last seven years was revolving around this one dream(!) of
getting a job in an MNC. I got my chance when I got placed in Cisco last
Monsoon. I was super excited about joining Cisco since then. Perhaps because of
the MacBook on which I am typing this article right now :smile: and partly
because of the monotonicity of the NIT-C environment. I wanted to break out of
the comfort zone that I had built there around myself in NIT-C. Changing place
seemed the only viable option.

I have been doing a self-introspection for the last four to five months. My blog
posts from the previous few months reflect some hints about my introspections. I
have mentioned my observations here and there in a few of my blog posts. I
discovered some unique aspects of my personality. On the other hand, I found out
some traits which are pretty weird (in my opinion :) ). I am not going to
publish all of my findings, but one thing became apparent, my social anxiety
requires my immediate attention.

It is quite difficult to change some aspects of our personality; usually those
we are born with. But most of the qualities that define someone keeps changing.
Life experiences play an essential role in determining a person’s character.
Success and failure define a person. I firmly believe that no person ever
remains the same. People continuously go through phases of realizations and the
ups and downs in the career, academics, broken trusts, dampening creativity,
growing age, success, glory, hatred, and betrayals. People become what they are
because of the world around them. These realizations come from experiences and
experiences that come from bad experiences.

I learned this the hard way!

So, I decided, I will not commit those similar set of mistakes again. I will
make new mistakes :stuck_out_tongue_winking_eye:. I realized that there exists a
world outside computers and tech. I need to go and talk to people. If not random
strangers, I should talk to my friends, take part in various activities, play
some sport, focus on my fitness and mental health, and go on trips. And of
course, perform well in work and maintain a good work-life balance if it is not
a
[myth](https://medium.com/the-ascent/is-work-life-balance-a-myth-c328377966de).

I cannot change the past now. It is only the future that is yet in my power. I
am eager to see how my current actions are going to affect my future.

At last, let me finish this article by quoting Winston Churchill (Although I am
not a big fan of him, this quote is worth sharing).

> If we open a quarrel between past and present, we shall find that we have lost
> the future.

Cheers. 😊
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Good and Bad about CSED of NIT-C]]></title>
        <id>https://v2.yashagarwal.in/blog/the-good-and-bad-about-csed-of-nit-c</id>
        <link href="https://v2.yashagarwal.in/blog/the-good-and-bad-about-csed-of-nit-c"/>
        <updated>2018-06-14T12:29:28.000Z</updated>
        <content type="html"><![CDATA[
Four years ago, in this very month of June, JEE Mains results were out. I had
screwed up my JEE Advanced, so I had to settle for an NIT. My AIR was good
enough to get me a seat of Computer Science and Engineering in any of the NITs
except the first three (at that time Trichy, Warangal, and Surathkal). I was
skeptical about going to [NIT Calicut](http://nitc.ac.in/) because of its
distance from my native place, so NIT Allahabad was the most suitable choice.
However, in the end, I decided to give preference to NIT Calicut over NIT
Allahabad. One of the many reasons for this decision was an excellent
[article](https://dsanghi.blogspot.com/2011/05/my-2011-list-of-recommended-csit.html)
by Dr. Dheeraj Sanghi, a retired professor from IIT Kanpur. His blog post was
the primary reason; I decided to go with NIT Calicut. Now that I have graduated
from NIT Calicut, I think it is the right time to document my observations about
the CSE department of NIT Calicut from the perspective of a student.

My exposure to the CSE department was limited to the facilities provided to
undergraduate students only (almost everything except some academic facilities),
so I am not entirely sure if this article will help any of the postgraduate
students out there. However, some points below might help you decide about the
non-academic activities of the department.

## Faculties

Like every other NIT, NIT Calicut also suffers from the lack of permanent
faculties. Most of the faculties in the department are recruited on a contract
basis (ad-hoc). It is **not** necessarily a
[bad](https://dsanghi.blogspot.com/2018/05/teaching-by-temps-it-is-budget-issue-too.html)
thing, but many a time, an ad-hoc faculty gets to teach a subject where one does
not hold strong command. In that case, the subject becomes a burden for both
student and teacher. It happened to me many times when I was stuck in a
situation that I ended up losing my interest in the subject as well as grades.

Most of the core subjects are taught by permanent faculties who are very good at
their subjects. These faculties are very experienced and are alumni of some of
India's top IITs and IISc. The department used to
[ask](https://dsanghi.blogspot.com/2011/05/my-2011-list-of-recommended-csit.html)
new hires to get a postgraduate degree from some IIT or IISc, but this does not
seem to be the case anymore.

Most of the professors prefer to teach traditional computer science subjects, so
if you are interested in AI, Data Science, or any other such areas of computer
science, then you might have to depend on self-study.

## Club Activities

[CSEA](http://assoc.cse.nitc.ac.in/) is the main departmental club that
organizes almost every co-curricular activity in the department. In my opinion,
CSEA is the best department association in NIT Calicut. I was not a member of
CSEA, so all of my views are from the perspective of an outsider. CSEA organizes
talks and workshops for the freshers from time to time. I attended all the
lectures and seminars arranged by CSEA in my initial years, and I feel that
those workshops were quite beneficial for me as a student.

FOSSCell is a group of students who contribute to open-source software. FOSSCell
organizes workshops related to Linux and open source contributions. It also
organizes [FOSSMeet](http://fossmeet.in/), the yearly free and open-source
software conference organized in NIT-C. It is one of the largest gatherings of
open source enthusiasts in South India. I have written two posts about my
experience as a part of the organizing team of FOSSMeet. You can read them
[here](/blog/fossmeet-17/) and [here](/blog/fossmeet-18/). Attending and
organizing FOSSMeet is one of the best experiences of my college life. The
current executives of FOSSCell are actively working on improving the state of
open source contributions in NIT-C. I hope the situation will change in the
coming years.

The students manage all the labs in the department. The
[Software Systems Lab](http://athena.nitc.ac.in/) is assigned to undergraduate
students. This lab is probably the crown jewel and pride of every CS student of
NIT Calicut. It remains open most of the time. All the department servers are
kept in this lab and are managed independently by the student administrators
chosen by the student administrators. The student administrators are given the
responsibility to maintain all the department websites. I do not know if any
other university or college in India provides such independence to its students.
I was one of the student administrators in this lab, and I consider that this
was the best thing that happened to me during my graduation.

## The Infrastructure

A traditional computer science course does not require many types of equipment
except a laptop and a fast enough internet connection. Internet speed is not
extraordinary in NIT-C, but it was sufficient for me. The network administrators
blocked many websites, but if the site is related to coursework, sending a short
mail was enough in most cases to get it unblocked.

The labs are equipped with modern computer systems, and Ubuntu is installed on
almost every department system. The particular emphasis on the use of
open-source software is a big plus point for the department.

## Courses

The curriculum was last updated in 2010. Since then, six batches have graduated.
I think it is an excellent time to consider revising it. The current curriculum
is good enough for most traditional CS subjects, but its focus on the present
buzzwords of the CS world is very less. I heard that the department changed the
curriculum for the batches joining 2017 onwards, but I doubt that there are any
significant changes.

{/* However, the department currently lacks enough number of faculties to teach those subjects, so */}

The academics are taken quite seriously in the department (apparently). The
level of question papers in examinations is generally very tough. I always felt
the heat, at least. However, teachers are quite friendly and will help you with
any of your queries.

The situation of lab courses (except OS, Compilers, and DSA lab) in the
department is very pathetic. Operating Systems lab and Compiler lab have a
well-defined structure, and the feeling of developing your tiny OS or compiler
is one of the best feelings ever. Data Structure and Algorithms lab runs in
parallel to the corresponding theory course, and that helps students in
understanding theory by practice.

I cannot say the same about any other lab in the department; most of the
students end up learning nothing new from these lab courses. The problem is in
the way these courses are handled. There does not seem to be a proper structure
of teaching in these courses. Students are expected to learn on their own and
come to the lab and give exams. Although most of the time, the corresponding
theory course carries marks for a mini project which compensates for the lab
course, these lab courses do have some scope for improvements.

## Placements & Higher Studies

The department does not handle placements, but the quality of education and the
focus on industry-oriented courses do affect the placements. The placement
department of NIT-C has been doing an excellent job of maintaining a track
record of over 90% placements from computer science every year.

Department, as such, does not focus on placements much. I feel that the
department is more interested in making researchers than software engineers.
Most of the courses are very heavily inclined towards theory. From my batch, I
know at least ten people who are planning to go to the USA for higher studies in
the next two years. The faculties also encourage students to pursue higher
education (and subsequently research). Perhaps, it is one of the reasons that
the state of competitive coding is not very good in the department.

## Conclusion

Despite continuous lack of good permanent faculties and its location
disadvantages, CSED of NIT-C has managed to produce competent engineers year by
year. Spending four years in Kerala can be a different experience for outsiders,
especially North Indians, but it is an experience worth gaining. If you have a
good rank in JEE Mains and do not mind going too far from home, CSED of NIT
Calicut is an excellent choice. I hope you will not regret the decision, though
I will not say the same about other departments of NIT-C.

If you decide to join NIT-C, do read my article about my
[experience](/blog/mistakes-that-i-made-in-nitc/) at NIT Calicut.

Thanks to my friends [Aashish](https://www.linkedin.com/in/aashishsatya),
[Mahaveer](https://www.linkedin.com/in/mahaveer-chouhan-575abba7/) and
[Faris](https://www.facebook.com/faris.shajahan.1) for reading the drafts of
this article and providing their suggestions.

Best wishes. Cheers :smile:
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Battery Notifications in i3]]></title>
        <id>https://v2.yashagarwal.in/blog/battery-notifications-in-i3</id>
        <link href="https://v2.yashagarwal.in/blog/battery-notifications-in-i3"/>
        <updated>2018-06-12T04:15:46.000Z</updated>
        <content type="html"><![CDATA[
I am using _i3_ window manager for the last seven months, and it has been a
pleasant and productive experience so far. There were a few hiccups here and
there, but that is expected with such minimalistic setups. One thing that I
never noticed was the lack of notifications on critical battery levels. For the
last few months, my laptop battery was discharging to 0% all the time. Probably
this proved to be too fatal for my battery. According to this
[article](https://lifehacker.com/how-often-should-i-charge-my-gadgets-battery-to-prolong-5875162),
lithium-ion batteries are not expected to go from 100% to 0% frequently. I
recently bought a new battery, and I did not want to reduce the lifespan of this
battery too. So I decided to set up battery notifications for my i3 setup.

I [found](https://agorf.gr/2016/06/29/low-battery-notification-in-i3wm/) a bash
script which shows a notification using _notify-send_ when battery charge level
reaches or drops below a configured threshold. However, I had to do some
additional steps to make this script work on my system.

The first issue was the _lockfile_ program, which was not installed in my
system. I installed it using the following command.

```bash
sudo apt install procmail
```

The second issue was more difficult to solve. I planned to set up the script to
run every minute using _cron_. However, it turns out that cron operates in a
very
[minimalistic](https://askubuntu.com/questions/23009/why-crontab-scripts-are-not-working/23438#23438)
environment and notify-send requires the presence of some special variables in
the environment. These variables are **DBUS_SESSION_BUS_ADDRESS**,
**XAUTHORITY** and **DISPLAY**. To provide the values of these variables to the
cron environment, I modified the script and sourced a new file `.bat_envs`.

```bash
#!/usr/bin/env bash

. /home/yash/.bat_envs

THRESHOLD=15

lock_path='/tmp/battery.lock'

lockfile -r 0 $lock_path 2>/dev/null || exit

acpi_path=$(find /sys/class/power_supply/ -name 'BAT*' | head -1)
charge_now=$(cat "$acpi_path/charge_now")
charge_full=$(cat "$acpi_path/charge_full")
charge_status=$(cat "$acpi_path/status")
charge_percent=$(printf '%.0f' $(echo "$charge_now / $charge_full * 100"
 | bc -l))
message="Battery running critically low at $charge_percent%!"

if [[ $charge_status == 'Discharging' ]] && [[ $charge_percent -le $THRE
SHOLD ]]; then
  /usr/bin/notify-send -u critical "Low battery" "$message"

  current_date_time="`date +%Y%m%d%H%M%S`";
  echo "[BATTERY LOG] = $charge_percent% on $current_date_time"
fi

rm -f $lock_path
```

Read this blog
[post](https://agorf.gr/2016/06/29/low-battery-notification-in-i3wm/) to
understand how this script works.

As the notify-send requires some special X session environmental variables, we
will need a method to provide these variables to notify-send in cron
environment. The safest way to get X session related environmental variables is
to get them from the environment of a process of the user who is logged on to X.
The following script will run every time a user logs in and stores these
variables in a file `.bat_envs`.

{/* https://unix.stackexchange.com/a/111194 */}

```bash
#!/usr/bin/env bash

env_path="$HOME/.bat_envs"

rm -f "${env_path}"
touch "${env_path}"

copy_envs="XAUTHORITY DISPLAY DBUS_SESSION_BUS_ADDRESS"

for env_name in $copy_envs
do
    env | grep "${env_name}" >> "${env_path}";
    echo "export ${env_name}" >> "${env_path}";
done

chmod 600 "${env_path}"
```

To run this script at startup, I added this file to the i3 config file with the
following command.

```bash
exec --no-startup-id "path to your script"
```

Then at the end of cron file, I added a new entry for the battery monitoring
script.

To open cron file:

```bash
crontab -e
```

Now add the following line to the end of the file and save the file.

```bash
* * * * * bash "path to your script" >> "path to your log file"
```

Replace the _path to your script_ (with double quotes) with your script path and
the _path to your log file_ with a path where you want to save your log file.

Now every minute, this script will be executed, and if your battery percent
drops below the threshold value, you will be notified with a notification
bubble.

I tested this procedure on _Ubuntu 18.04 with i3_. It should work on Arch Linux
and other non-Debian distributions also, but the steps might be slightly
different due to various reasons. Please comment if you face any issues with the
setup.

Thank you for reading the article. Cheers 😄
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mistakes That I Made in NITC]]></title>
        <id>https://v2.yashagarwal.in/blog/mistakes-that-i-made-in-nitc</id>
        <link href="https://v2.yashagarwal.in/blog/mistakes-that-i-made-in-nitc"/>
        <updated>2018-06-01T04:51:45.000Z</updated>
        <content type="html"><![CDATA[
Now that I am graduated from NIT Calicut, one more chapter of my life is over.
It is time to move on to the next page, but before I begin that phase, I thought
it would be nice, to sum up, the experience that I gathered in NIT Calicut. The
last four years have been great for me. I learned a lot of new life lessons, but
there were some decisions that I could have avoided. I take full responsibility
for my actions and do not blame anybody for the same. Although I do not regret
taking any of those decisions, I feel it is crucial to document all those
lessons before they vanish from my _otherwise_ average memory. This post is
intended to serve as a document for my future self, but most of the content here
should be able to help anyone who happens to read this post. Most of this
content has been taken from my journal, which I maintained (not consistently)
over the last two years.

## Studies

From the first year itself, I had an impression from various online QA sites and
some seniors that studies are not a big deal in college. That was a grave
mistake which cost me a lot during my college life. I tried to compensate for it
in the latter half of my graduation, but that was not enough.

While my friends used to learn by teaching each other, I never enjoyed studying
in groups. I wish I had participated more in such group learning activities.

Most of the courses taught in traditional colleges like NITC are useless, in my
opinion. However, Data Structures and Algorithms(DSA) was one subject which
shows its importance again and again. It is one of those subjects where I should
have put more attention. Although I was suffering from a fracture at the time of
this course, some more efforts from my side could have changed things as they
are today.

## Wrong learning methods

I always tended to learn anything new using the tutorials available on the
Internet. It is fine, but I never tried to do any projects/practicals to
strengthen my learning. In my experience, it is always better to learn any
programming language by doing projects in it.

My first programming language was C, which was taught in an introductory course
in the first year. C is a relatively low-level language, and it helped me in
understanding many concepts and working on many systems related stuff. Still, I
feel that it is also one of the reasons that I am not able to think in
higher-level abstraction. When I started learning Python, I was not able to
think anything in abstract terms. I wish I had put more effort into learning
Python or any other OOP language early in my college life.

## Communication

I have always been an introvert person when it comes to communicating with
people. I wish I had worked on improving this aspect of my personality. For the
first two years, I never asked any seniors for advice, never asked any questions
in the classroom, never discussed project ideas with any faculty. I tried to
improve myself in the last two years, and I feel satisfied with my efforts. In
my opinion, it is always better to ask a more experienced person for their
advice than to take blind steps and regret later.

I was hesitant about talking to people from different linguistic backgrounds in
my first and second years. Again thanks to my inability to communicate with new
people. I improved this later, but first impressions are crucial, if not
everything.

## Friends and seniors

In my first year, I made a mistake by choosing to befriend some people who
identified themselves as _state seniors_ (people from the same north Indian
state as I am). I was naive in identifying people at that time, but when I look
back now, I feel that if I had avoided those people and invested that time in
learning something related to CS, I could have gained more out of college. For a
person who was entirely new for CS, that one year's time was very crucial, and I
completely wasted it. It took me two years to rectify my mistake.

## Not taking breaks

I never took breaks from learning new things. I always put my work ahead of my
personal life. That was the wrong approach. However, I do not blame myself for
this. I was new to such work-life equations, and I did not realize the
requirement to maintain a proper work-life balance. I wanted to learn a lot of
new things, and college provided me a suitable environment, but I feel that I
exhausted myself many times. That resulted in my loss of interest from Computer
Science also in the second year.

## Writing and Reading

I was never a voracious reader in my childhood. I never tried to spend my free
time with books. After coming to college, I saw many people reading books day
and night. That inspired me to develop a new hobby of **Reading**. Although I
still do not read a lot (just 5-6 books a year), it is better than reading none.

I started this blog in the second year. My intention was _not_ to write. I just
wanted to learn how to set up Wordpress and Jekyll. However, slowly I developed
the habit of writing. I now consider it the biggest takeaway from college.
Writing a blog has helped me learn new things and systematically explain things.

I tried to write a journal to document significant events in life, but I could
not maintain it regularly. That is one thing which I would like to improve in
the coming years.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Proxy Your Requests to the Backend Server With Grunt]]></title>
        <id>https://v2.yashagarwal.in/blog/proxy-your-requests-to-the-backend-server-with-grunt</id>
        <link href="https://v2.yashagarwal.in/blog/proxy-your-requests-to-the-backend-server-with-grunt"/>
        <updated>2018-05-15T11:44:13.000Z</updated>
        <content type="html"><![CDATA[
_This article was originally published on
[zeolearn](https://www.zeolearn.com/magazine/proxy-your-requests-to-the-backend-server-with-grunt)._

If you are working on large projects, it is undoubtedly a good idea to have a
build script or some task scripts to help to automate some of the repetitive
parts of the development process. For JavaScript projects, `Grunt` serves a
similar purpose. It is a JavaScript task/build runner that is written on top of
NodeJS. Grunt can help you with automatically minifying your JavaScript or CSS
files, or reload your browser on every file change. It can show you a
comprehensive list of JavaScript errors, compile your `SASS/LESS` files into CSS
files automatically, and many other things.

However, the most significant advantage of Grunt that I am going to discuss
today is its ability to proxy your requests. For example, when you are
developing your backend with anything other than JavaScript, you will face
difficulty in accessing the backend data in your frontend without having to
compile and deploy the code every time you make any changes. It is not possible
with a typical web server setup because
[XHR](https://en.wikipedia.org/wiki/XMLHttpRequest) requests are not allowed to
be cross-domain by browsers due to
[Cross-origin resource sharing](https://en.wikipedia.org/wiki/Cross-origin_resource_sharing)
(CORS) limitations.

So, the problem here is as follows,

> you are developing the UI of your applications using some frontend JavaScript
> framework (say Angular) with Grunt as the build runner, and the backend of
> your application is being designed in some backend framework other than
> JavaScript/NodeJS (say Laravel), you might face problems accessing the backend
> while running Grunt server.

It happens because the backend Laravel service runs on port 8000, and the front
end development server runs on port 8080. The requests from the frontend server
to the backend-server will result in
[same-origin policy](https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy)
errors due to the port difference. To fix this issue, we can set up CORS through
a proxy on Grunt. This proxy will stand in front of your frontend server and the
backend server and get the required data from the backend and pass it to your
frontend while letting your browser think that you are all in the same domain.

Grunt has a module
[grunt-connect-proxy](https://github.com/drewzboto/grunt-connect-proxy) that
exists to help to solve this issue. It delegates requests that match a given URL
to the backend of your choice. So for example, you want to access your backend
using the URL [http://localhost:8080/api](http://localhost:8080/api), you can
write a proxy rule so that whenever your user tries to access this URL in a
browser, the proxy will get the data from your backend and server it at this
particular URL.

The procedure to set up the proxy is simple. First, you will have to add the
proxy configuration to your `Gruntfile.js`. In this example, I am assuming that
the backend server is running on the port 8000, and the Grunt server is running
on the port 8080. This configuration will delegate all requests to
[http://localhost:8080/api](http://localhost:8080/api) to
[http://localhost:8000/backend](http://localhost:8000/backend).

```js
connect: {
  server: {
    options: {
      port: 8080,
      base: 'public',
      hostname: 'localhost',
      livereload: true,
      middleware: function (connect, options, middlewares) {
        middlewares.unshift(require('grunt-connect-proxy/lib/utils').proxyRequest);
        return middlewares;
      }
    },
    proxies: [
      {
        context: '/api',
        host: 'localhost',
        port: 8000,
        https: false,
        rewrite: {
            '^/api': '/backend'
        }
      }
    ]
  }
}
```

Now register your Grunt server task to run the proxy on Grunt execution.

```js
grunt.registerTask("server", function (target) {
  grunt.task.run(["configureProxies:server", "connect:server"])
})
```

Let me explain the above two scripts line by line. In the connect section of
your `Gruntfile`, we add a new section called `proxies`. The options defined in
the proxies section are explained below.

- **context**: This is the context against which the incoming requests will be
  matched. Matching requests will be proxied to the backend server.
- **host**: The host address where the backend server is running. The incoming
  requests will be proxied to this host.
- **port**: The port where the backend server is running.
- **https**: If your backend server is an https endpoint, then set this value to
  `true`.
- **rewrite**: This option allows rewriting of URL when proxying. What this
  means is that when trying to proxy
  [http://localhost:8080/api](http://localhost:8080/api) to the backend server,
  the URL will be rewritten as
  [http://localhost:8000/backend](http://localhost:8000/backend). The object's
  key serves as the regex used in the replacement operation, and the object's
  value is the context of your backend server's service.

More options can be found in the
[documentation](https://github.com/drewzboto/grunt-connect-proxy#grunt-connect-proxy)
of `grunt-connect-proxy`.

You will also need to set up the proxy's middleware in the `options` section of
the `connect`. The relevant code is as follows.

```js
...
middleware: function (connect, options, middlewares) {
  middlewares.unshift(require('grunt-connect-proxy/lib/utils').proxyRequest);
  return middlewares;
}
...
```

Finally, include your proxy task in the server task. It is necessary to append
the proxy task before the connect task. Also, make sure to specify the
connection target in the `configureProxies` section. In our case, the connect
target is `server`.

Now you can start your Grunt server via this configured proxy by typing
`Grunt server` in the command line. You should see something like this in the
console.

```sh
$ grunt server
...
Running "configureProxies:server" (configureProxies) task
Rewrite rule created for: [/^\/api/ -> /backend].
Proxy created for: /api to localhost:8000

Running "connect:server" (connect) task
Started connect web server on http://localhost:8080
...
```

The above output confirms that the proxy is working fine. Some of the example
URLs are:

{/* TODO table formatting */} | Grunt Server | Backend Server | |
----------------------------- | --------------------------------- | |
http://127.0.0.1:8080/api | http://127.0.0.1:8000/backend | |
http://127.0.0.1:8080/api/x/y | http://127.0.0.1:8000/backend/x/y |

That's all. Now you will not face any problems getting data from any backend of
your choice.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Writing Drozer Modules]]></title>
        <id>https://v2.yashagarwal.in/blog/writing-drozer-modules</id>
        <link href="https://v2.yashagarwal.in/blog/writing-drozer-modules"/>
        <updated>2018-05-13T11:40:13.000Z</updated>
        <content type="html"><![CDATA[
This post is a result of my experimentation with Drozer. Drozer is a security
testing framework for Android, developed by MWR Labs. According the Drozer's
official
[documentation](https://labs.f-secure.com/assets/BlogFiles/mwri-drozer-user-guide-2015-03-23.pdf):

> Drozer allows you to assume the role of an Android app and interact with other
> apps. It can do anything that an installed application can do, such as making
> use of Android's Inter-Process Communication (IPC) mechanism and interact with
> the underlying operating system.

Drozer modules are written in Python. The module performs operations on an
Android device with the help of an agent app installed on the device. The agent
app, by default, has permission to use the internet connection only. This
permission is required so that the agent can open a ServerSocket on port 31415
(default). The agent will listen for the incoming connections on this port. The
console will connect to the agent on this port.

Drozer modules are inherited Python classes. The parent class is defined in
[drozer.modules.Module](https://github.com/FSecureLABS/drozer/blob/develop/src/drozer/modules/base.py).
Drozer console provides commands to create a custom module repository, which is
very useful for the local development of modules.

You can read more about the structure of a Drozer module
[here](https://github.com/FSecureLABS/drozer/wiki/Writing-a-Module).

I will explain all the critical parts of a Drozer module with the help of a
sample module. I will be implementing a module to record and save the sound from
the inbuilt mic of an Android device.

I initialized a new module repository using the Drozer console using the
following command.

```text
dz> module repository create custom
Initialised repository at custom.
```

You will see a new directory `custom` in your current directory after executing
above command. Navigate to this directory and create a new folder with any name.
I prefer to name this folder same as my module name. In this folder, create a
file `__init__.py`. Drozer identifies the folder as a module directory if
`__init__.py` is present in the directory. Now you can implement your module in
this directory.

To begin implementing our module, create a new file `record.py` in the module
directory. Drozer has many different utility classes, which we can use to
simplify our implementation. To use these utility classes
([mixins](https://github.com/FSecureLABS/drozer/wiki/Using-mixins)), our module
class must extend _mixins_ using Python's multiple inheritance feature.

We first need to import all the required mixins. The mixins are stored in
`modules.common` package in the Drozer source tree. After importing mixins and
extending our class, the code will look like this. You can also import any other
standard Python module here.

```python
from drozer.modules import common, Module
import os, subprocess, time

class Record(Module, common.Shell, common.FileSystem, common.ClassLoader):
```

Now we will set up the metadata for our module. This information will help
Drozer to organize and list our module correctly. We can define the name,
description, author, date, license, path, permissions, and examples. Most of the
available options are self-explanatory. But _path_ and _permissions_ require
some explanation.

The _path_ variable defined here is an array that contains the values for the
namespace of the module. Drozer supports separate namespaces for each module. We
can combine similar modules in the same namespace using this feature.

The _permissions_ array variable contains all the permissions that this module
will require for proper functioning. For example, our module will need
permission to record audio on the device to work correctly. So we define this
permission in the permissions array. The agent app on the device is required to
have this permission. Otherwise, our module will throw an error.

The following snippet shows the metadata section of our module.

```text
name = "Record sound from the inbuilt mic of an Android device."
description = "Record sound from the inbuilt mic of an Android device. The default save format is 3GPP. Relies on the agent having the RECORD_AUDIO permission."
examples = """
dz> run custom.record.record
Setting up recorder configuration...
Recording started
Press any key to stop recording

Recording stopped...downloading recording
Screenshot captured. Saved at location /home/yash/work/drozer/1524201166.3gp
"""
author: "Yash Agarwal"
date: "2018-04-14"
license = "BSD (3 clause)"
path = ["custom", "record"]
permissions = ["android.permission.RECORD_AUDIO", "com.mwr.dz.permissions.GET_CONTEXT"]
```

Now we can start implementing the heart of our module, the `execute()` function.
This function will be invoked by Drozer when the module is run. Every action
that the module is expected to perform should be implemented in this method.

The implementation of `execute()` method is slightly tricky and requires an
understanding of different classes and methods provided by the Android API. As
we are writing a module to record sound, we will look into the documentation of
[MediaRecorder](https://developer.android.com/guide/topics/media/mediarecorder.html)
class. Before reading further, go through the documentation about the use of
reflection API in Drozer
[here](https://github.com/FSecureLABS/drozer/wiki/Using-Reflection).

The `execute()` function is given below.

```python
def execute(self, arguments):
    # unique file names
    filename = str(int(time.time())) + ".3gp"

    # current working directory of Drozer console
    cwd = self.workingDir()

    # Magic of Reflection API !!!
    recorder = self.new("android.media.MediaRecorder")
    AudioSource = self.klass("android.media.MediaRecorder$AudioSource")
    OutputFormat = self.klass("android.media.MediaRecorder$OutputFormat")
    AudioEncoder = self.klass("android.media.MediaRecorder$AudioEncoder")

    recorder.setAudioSource(AudioSource.MIC)
    recorder.setOutputFormat(OutputFormat.THREE_GPP)
    recorder.setAudioEncoder(AudioEncoder.AMR_NB)
    recorder.setOutputFile("%s/recording.3gp" % cwd)
    recorder.prepare()

    self.stdout.write("Recording started\n")
    recorder.start()
    raw_input("Press any key to stop recording\n")
    recorder.stop()
    self.stdout.write("Recording stopped...\n")
    recorder.reset()
    recorder.release()

    # Download file from device to PC
    length = self.downloadFile("%s/recording.3gp" % cwd, filename)

    if length != None:
        self.stdout.write("Recording saved\n")

    else:
        self.stderr.write("Recording could not be fetched from the device.\n")
```

I followed the sample use case given on
[this](https://developer.android.com/reference/android/media/MediaRecorder.html)
page, to instantiate and use the _MediaRecorder_ object.

After the recording is finished, we want to save this recorded media file to our
computer. Drozer provides a method,
[downloadFile](https://github.com/FSecureLABS/drozer/blob/c92d74024c653b6dc7de3378a24e51d276ae2c62/src/drozer/modules/common/file_system.py)
exactly for this purpose. This method returns the length of the data downloaded
on success and `None` otherwise. We can use this information to test the success
or failure of the fetching of the recording.

That's all. We have successfully implemented a Drozer module which can record
the sound on an Android device without the knowledge of the user. Do you smell
something fishy here? The whole idea here depends on that particular
`android.permission.RECORD_AUDIO` permission that our agent app had. It allowed
our module to record without _user consent_ (actually, the user gave her consent
unknowingly while installing agent app). Many apps nowadays ask for arbitrarily
random permissions. Those permissions might not be related to the functionality
of the app in any way, but because there is no method to install apps without
granting these permissions, the users grant all permissions to these apps. That
can be exploited very easily. This tutorial tried to show one of such
exploitations.

Here are some exercises that you should try if you want to learn more about
Drozer module development.

- A module to initiate a call on a device.
- A module to get the clipboard values on a device
- Try finding a public exploit on Android forums such as XDA and implement that
  exploit as a Drozer module.

Slightly tougher one.

- A module to terminate a call without user intervention (I do not know if it is
  possible to do this programmatically. If you implement this successfully, do
  let me know in the comments section.)

Thanks for reading. Cheers :)
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[So I Applied for GSoC]]></title>
        <id>https://v2.yashagarwal.in/blog/so-I-applied-for-GSoC</id>
        <link href="https://v2.yashagarwal.in/blog/so-I-applied-for-GSoC"/>
        <updated>2018-03-28T15:28:26.000Z</updated>
        <content type="html"><![CDATA[
I first heard about Google Summer of Code (GSoC) in my second year (2016). It
was quite fascinating to know that such a program exists (possibly because of
that super attractive amount of money, $5500 at that time). I researched about
it and sent emails to some mentors. The replies were mostly encouraging, but I
still could not gather the courage to apply as I used to doubt my capabilities.
Then last year (2017) again, I decided that I should try for GSoC one more time.
I looked for the projects, started reading codebase of one project, but due to
my lack of determination, I again did not apply.

In the summers of 2017, I got some time to think about it. I decided that for
the next year, I will try everything to make sure that I apply for GSoC 2018. I
started coding as much as possible and pushing my code to GitHub to build an
impressive profile.

Now I can say that I am satisfied with my efforts to some extent. I did start
some good [open](https://github.com/yashhere/BeautifyMP3)
[source](https://github.com/yashhere/ConMan)
[projects](https://github.com/yashhere/Goofy). They are not very extraordinary,
but something is better than nothing. I dived into Debian packaging also and
volunteered for a FOSS event. Spreading awareness about FOSS is also
contributing to FOSS. Isn't it?

Coming back to GSoC, this year, I have successfully submitted a proposal to the
Debian Project. It does not matter whether I get it or not. I overcame one of my
biggest fears of doubting my capabilities. It is something that I was trying to
do for the last two years. This moment is worth celebrating.

Read about my GSoC project on
[Boot Many Machines via Bittorrent](https://wiki.debian.org/SummerOfCode2018/Projects#SummerOfCode2018.2FProjects.2FBootTorrent.Boot_many_machines_via_bittorrent).
It is related to something which I learned in [SSL](http://athena.nitc.ac.in/)
as SSL admin.

Read my project proposal on
[Debian Wiki](https://wiki.debian.org/YashAgarwal/GSoCProposal).

![gsoc timeline](/images/posts/gsoc-timeline.png "gsoc timeline")

Eagerly waiting for the results. :smile:

**Update(24/04/2018)**: Finally, I did not get into GSoC this time too. No
worries. I anticipated the results and prepared backup plans. Looking forward to
a productive summer. :)
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[FOSSMeet'18]]></title>
        <id>https://v2.yashagarwal.in/blog/fossmeet-18</id>
        <link href="https://v2.yashagarwal.in/blog/fossmeet-18"/>
        <updated>2018-03-26T06:27:14.000Z</updated>
        <content type="html"><![CDATA[
I know I am very late in writing this post. It has been almost one and a half
months since the last edition of FOSSMeet is over. I have been a part of
FOSSMeet both as a participant and a volunteer. I want to share some of my
observations, views, and suggestions through this post. I intend to keep a
memory of my most favorite event of NIT Calicut. Juniors can read this post and
think about ways to improve FOSSCell and FOSSMeet. I did the same by reading
Kartik's
[post](http://techglider.in/post/2013/04/14/of-fossmeets-at-nit-calicut/).

Before I start, if you have not read my _post_ on the 2017 edition of the
FOSSMeet, it is a good time to read that first. This post is going to be a
follow up from where I stopped that post. [Here](/blog/fossmeet-17/) is the link
to that post.

I'll start by quoting some lines from the last paragraph of that article.

> I hope that I will find time next year for FOSSMeet, although I would prefer
> to attend FOSSMeet as a participant observing everything silently rather than
> being a part of the organizing team.

These were my views after last year's FOSSMeet. I felt that I was not getting
any benefit from volunteering for FOSSMeet. It is one thing that you help
conducting an event, but on a personal level, I was not learning much. I wanted
to attend talks and learn about free software philosophies, but because I was
busy volunteering for workshops in _SSL_, I could not participate in any
lecture. So I wanted to make sure that in my last FOSSMeet, I do attend all the
talks and learn something new.

But fate had its plans for me. Few days after writing that post, Simsar, the
coordinator of FOSSMeet '17, came to my room and asked me if I would like to
become the next secretary of FOSSCell. Those who don't know, FOSSCell is the
group of people in NITC, who are supposed to work on free and open-source
contribution. But it is not very active for the last few years. Probably the
seniors decided to give me a chance because I was quite active in providing my
suggestions for the FOSSCell when I was in the third year and had shown my
intentions to reinitiate FOSSCell. Anyway, I was not very enthusiastic about
this opportunity and _refused_ to accept it. I thought that the topic was closed
and did not bother about it much.

Fast forward two months, I was at home thinking about the reasons that I could
not get an internship were. I figured out some reasons (a topic reserved for a
later post!) and decided that whatever happens, I will not commit these mistakes
again. A few days later, Simsar messaged me on WhatsApp, asking whether I am
still interested in the post of secretary. This time, I immediately accepted his
offer. I was under the influence of my learnings from past mistakes. And that's
how I became the unexpected (at least for my batchmates) secretary of FOSSCell.

I was placed in the first few days of placement season, so I was free on that
front. CSEA had conducted a Debian packaging workshop at the very beginning of
the semester, but I could not attend that workshop. So I messaged Pirate Praveen
sir privately and asked him whether he can guide me about Debian packaging. As
with most of the senior open source contributors, he was very enthusiastic about
helping me. So that's how I restarted my journey in open source. It was a fun
time learning about free software ideology from Pirate Praveen. We decided to
conduct a small Debian Packaging hackathon in NITC. As it is a norm in CSE NITC
nowadays about any such activity, people did not turn up at all for this
hackathon. Only five people showed up for the hackathon. That was disappointing.
Though, on a personal level, I was satisfied. I submitted two packages to the
Debian unstable repository. We did not have any other activity for the remaining
of that semester.

Okay, enough of the background!

## My Observations

We opted for the [HasGeek's Funnel](https://talkfunnel.com/) for the proposal
acceptance this time also. The funnel works quite well for our workflow. We did
not get many [proposals](https://fossmeet-nitc.talkfunnel.com/2018/) in the
beginning. I had read somewhere on the web that FOSSMeet had a MiniDebConf once.
That seemed like an excellent idea to the team. So I talked with Praveen sir,
about the possibility of a separate Debian track during FOSSMeet. I thought that
Debian packaging might be a good and easy way to introduce NITC students to
Open-source software.

In previous editions of FOSSMeets, the organizers used to receive the
[feedback](http://techglider.in/post/2013/04/14/of-fossmeets-at-nit-calicut/)
that the student audience is entirely novice for some sessions and the
supposedly advanced session turned out to be a beginner session. We were well
aware of this problem and thought of a way to solve this. The solution may be a
controversial one because even I have mixed feelings about this solution. We
decided to look at the GitHub profiles of each participant and then select a few
participants rather than allowing each and everyone who is paying money to
attend the FOSSMeet. Our experience from last year was awful in this aspect.
Students from various colleges of Kerala came to FOSSMeet just to get the
certificate. Such an audience was not contributing anything to FOSSMeet.

Now, let me explain why I think that this is not the right way to filter good
participants. If I am not wrong, one motive behind organizing such _student run
conferences_ is to inspire beginners and college students to learn about free
and open-source software and to allow them to learn about new technologies. Now,
it should not matter if the person has any prior experience or not. In our case,
we prioritized the _previous experience_ part and neglected _the will to learn_.
I know that it is tough to identify if a person is really interested in the
event or just coming for the certificate, but still, there must be some better
way to solve this issue. For now, this method is the best option available, and
it worked well enough for our purpose.

The decision to allow only 150 participants was an excellent move. We had
decided not to have parallel workshops and talks. This decision was a direct
outcome of some of the bad feedback from the previous FOSSMeets. The decisions
to check GitHub profiles and to restrict the number of participants made sure
that this edition of FOSSMeet has the most appropriate (read qualified) audience
for any session.

We publicized the event among CSED's first years. We even had a beginner level
Git workshop for them. We were expecting that they will come to take part in the
event. These events provide excellent opportunities for newcomers to learn about
Computer Science and its various fields. I used to give priority to a CSEA event
over any cultural event when I was in my first year. But, the turnout of
first-year students for FOSSMeet was very less. I sometimes worry, how are these
people going to continue organizing FOSSMeet. In the end, conducting this event
will become a burden (of carrying a legacy) for them, and they will hold this
event just like any other useless event that happens in NITC every weekend. We
even made the entry, free for them; still, if they don't feel interested in the
event, then they are at an apparent loss.

One other complaint that we received from the community was that the procedure
of selecting proposals from the funnel is not transparent. _In my opinion_, it
is true. The organizing team of FOSSMeet sit together and choose the topics
based on the relevance of the topics and its relation to FOSS ideologies. Most
of the proposals in the funnel were related to some technology or programming
language. We aimed to give a chance to the talks which explain more about free
software in general. Most of the proposals selected this year revolved around
this theme with one or two exceptions. But I think it might be a good idea to
publicly tell the factors that are taken into account while selecting proposals.
FOSSMeet is an event about free software and the community, and it is the
responsibility of the organizers to make sure that they adhere to the ideologies
of free software, including transparency.

The decision to select philosophical topics might seem like a great thing.
Still, in reality, the student audience is not very interested in listening to
some random guy preaching about something which is not very relevant to them.
Students want more technical knowledge, which they can get only from technical
talks and workshops. I hope that future FOSSMeet organizers will be more careful
about maintaining the right balance between technical and not technical
discussions and workshops.

Some students from Amrita college complained about our selection of the same
speakers every year. In my opinion, it is a very valid complaint. In my last
three FOSSMeets, almost 3-5 speakers are giving talks/workshops every year. I am
not saying that it is bad in any way, but the organizing team can start a bit
early and invite some other prominent faces of the field from different parts of
the country. The issue is that we begin contacting speakers very late and the
people coming from far corners of the country or from abroad get very little
time for making arrangements.

We used to have panel discussions in FOSSMeet. For the last two years, we
stopped having one. I think that a panel discussion is a great way to learn
about different viewpoints of experienced people. It will be good if the future
organizers can squeeze one such panel discussion in the FOSSMeet schedule.

Now coming to my memories of this edition of the event, I liked the video
conference by Bradley M Kuhn, the president of the Software Freedom Conservancy.
The way he explained current issues in software freedom was fascinating. I was
amazed by his humbleness. I was looking forward to the talk by RMS, but he could
not deliver his speech due to some technical issues.

**On a lighter note**, It feels strange when you are working in a team where
everyone except you speaks a language that you don't understand. I know that it
is a very natural behavior, and I have no _complains_ about it. But in my
opinion, language is a tool of communication, and when you are not able to
communicate your views to others, then there is some problem. When I think about
these issues, I admire the forefathers of India for their farsightedness to make
a _foreign_ but _universal_ language, one of the official languages of the
Republic of India.

## Conclusion

I feel at a loss because I got the chance to attend only three FOSSMeets (2015
edition never came to reality). It has been a great experience both as a
participant and a volunteer for me over the last three years. I have written two
posts about FOSSMeets and have tried to cover everything which I liked or
disliked about this event. I might be very _biased_ in the views expressed here
as I was very disappointed with the lack of any activity from the FOSSCell side
to introduce students about open source contributions. My _lack_ of good
communication skills made sure that the trend continues in my tenure also. I
wish good luck to the next office bearers and hope that they will not continue
this trend. :smile:

Thanks to all fourth years -- Sajmal, **Navaneeth**, Nithin, Kumar, Pavithra,
Vrushabh, Nitin, and others for making the FOSSMeet a success. All the best to
all juniors -- Abhiram, Archana, Olive, Amruth, Gazala, Abhirami, Anupam,
Madhumita, Adil, Vysakh, Arun, and others. Special mention to some second years
also -- Nirmal, Faris, Darshana, Kavitha, Naina, Vishnu, and others for helping
us out in a smooth organization of the event.

Feeling relieved now, as this long overdue post is finally complete. If you find
the article interesting, share your views in the comments section. Thanks for
reading. :relaxed:
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deactivated My Facebook Account]]></title>
        <id>https://v2.yashagarwal.in/blog/deactivated-my-facebook-account</id>
        <link href="https://v2.yashagarwal.in/blog/deactivated-my-facebook-account"/>
        <updated>2018-03-23T15:30:44.000Z</updated>
        <content type="html"><![CDATA[
Today, I deactivated my Facebook account again. For the last few days, I was
feeling that I am using Facebook excessively. It was affecting my work, my
_public life_. I was using Facebook day in and day out. Today when I woke up in
the morning, I first opened Facebook and didn't leave my bed for one hour. I
realized that I had wasted one hour merely browsing through useless stuff.
Immediately, I decided to deactivate the account for some time and analyze how
much my life changes by one less distraction.

Coincidentally, it is the time of [Ragam](http://ragam.org.in/Main/), the annual
cultural festival of NIT Calicut. I _introspect_ myself every year at the same
time. For the last two years, this introspection is resulting in the
deactivation of my Facebook account. It is the reason why I could finish all my
pending projects in the summers.

I sometimes feel that after coming to NITC, I have become much more socially
awkward and even more of a loner than I was before. I never enjoyed going into
public events, but in college, that tendency seems to have increased a lot. Now,
I do not feel comfortable with this state. I want to change this, but every time
I try, there is some _invisible force_ which pulls me back from expressing
myself. NITC's environment was entirely different for a person like me, who
always preferred to stay alone. So, I built a _bubble_ around myself, where
there is no one to disturb or doubt me. It was okay in the initial years of my
campus life when circumstances were not in my favor, but now this bubble is an
obstacle for me. I feel difficulty in coming out of this bubble.

There are only one and a half months left of my undergraduate life. I might not
overcome this fear at this time. But I hope that the change of environment will
help me cross this barrier. I have learned a lot of lessons from my mistakes in
the past, and I hope that I will not repeat one of the biggest mistakes of my
life.

I will write again about the changes I feel after deactivating Facebook. In the
meantime, I will try to spend more time with my friends and less on my laptop.
:relieved:
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Develop a Theme for Hugo]]></title>
        <id>https://v2.yashagarwal.in/blog/develop-a-theme-for-hugo</id>
        <link href="https://v2.yashagarwal.in/blog/develop-a-theme-for-hugo"/>
        <updated>2018-03-02T05:57:05.000Z</updated>
        <content type="html"><![CDATA[
_This article was originally published on
[zeolearn](https://www.zeolearn.com/magazine/develop-a-theme-for-hugo)._

## Introduction

In this tutorial, I will show you how to create a basic Hugo theme. I assume
that you are familiar with basic HTML, and how to write content in markdown. I
will be explaining the working of Hugo and how it uses Go templating language
and how you can use these templates to organize your content. As this post will
be focusing mainly on Hugo's working, I will not be covering CSS here.

We will be starting with some necessary information about the terminology used
in Hugo. Then we will create a Hugo site with a very basic template. Then we
will add new templates and posts to our site as we delve further into Hugo. With
very slight variations to what you will learn here, you will be able to create
different types of real-world websites.

Now, a short tutorial about the flow of this post. The commands that start with
`$` are meant to be run in the terminal or command line. The output of the
command will follow immediately. Comments will begin with `#`.

## Some Terminology

### Configuration File

Hugo uses a configuration file to identify common settings for your site. It is
located in the root of your site. This file can be written in TOML, YAML or JSON
formats. Hugo identifies this file using the extension.

By default, Hugo expects to find Markdown files in your `content/` directory and
template files in your `themes/` directory. It will create HTML files in your
`public/` directory. You can change this by specifying alternate locations in
the configuration file.

### Content

The content files will contain the metadata and text about your posts. A content
file can be divided into two sections, the top section being frontmatter and the
next section is the markdown that will be converted to HTML by Hugo. The content
files reside in `/content` directory.

### Frontmatter

The frontmatter section contains information about your post. It can be written
in JSON, TOML or YAML. Hugo identifies the type of frontmatter used with the
help of identifying tokens(markers). TOML is surrounded by `---`, YAML is by
`---` and JSON is enclosed in curly braces `{` and `}`. The information in the
front matter of a content type will be parsed to be used in the template for
that specific content type while converting to HTML.

I prefer to use YAML, so you might need to translate your configurations if you
are using JSON or TOML.

This is an example of frontmatter written in YAML.

```yaml
---
date: "2018-02-11T11:45:05+05:30"
title: "Basic Hugo Theming Tutorial."
description:
  "A primer about theme development for Hugo, a static site generator written in
  Golang."
categories:
  - Hugo
  - Customization
tags:
  - Theme
---
```

You can read more about different configuration options available for
frontmatter [here](https://gohugo.io/content-management/front-matter/#readout).

### Markdown

The markdown section is where you will write your actual post. The content
written here will automatically be converted to HTML by Hugo with the help of a
Markdown engine.

### Templates

In Hugo, templates govern the way; your content will be rendered to HTML. Each
template provides a consistent layout when rendering the markdown content. The
templates reside in the `/layouts` directory.

There are three types of templates: _single_, _list_ and _partial_. Each kind of
template take some content as input and transform it according to the way
defined in the template.

#### Single Template

A single template is used to render a single page. The best example of this is
_about_ page.

#### List Template

A list template renders a group of related content. It can be all recent posts
or all posts belonging to a particular category.

The homepage template is a specific type of list template. Hugo assumes that the
homepage will serve as a bridge to all the other content on your website.

### Partials

Partials are short code snippets that can be injected in any other template
type. They are instrumental when you want to repeat some content on every page
of your website. The header and footer content are good candidates to be
included in separate partials. It is a good practice to use partials liberally
in your Hugo site as it adheres to
[DRY](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself) principle.

## Okay, Let's Start

So now that you have a basic understanding of Hugo, we will create a new site
using Hugo. Hugo provides a command to generate new sites. We will use that
command to scaffold our site. It will create a basic skeleton of your site and
will give you a basic configuration file.

```yaml
$ hugo new site ~/zeo $ cd ~/zeo $ ls -l total 28 drwxr-xr-x 2 yash hogwarts
4096 Feb 11 11:13 archetypes -rw-r--r-- 1 yash hogwarts   82 Feb 11 11:13
config.toml drwxr-xr-x 2 yash hogwarts 4096 Feb 11 11:13 content drwxr-xr-x 2
yash hogwarts 4096 Feb 11 11:13 data drwxr-xr-x 2 yash hogwarts 4096 Feb 11
11:13 layouts drwxr-xr-x 2 yash hogwarts 4096 Feb 11 11:13 static drwxr-xr-x 2
yash hogwarts 4096 Feb 11 11:13 themes
```

**Note:** I will use YAML format for the config file. Hugo, By default, uses
TOML format.

A small description of this directory structure:

- **archetypes**: The archetypes contains predefined frontmatter format for your
  website's content types. It facilitates consistent metadata format across all
  the content of your site.
- **content**: The content directory contains the markdown files that will be
  converted to HTML and served to the user.
- **data**: From Hugo documentation

  > The data folder is where you can store additional data for Hugo to use when
  > generating your site. Data files are not used to generate standalone pages;
  > rather, they are meant to be supplemental to content files. This feature can
  > extend the content in case your front matter fields grow out of control. Or
  > perhaps you want to show a larger dataset in a template (see example below).
  > In both cases, it is a good idea to outsource the data in their files.

- **layouts**: The layouts folder stores all the templates files which form the
  presentation of the content files.
- **static**: The static folder will contain all the static assets such as
  `CSS`, `JS` and `image` files.
- **themes**: The themes folder is where we will be storing our theme.

We will edit the `config.yaml` file to edit some basic configuration of the
site.

```sh
$ vim config.yaml
baseURL: /
title: "My First Blog"
defaultContentLanguage: en
languages:
  en:
    lang: en
    languageName: English
    weight: 1
MetaDataFormat: "yaml"
```

Now when you run your site, Hugo will show some errors. It is normal because our
layouts and themes directories are still empty.

```sh
$ hugo --verbose
INFO 2018/02/11 11:20:59 Using config file: /home/yash/zeo/config.yaml
Building sites … INFO 2018/02/11 11:20:59 syncing static files to /home/yash/zeo/public/
WARN 2018/02/11 11:20:59 No translation bundle found for default language "en"
WARN 2018/02/11 11:20:59 Translation func for language en not found, use default.
WARN 2018/02/11 11:20:59 i18n not initialized, check that you have language file (in i18n) that matches the site language or the default language.
WARN 2018/02/11 11:20:59 [en] Unable to locate layout for "taxonomyTerm":
...
...
```

This command will also create a new directory called `public/`. This is the
directory where Hugo will save all the generated HTML files related to your
site. It also stores all static data in this folder.

Let's have a look at the `public` folder.

```sh
$ ls -l public/
total 16
drwxr-xr-x 2 yash hogwarts 4096 Feb  11 11:22 categories
-rw-r--r-- 1 yash hogwarts  400 Feb  11 11:25 index.xml
-rw-r--r-- 1 yash hogwarts  383 Feb  11 11:25 sitemap.xml
drwxr-xr-x 2 yash hogwarts 4096 Feb  11 11:22 tags
```

Hugo generated some XML files, but there are no HTML files. It is because we
have not created any content in our content directory yet.

At this point, you have a working site with you. All that is left is to add some
content and a theme to your site.

### Create a new theme

Hugo doesn't ship with a default theme. There are a lot of themes available on
Hugo website. Hugo also ships with a command to create new themes.

In this tutorial, we will be creating a theme called `zeo`. As mentioned
earlier, my aim is to show you how to use Hugo's features to fill out your HTML
files from the markdown content, I will not be focusing on CSS. So the theme
will be ugly but functional.

Let's create a basic skeleton of the theme. It will create the directory
structure of the theme and place empty files for you to fill in.

```sh
# run it from the root of your site
$ hugo new theme zeo
$ ls -l themes/zeo/
total 20
drwxr-xr-x 2 yash hogwarts 4096 Feb 11 11:30 archetypes
drwxr-xr-x 4 yash hogwarts 4096 Feb 11 11:30 layouts
-rw-r--r-- 1 yash hogwarts 1081 Feb 11 11:30 LICENSE.md
drwxr-xr-x 4 yash hogwarts 4096 Feb 11 11:30 static
-rw-r--r-- 1 yash hogwarts  432 Feb 11 11:30 theme.toml
```

Fill out `LICENSE.md` and `theme.toml` file if you plan to distribute your theme
to outside world.

Now we will edit our `config.yaml` file to use this theme.

```sh
$ vim config.yaml
theme: "zeo"
```

Now that we have an empty theme, let's build the site.

```sh
$ hugo --verbose
INFO 2018/02/11 11:34:14 Using config file: /home/yash/zeo/config.yaml
Building sites … INFO 2018/02/11 11:34:14 syncing static files to /home/yash/zeo/public/
WARN 2018/02/11 11:34:14 No translation bundle found for default language "en"
WARN 2018/02/11 11:34:14 Translation func for language en not found, use default.
WARN 2018/02/11 11:34:14 i18n not initialized, check that you have language file (in i18n) that matches the site language or the default language.

                   | EN
+------------------+----+
  Pages            |  3
  Paginator pages  |  0
  Non-page files   |  0
  Static files     |  0
  Processed images |  0
  Aliases          |  0
  Sitemaps         |  1
  Cleaned          |  0

Total in 12 ms
```

These warnings are harmless in our case, as we are developing our site in
English only.

Hugo does two things while generating your website. It transforms all the
content files to HTML using the defined templates, and its copies static files
into the site. Static files are not transformed by Hugo. They are copied exactly
as they are.

### The Cycle

The usual development cycle when developing themes for Hugo is:

- Delete the `/public` folder
- Run the built-in web server and open your site in the browser
- Make changes to your theme files
- View your changes in browser
- Repeat step 3

It is necessary to delete the `public` directory because Hugo does not try to
remove any outdated files from this folder. So the old data might interfere with
your workflow.

It is also a good idea to track changes in your theme with the help of a version
control software. I prefer Git for this. You can use others according to your
preference.

### Run your site in the browser

Hugo has a built-in web server which helps considerably while developing themes
for Hugo. It also has a _live reload_ and _watch_ feature which watches for
changes in your files and reloads the web page accordingly.

Run it with `hugo server` command.

Now open [http://localhost:1313](http://localhost:1313) in your browser. By
default, Hugo will not show anything, because it cannot find any HTML file in
the public directory.

The command to load web server with `--watch` option is:

```sh
$ hugo server --watch --verbose
...
...
                   | EN
+------------------+----+
  Pages            |  4
  Paginator pages  |  0
  Non-page files   |  0
  Static files     |  0
  Processed images |  0
  Aliases          |  0
  Sitemaps         |  1
  Cleaned          |  0

Total in 11 ms
...
...

```

### Update the Home page template

Hugo looks for following directories in theme's `/layout` folder to search for
`index.html` page.

- index.html
- \_default/list.html
- \_default/single.html

It is always desirable to update the most specific template related to the
content type. It is not a hard and fast rule, but a good generalization to
follow.

We will first make a static page to see if our `index.html` page is rendered
correctly.

```html
$ vim themes/zeo/layouts/index.html
<!DOCTYPE html>
<html>
  <body>
    <p>Hello World!</p>
  </body>
</html>
```

Build the site and verify the results. You should see _Hello World!_ when you
open [http://localhost:1313](http://localhost:1313).

### Building a functional Home Page

Now we will create a home page which will reflect the content of our site every
time we build it.

For that, we will first create some new posts. We will display these posts as a
list on the home page and on their pages, too.

Hugo has a command for generating skeleton of posts, just like it did for sites
and themes.

```sh
$ hugo --verbose new post/first.md
INFO 2018/02/11 11:40:58 Using config file: /home/yash/zeo/config.yaml
INFO 2018/02/11 11:40:58 attempting to create "post/first.md" of "post" of ext ".md"
INFO 2018/02/11 11:40:58 curpath: /home/yash/zeo/archetypes/default.md
...
...
/home/yash/zeo/content/post/first.md created
```

The `new` command uses an archetype to generate the frontmatter for new posts.
When we created our site, hugo created a default archetype in the `/archetype`
folder.

```sh
$ cat archetypes/default.md
---
title: "{{ replace .Name "-" " " | title }}"
date: {{ .Date }}

---
```

It is a good idea to create a default archetype in the themes folder also so
that users can override the theme's archetype with their archetype whenever they
want.

We will create a new archetype for our posts' frontmatter and delete the default
`archetype/default.md`.

```sh
$ rm -rf archetype/default.md
$ vim themes/zeo/archetypes/post.md
---
title: "{{ replace .Name "-" " " | title }}"
date: {{ .Date }}
Description: ""
Tags: []
Categories: []

---
```

Create one more post in `content/post` directory.

```sh
$ hugo --verbose new post/second.md
INFO 2018/02/11 12:13:56 Using config file: /home/yash/zeo/config.yaml
INFO 2018/02/11 12:13:56 attempting to create "post/second.md" of "post" of ext ".md"
INFO 2018/02/11 12:13:56 curpath: /home/yash/zeo/themes/zeo/archetypes/post.md
...
...
/home/yash/zeo/content/post/second.md created
```

See the difference. Hugo used the theme's archetype for generating the
frontmatter this time.

By default, Hugo does not generate posts with an empty content section. So you
will need to add some content before you try to build the site.

Let's look at the `content/post/first.md` file, after adding content to it.

```sh
$ cat content/post/first.md
---
title: "First"
date: 2018-02-11T11:35:58+05:30
draft: true
Tags: ["first"]
Categories: ["Hugo"]

---

Hi there. My first Hugo post
```

Now that our posts are ready, we need to create templates to show them in a list
on the home page and to show their content on separate pages for each post.

We will first edit the template for the home page that we created previously. We
will then modify "single" templates which are used to generate output for a
single content file. We also have "list" templates which are used to group
similar type of content and render them as a list. The home page will show a
list of last ten posts that we have created. Let's update its template to add
this logic.

### Update your home page to show your content

Now add your template code to `themes/zeo/layouts/index.html`.

```html
$ vim themes/zeo/layouts/index.html $ cat !$ cat themes/zeo/layouts/index.html
<!DOCTYPE html>
<html>
  <body>
    {{ range first 10 .Data.Pages }}
    <h1>{{ .Title }}</h1>
    {{ end }}
  </body>
</html>
```

Hugo uses Go Template Engine. This engine scans the templates for commands that
are enclosed between `{{` and `}}`. In this template, the commands are `range`,
`first`, `.Data.Pages`, `.Title` and `end`.

The template implies that we are going to get first 10 latest pages from our
content folder and render their title as `h1` heading.

`range` is an iterator function. Hugo treats every HTML file created as a page,
so `range` will loop through all the pages created. Here we are instructing
`range` to stop after first ten pages.

The `end` command signals the end of the _range_ iterator. The engine loops back
to the next iteration as soon as it encounters the _end_ command. Everything
between _range_ and _end_ will be evaluated for each iteration of the loop.

Build the website and see the changes. The homepage now shows our two posts.
However, you cannot click on the posts and read their content. Let's change that
too.

### Linking your posts on Home Page

Let's add a link to the post's page from home page.

```html
$ vim themes/zeo/layouts/index.html
<!DOCTYPE html>
<html>
  <body>
    {{ range first 10 .Data.Pages }}
    <h1>
      <a href="{{ .Permalink }}">{{ .Title }}</a>
    </h1>
    {{ end }}
  </body>
</html>
```

Build your site and see the result. The titles are now links, but when you click
on them, it takes you to a page which says `404 page not found`. That is
expected because we have not created any template for the single pages where the
content can be rendered. So Hugo could not find any template, and it did not
output any HTML file. We will change that in a minute.

We want to render the posts, which are in `content/post` directory. That means
that their section is post and their type is also post.

Hugo uses section and type information to identify the template file for each
piece of content. It will first look for a template file which matches the
section or type of the content. If it could not find it, then it will use
`_default/single.html` file.

Since we do not have any other content type yet, we will just start by updating
the `_default/single.html` file.

Remember that Hugo will use this file for every content type for which we have
not created a template. However, for now, we will accept that cost as we do not
have any other content type with us. We will refactor our templates to
accommodate more content types, as we add more content.

Update the template file.

```html
$ vim themes/zeo/layouts/_default/single.html
<!DOCTYPE html>
<html>
  <head>
    <title>{{ .Title }}</title>
  </head>
  <body>
    <h1>{{ .Title }}</h1>
    {{ .Content }}
  </body>
</html>
```

Build the site and verify the results. You will see that on clicking on `first`,
you get the usual result, but clicking on `second` still produces the
`404 page not found` error. It is because Hugo does not generate pages with
empty content. Remember I mentioned it earlier.

Now that we have our home page and posts page ready, we will build a page to
list all the posts, not just the recent ten posts. This page will be accessible
at [http://localhost:1313/post](http://localhost:1313/post). Currently, this
page is blank because there is no template defined for it.

This page will show the listings of all the posts, so the type of this page will
be a list. We will again use the default `_default/list.html` as we do not have
any other content type with us.

Update the list file.

```html
$ vim themes/zeo/layouts/_default/list.html
<!DOCTYPE html>
<html>
  <body>
    {{ range .Data.Pages }}
    <h1><a href="{{ .Permalink }}">{{ .Title }}</a></h1>
    {{ end }}
  </body>
</html>
```

### Add "Date Published" to the posts

It is a standard practice to add the date on which the post was published on the
blog. The front matter of our posts has a variable named `date`. We will use
that variable to fetch the date. Our posts are using the default _single_
template, so we will edit that file.

```html
$ vim themes/zeo/layouts/_default/single.html
<!DOCTYPE html>
<html>
  <head>
    <title>{{ .Title }}</title>
  </head>
  <body>
    <h1>{{ .Title }}</h1>
    <h2>{{ .Date.Format "Sun, Feb 11, 2018" }}</h2>
    {{ .Content }}
  </body>
</html>
```

---

## Adding top-level Pages

Okay, so now that we have our homepage, post-list page and post content pages in
place, we will add a new _about_ page at the top level of our blog, not at a
sublevel like we did for posts.

Hugo uses the directory structure of the content directory to identify the
structure of the blog. Let's verify that and create a new `about` page in the
content directory.

```yaml
$ vim content/about.md
---
title: "about"
description: "about this blog"
date: "2018-02-11"
---
### about me

Hi there, you just reached my blog.
```

Let's generate the site and view the results.

```sh
$ hugo --verbose
$ ls -l public/
total 36
drwxr-xr-x 2 yash hogwarts 4096 Feb 11 12:43 about
drwxr-xr-x 3 yash hogwarts 4096 Feb 11 12:43 categories
drwxr-xr-x 2 yash hogwarts 4096 Feb 11 11:20 css
-rw-r--r-- 1 yash hogwarts  187 Feb 11 12:43 index.html
-rw-r--r-- 1 yash hogwarts 1183 Feb 11 12:43 index.xml
drwxr-xr-x 2 yash hogwarts 4096 Feb 11 11:20 js
drwxr-xr-x 4 yash hogwarts 4096 Feb 11 12:43 post
-rw-r--r-- 1 yash hogwarts 1139 Feb 11 12:43 sitemap.xml
drwxr-xr-x 3 yash hogwarts 4096 Feb 11 12:43 tags
```

Notice that Hugo created a new directory `about`. This directory contains only
one file `index.html`. The about page will be rendered from `about/index.html`.

If you look carefully, the `about` page is listed with the posts on the
homepage. It is not desirable, so let's change that first.

```html
$ vim themes/zeo/layouts/index.html
<!DOCTYPE html>
<html>
  <body>
    <h1>posts</h1>
    {{ range first 10 .Data.Pages }} {{ if eq .Type "post"}}
    <h2><a href="{{ .Permalink }}">{{ .Title }}</a></h2>
    {{ end }} {{ end }}

    <h1>pages</h1>
    {{ range .Data.Pages }} {{ if eq .Type "page" }}
    <h2><a href="{{ .Permalink }}">{{ .Title }}</a></h2>
    {{ end }} {{ end }}
  </body>
</html>
```

Now build the site and verify the results. The homepage now has two sections,
one for posts and other for the pages. Click on the _about_ page. You will see
the page for _about_. Remember, I mentioned that Hugo would use the _single_
template for each page, for which it cannot find a template file. There is still
one issue. The _about_ page shows the date also. We do not want to show the date
on the _about_ page.

There are a couple of ways to fix this. We can add an if-else statement to
detect the type of the content and display date only if it is a post. However,
let's use the feature provided by Hugo and create a new template type for the
posts. Before we do that, let's learn to use one more template type which is
_partials_.

## Partials

In Hugo, partials are used to store the shared piece of code which repeats in
more than one templates. Partials are kept in `themes/zeo/layouts/partials`
directory. Partials can be used to override the themes presentation. End users
can use them to change the default behavior of a theme. It is always a good idea
to use partials as much as possible.

### Header and Footer partials

Header and footer of most of the posts and pages will follow a similar pattern.
So they form an excellent example to be defined as a partial.

```html
$ vim themes/zeo/layouts/partials/header.html
<!DOCTYPE html>
<html>
  <head>
    <title>{{ .Title }}</title>
  </head>
  <body>
    $ vim themes/zeo/layouts/partials/footer.html
  </body>
</html>
```

We can call a partial by including this path in the template

```go
{{ partial "header.html" . }}
```

## Update the Homepage template

Let's update our homepage template to use these partials.

```html
$ vim themes/zeo/layouts/index.html {{ partial "header.html" . }}

<h1>posts</h1>
{{ range first 10 .Data.Pages }} {{ if eq .Type "post"}}
<h2><a href="{{ .Permalink }}">{{ .Title }}</a></h2>
{{ end }} {{ end }}

<h1>pages</h1>
{{ range .Data.Pages }} {{ if or (eq .Type "page") (eq .Type "about") }}
<h2>
  <a href="{{ .Permalink }}"
    >{{ .Type }} - {{ .Title }} - {{ .RelPermalink }}</a
  >
</h2>
{{ end }} {{ end }} {{ partial "footer.html" . }}
```

## Update the single template

```html
$ vim themes/zeo/layouts/_default/single.html {{ partial "header.html" . }}

<h1>{{ .Title }}</h1>
<h2>{{ .Date.Format "Sun, Feb 11, 2018" }}</h2>
{{ .Content }} {{ partial "footer.html" . }}
```

Build the website and verify the results. The title on the posts and the about
page should both reflect the value from the markdown file.

## Fixing the date shown on About page

Remember, we had the issue that the date was showing on the _about_ page also.
We discussed one method to solve this issue. Now I will discuss a more _hugoic_
way of solving this issue.

We will create a new section template to fix this issue.

```html
$ mkdir themes/zeo/layouts/post $ vim themes/zeo/layouts/post/single.html {{
partial "header.html" . }}

<h1>{{ .Title }}</h1>
<h2>{{ .Date.Format "Mon, Jan 2, 2006" }}</h2>
{{ .Content }} {{ partial "footer.html" . }} $ vim
themes/zeo/layouts/_default/single.html
<!DOCTYPE html>
<html>
  <head>
    <title>{{ .Title }}</title>
  </head>
  <body>
    <h1>{{ .Title }}</h1>
    {{ .Content }}
  </body>
</html>
```

Note that we have changed the default _single_ template and added that logic in
post's _single_ template.

Build the website and verify the results. The _about_ page does not show the
date now, but the posts page still show the date. We can also move the list
template's logic to the `index.html` file of post section template.

## Conclusion

We have learnt, how Hugo harnesses the powerful yet simple Go template engine to
create the static site generator. We also learnt about partials and their
excellent utilization by Hugo in the spirit of _Don't Repeat Yourself_
principle. Now that you know how to make themes in Hugo, go ahead and start
creating new beautiful themes. Best of luck for your endaevour.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[My New Domain]]></title>
        <id>https://v2.yashagarwal.in/blog/my-new-domain</id>
        <link href="https://v2.yashagarwal.in/blog/my-new-domain"/>
        <updated>2018-02-25T04:40:04.000Z</updated>
        <content type="html"><![CDATA[
I bought a new domain a few days back - _yashagarwal.in_. I was trying to buy
this domain for the last two years, but it was already taken. My previous
domain, _yashagarwal.me_ that I got for free via GitHub education pack, was good
enough for me, but the thought that I own a domain which is a top-level domain
of some other country was in itself something which was not comfortable to me.
So when I got the chance to buy this domain, I didn't delay. Hope this domain
will remain my personal home on the web for years to come.

The domain is mapped with GitLab, and the SSL certificates are provided by
[Let's Encrypt](https://letsencrypt.org/). Let's Encrypt requires you to renew
the SSL certificates every 90 days. That seems like a manual work to me.
Moreover, my new registrar, GoDaddy, provides a complete API for their domain
services. So I am planning to write a script that utilizes the APIs of
[GitLab](https://gitlab.com/help/api/README.md) and
[GoDaddy](https://developer.godaddy.com/) to deploy the SSL certificates
automatically. I will probably use the DNS based authentication to verify the
ownership of my domain, as that seems the only method that does not require any
modification on the host side. I will write a post with all the details about
the script, once I finish implementing it.

That's all for this post. See you next time. :)
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Syncing Time on Windows & GNU/Linux Dual Boot Setups]]></title>
        <id>https://v2.yashagarwal.in/blog/syncing-time-on-windows-gnu-linux-dual-boot-setups</id>
        <link href="https://v2.yashagarwal.in/blog/syncing-time-on-windows-gnu-linux-dual-boot-setups"/>
        <updated>2018-02-01T07:24:34.000Z</updated>
        <content type="html"><![CDATA[
This post is going to be one of those that I have written for my reference.
Whatever I am going to mention in this post is not new. Everything has already
been said and written many times on many websites and Linux forums.

So I will start by explaining the problem. When you try to dual boot your
machine to run both GNU/Linux and Windows operating systems, you might have
noticed that the time is not the same in both the operating systems. It is
generally one operating system showing the correct time, and the other one
showing the wrong time. It happens because Microsoft Windows thinks that the
hardware clock (CMOS clock or BIOS clock) of the machine is using the local time
(depends on your current time zone), and hence it doesn't do anything and shows
you the same time. But most GNU/Linux operating systems (Ubuntu, Arch Linux,
etc.) think that the hardware clock is set to track UTC. Hence the mismatch in
the time happens. For example, assume that the current real-time is 10:22:51,
and the hardware clock time is set to 10:22:51. Windows will interpret this time
as local time and show 10:22:51, but Linux based systems will show 15:52:51
because they will understand this time as UTC. Of course, the above example is
true if we assume time zone as India, which is +05:30 from UTC.

This issue can be fixed either from Windows or from GNU/Linux OS. I prefer to
adjust the behavior of Windows to use UTC. It is much more convenient to use
when traveling between different time zones. Please note that this method might
not work or cause instability with older versions of Windows OS. I have tried
this fix on Windows 10, and it works without any issues.

Open an Administrator Command Prompt by pressing `⊞ + x`, then type `a`. This
method of opening the Administrator Command Prompt does not work on Windows 7.

Now execute the following command:

```sh
reg add "HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\TimeZoneInformation" /v RealTimeIsUniversal /d 1 /t REG_DWORD /f
```

Windows Time Service, which keeps the clock in Windows OS accurate, will still
write the local time to the Real-time clock (RTC) regardless of the registry
settings on shutdown. So I prefer to disable the Windows Time Service.

```sh
sc config w32time start= disabled
```

Now you may need to change the time in your BIOS to UTC time, although that
depends on whether your Windows OS was showing the correct time before applying
the above modifications. If yes, then changing BIOS time to UTC will make sure
that both Windows and GNU/Linux convert hardware clock to local time.

---

## References

1. [Multiple Boot Systems Time Conflicts](https://help.ubuntu.com/community/UbuntuTime#Multiple_Boot_Systems_Time_Conflicts)
2. [UTC in Windows](https://wiki.archlinux.org/index.php/Time#UTC_in_Windows)
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why a Sanskrit Shloka?]]></title>
        <id>https://v2.yashagarwal.in/blog/why-a-sanskrit-shloka</id>
        <link href="https://v2.yashagarwal.in/blog/why-a-sanskrit-shloka"/>
        <updated>2018-01-30T14:59:00.000Z</updated>
        <content type="html"><![CDATA[
> श्रूयतां धर्मसर्वस्वं श्रुत्वा चाप्यवधार्यताम् । <br /> आत्मनः प्रतिकूलानि
> परेषां न समाचरेत् ।।
>
> If the entire Dharma can be said in a few words, then it is — that which is
> unfavorable to us, do not do that to others.<br />
>
> — Padmapuraana, shrushti 19/357-358

So when you landed on this blog, the first thing you might have noticed is that
the home page of this blog has a Sanskrit shloka. Many people ask me, why did I
choose to display a Sanskrit shloka on my blog.

There is no one answer to this question. There have been several incidents in my
undergraduate life, which have given me a lot of good and evil memories. This
shloka summarizes all those experiences that I earned in NIT Calicut during my
undergraduate course. It reminds me, how I should treat others to receive
similar treatment.

It was my first time away from home and family when I got admission in NIT
Calicut. I was very naive about judging people. I got to know many new people in
NITC. That is when I learned that not everyone is helping you. People are here
to exploit you, and they will do anything to achieve their goals and to get
success, whether it comes at the price of someone else's loss. It is the harsh
truth of life, and the sooner one understands this, the better. I realized this
in my second year, and that is when my life changed. Thankfully, I did not find
other such people after my first year. However, life is very long, and I am
bound to find such people at some point in my life again. I hope the experience
that I earned in NITC will help me face that time.

Now, to the second part of the question, why Sanskrit? A quick Google search
reveals that this shloka represents the concept of
[Golden Rule](https://en.wikipedia.org/wiki/Golden_Rule), which is common to
most world religions, and Hinduism is no exception here. There is even a
[question](https://hinduism.stackexchange.com/questions/21431/what-all-hindu-scriptures-advocate-the-golden-rule-and-what-is-the-oldest-hindu)
about the relation of this shloka with Hinduism. I studied Sanskrit for six
years till my 10<sup>th</sup> standard and feel a connection to it. Besides,
Hindi is my mother tongue, so Sanskrit was the obvious choice given that there
is not much Hinduism related literature available in Hindi.

**Edit(23/03/2018)**: I have removed the shloka from the front page now. I am
keeping this post for historical purpose.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Arch Linux Installation Guide Part 2]]></title>
        <id>https://v2.yashagarwal.in/blog/arch-linux-installation-guide-part-2</id>
        <link href="https://v2.yashagarwal.in/blog/arch-linux-installation-guide-part-2"/>
        <updated>2018-01-26T10:15:27.000Z</updated>
        <content type="html"><![CDATA[
In this post, I will continue from my last
[post](/blog/arch-linux-installation-part-1/) and set up my newly installed Arch
Linux for daily use. I am going to install some applications that I use on a day
to day basis. Some of these applications are required for my current dotfile
[configuration](/blog/my-own-configuration-manager/) setup to work properly. The
choice of applications is highly opinionated and your preferences might be
different.

If you had gone for installation via SSH option, then I would suggest you to
edit your `sshd_config` file and disable `root` login. It can be a security risk
otherwise.

### Install a terminal based browser

Terminal-based browsers are very handy in cases when you are required to login
into a captive portal and you don't have access to a graphical browser. We will
install two different browsers, `elinks` and `w3m`.

```bash
sudo pacman -S elinks w3m
```

### Install X server.

```bash
sudo pacman -S xorg
```

This will install minimal X desktop environment with fonts, in case, you want to
test your system before installing any desktop environment.

### Enable multilib repository for 32-bit package support

To enable multilib repository, uncomment the `[multilib]` section in
`/etc/pacman.conf`.

```bash
[multilib]
Include = /etc/pacman.d/mirrorlist
```

Now upgrade your system.

```bash
sudo pacman -Syyu
```

### Install video and touchpad drivers

```bash
sudo pacman -S xf86-video-intel xf86-input-synaptics
```

### Install pacaur to fetch and install packages from AUR

```bash
sudo pacman -S expac yajl --noconfirm
cd /tmp
gpg --recv-keys --keyserver hkp://pgp.mit.edu:80 1EB2638FF56C0C53
curl -o PKGBUILD https://aur.archlinux.org/cgit/aur.git/plain/PKGBUILD?h=cower
makepkg -i PKGBUILD --noconfirm
curl -o PKGBUILD https://aur.archlinux.org/cgit/aur.git/plain/PKGBUILD?h=pacaur
makepkg -i PKGBUILD --noconfirm
cd
```

### Install graphical browsers

```bash
pacaur -S firefox chromium
```

### Install code editors

```bash
pacaur -S sublime-text-dev atom-editor-git visual-studio-code-bin neovim neovim-drop-in leafpad
```

### Setup LAMP stack

#### Install Apache server

```bash
sudo pacman -S apache

# Make your user-directory available to apache server
mkdir ~/public_html
chmod o+x ~
chmod o+x ~/public_html
chmod -R o+r ~/public_html
```

```bash
# To enable virtualhosts, uncomment the following line in `/etc/httpd/conf/httpd.conf`
Include conf/extra/httpd-vhosts.conf
```

Add your virtualhost configuration in following file -

```bash
sudo vim /etc/httpd/conf/extra/httpd-vhosts.conf
```

To test the virtual hosts on you local machine, add the virtual names to your
`/etc/hosts` file.

#### Install PHP:

```bash
sudo pacman -S php php-apache
```

To use PHP with apache, open `/etc/httpd/conf/httpd.conf` and uncomment
following line -

```bash
LoadModule mpm_prefork_module modules/mod_mpm_prefork.so
```

and comment out the following line -

```bash
# LoadModule mpm_event_module modules/mod_mpm_event.so
```

Now add these lines to `/etc/httpd/conf/httpd.conf`:

```bash
# Add these at the end of `LoadModule` section.
LoadModule php7_module modules/libphp7.so
AddHandler php7-script .php

# Place this at the end of the `Include` section:
Include conf/extra/php7_module.conf
```

#### Install MySQL server

```bash
sudo pacman -S mariadb

# Initialize the MariaDB data directory prior to starting the service. To do so, run:
sudo mysql_install_db --user=mysql --basedir=/usr --datadir=/var/lib/mysql

# Then issue the commands to start the database server
sudo systemctl enable mariadb.service
sudo systemctl start mariadb.service

# To apply recommended security settings to your database, run
sudo mysql_secure_installation
```

#### Install PHPMyAdmin

```bash
sudo pacman -S phpmyadmin php-mcrypt
```

Enable `mysqli`, `mcrypt`, `zip` and `bz2` extensions in `/etc/php/php.ini`.

Create the apache configuration file `/etc/httpd/conf/extra/phpmyadmin.conf`

```apache
Alias /phpmyadmin "/usr/share/webapps/phpMyAdmin"
<Directory "/usr/share/webapps/phpMyAdmin">
    DirectoryIndex index.php
    AllowOverride All
    Options FollowSymlinks
    Require all granted
</Directory>
```

Then include following in `/etc/httpd/conf/httpd.conf`

```apache
# phpMyAdmin configuration
Include conf/extra/phpmyadmin.conf
```

Now restart `httpd` service to apply settings.

```bash
sudo systemctl restart httpd
```

Once all these steps are done, your LAMP stack should be working.

### Setup power management

Install `tlp` and some of its optional dependencies

```bash
sudo pacman -S tlp tlp-rdw bash-completion ethtool lsb-release smartmontools
```

Then enable `tlp` services

```bash
sudo systemctl enable tlp.service
sudo systemctl enable tlp-sleep.service

# mask some services for tlp to work properly
sudo systemctl mask systemd-rfkill.service
sudo systemctl mask systemd-rfkill.socket
```

### Install i3 and other tools

All these tools are part of my `i3` config with exception of the theme related
packages. So installing them here will help me later while setting up the `i3`
window manager.

```bash
pacaur -S i3 rofi polybar xautolock powerline-fonts-git i3lock-fancy-git compton scrot feh dunst unclutter xfce4-power-manager numlockx lxappearance adapta-gtk-theme gtk-engine-murrine gnome-themes-standard termite
```

### Fix Ugly Fonts [^1]

Fonts rendering is one area where Linux still lags behind Windows and OSX. It
can be a nightmare for users to setup fonts properly in Linux. In Arch Linux,
this is even worse. I found some tricks to improve the quality of font rendering
on Arch Linux. Though this is far from perfect, it is manageable. Follow these
[steps](https://www.reddit.com/r/archlinux/comments/5r5ep8/make_your_arch_fonts_beautiful_easily/)
on Reddit to fix font rendering. I use Noto Sans, Adobe Source Code Pro, and
Microsoft fonts. My apologies, but I can't help here. Some websites still use
Microsoft fonts.

### Setup Python Environment

I use Python extensively and virtual environments are a must for my development
setup. I use `pipenv` to manage my virtual environments. To install `pipenv`,
you need to install `virtualenv` first. To install it, run the following
command.

```bash
sudo pacman -S python-virtualenv
```

Now you are ready to install `pipenv`. Follow
[here](https://pipenv.pypa.io/en/latest/) to install the tool.

### Install some other common tools

```bash
sudo pacman -S vlc openssh npm imagemagick git la-capitaine-icon-theme-git
```

Do not forget to
[setup](https://stackoverflow.com/questions/10081293/install-npm-into-home-directory-with-distribution-nodejs-package-ubuntu/13021677#13021677)
`npm` to install packages globally without requiring `sudo`.

That's all! Your system should be in working condition now. Do check out my
[dotfiles](/blog/my-own-configuration-manager/) if you want to set up your
system like mine.

Hope you enjoyed the article. Cheers :smile:

[^1]:
    [Make your Arch fonts beautiful easily!](https://www.reddit.com/r/archlinux/comments/5r5ep8/make_your_arch_fonts_beautiful_easily/)
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Arch Linux Installation Guide Part 1]]></title>
        <id>https://v2.yashagarwal.in/blog/arch-linux-installation-guide-part-1</id>
        <link href="https://v2.yashagarwal.in/blog/arch-linux-installation-guide-part-1"/>
        <updated>2018-01-24T16:19:05.000Z</updated>
        <content type="html"><![CDATA[
Arch Linux is a Linux distribution known for its not-so-beginner-friendly
command line installer, no ready-to-use system after installation and
requirement of above average knowledge of command line. However, Arch Linux
allows me to set up a system in my desired state in shortest possible time with
least effort. This is why I keep coming back to Arch Linux even after some of
its annoyances.

This guide is written primarily for my reference, as someone who has installed
Arch Linux several times, I still can't remember all the installation steps
perfectly. Most of the steps have been taken from
[Arch wiki](https://wiki.archlinux.org/index.php/installation_guide) and should
work on other setups also.

All the commands are run in root shell unless otherwise specified.

## 0. Check your network connection

If you are behind a captive portal, use `links` to open browser and login into
your network. For WiFi connections, use `wifi-menu`. LAN connections should not
require any setup. The boot environment should automatically detect any wired
connections. After connecting, test your connection by pinging any website:

```bash
ping -c 5 google.com
```

## 1. Setup SSH

This step is not mandatory, though I prefer to use this method to install Arch
Linux, as it provides me the convenience of copying and pasting the commands
directly from Arch wiki.

By default the Arch Linux `root` account password is empty. We need to set up a
password for `root` account, which is needed for an SSH connection.

```bash
passwd
```

Now we need to change the setting to permit `root` login via SSH in
`/etc/ssh/sshd_config`. Check that `PermitRootLogin yes` is uncommented in this
file. If this line is not present there, add this to the end. Now start the
`sshd.service` by issuing the command

```bash
sudo systemctl start sshd.service
```

Also, note the IP address of the target machine by inspecting the output of the
following command.

```bash
ip addr
```

_Pro tip:_ One liner to get only the IP address

```bash
ip -o -4 addr show | awk -F '[ /]+' '/global/ {print $4}'
```

Now on your host machine, connect to the target machine via SSH using the
following command

```bash
ssh root@ip-address-of-target
```

## 2. Partition the disks

If Windows 8 or above is already installed on your machine, then your hard disk
is probably using `GPT` partitioning scheme. In that case, use `gdisk` to
partition your hard disk. ~~If you use `fdisk` on a GPT partitioned HDD, there
is a possibility of data loss.~~ `fdisk` understands `GPT` partitioning scheme
also.[1]

My preferred setup is to have one root partition and one home partition and use
`EFI` partition created by Windows to install boot-loader. The root and home
partition will be formatted using `ext4` file-system and the `EFI` partition
should be formatted using `FAT32` file-system.

For this guide, I am assuming that the `EFI` partition is `sda1`, root partition
is `sda9` and home partition is `sda10`.

Now to format the partitions with `ext4` file-system:

```bash
mkfs.ext4 /dev/sda9
mkfs.ext4 /dev/sda10
```

## 3. Mount the partitions

Now mount the root partition (`sda9` in this case) to `/mnt`

```bash
mount /dev/sda9 /mnt
```

If you have created any other partitions in previous steps, mount them at
appropriate locations.

```bash
mkdir /mnt/home
mount /dev/sda10 /mnt/home

mkdir /mnt/boot
mount /dev/sda1 /mnt/boot
```

## 4. Install the base file-system

To install the base system and some development tools, issue the following
command.

```bash
pacstrap /mnt base base-devel
```

This will take a while to download and install. After it finishes, it will give
you a bare-bone Arch Linux system with just the tools required to run a Linux
distribution, no other software is installed.

## 5. Generate /etc/fstab

The `/etc/fstab` file stores the information about file systems of partitions
and how to mount the partitions on system boot up. To generate this file, issue
the following command:

```bash
genfstab -U /mnt >> /mnt/etc/fstab
```

If you prefer to use partition labels (sda1, sda9 etc.) instead of UUID, then
use `-L` flag in place of `-U`.

## 6. chroot into the system

From the [Arch wiki](https://wiki.archlinux.org/index.php/Change_root):

> Chroot is an operation that changes the apparent root directory for the
> current running process and their children. A program that is run in such a
> modified environment cannot access files and commands outside that
> environmental directory tree. This modified environment is called a chroot
> jail.

At this step, we will go to the root of the newly installed system at `/mnt` and
pretend as if we are logged into this system.

```bash
arch-chroot /mnt
```

## 7. Setup the time zone, locale, and hostname

Browse the `/use/share/zoneinfo` directory to find your location entries. My
location is India, so I will use this command.

```bash
ln -sf /usr/share/zoneinfo/Asia/Kolkata /etc/localtime
```

To set the hardware clock:

```bash
hwclock --systohc
```

To set the locale for your system, open the `/etc/locale.gen` file and uncomment
your language. or run the following command for the default `en_US.UTF-8 UTF-8`.

```bash
LANG=C perl -i -pe 's/#(en_US.UTF)/$1/' /etc/locale.gen
```

Now generate the localization with

```bash
locale-gen
```

Then set the `LANG` variable in `/etc/locale.conf` accordingly, or run the
following command:

```bash
localectl set-locale LANG="en_US.UTF-8"
```

To set the hostname for your machine:

```bash
hostnamectl set-hostname your-host-name
```

To allow other machines to address the host by name, it is necessary to edit the
`/etc/hosts` file to look like this:

```bash
127.0.0.1    localhost.localdomain          localhost
::1          localhost.localdomain          localhost
127.0.1.1    your-host-name.localdomain     your-host-name
```

## 8. Create user account

Before creating user account, set password for `root` account

```bash
passwd
```

Now create a local account for your user

```bash
useradd -m -G wheel -s /bin/bash your-user-name
```

This will set up your user account, create a home directory for your user, set
the default shell to `bash` and add your user to `wheel` group, which is
necessary to gain `sudo` access in later steps.

Set password for your user.

```bash
passwd your-user-name
```

## 9. Enable sudo access

This allows you to use root privileges without using the root account. To enable
this, first open `/etc/sudoers` file

```bash
nano /etc/sudoers
```

Now uncomment the following line to enable `root` privilege for all the users
inside `wheel` group:

```bash
# %wheel ALL=(ALL) ALL
```

Now you can safely disable root account

```bash
passwd -l root

# login into your user account
su your-user-name
```

From this point onwards, it is necessary to append `sudo` to any command that
requires `root` privileges.

## 10. Install bootloader

My preferred bootloader of choice is `grub`. To install `grub`, we need to
install following packages.

```bash
sudo pacman -S grub efibootmgr
```

Now install `grub` with the following command.

```bash
sudo grub-install --target=x86_64-efi --efi-directory=/boot --bootloader-id=arch
```

Here `--efi-directory` is the folder where the `EFI` partition is mounted
[step 3](#step3) and `--bootloader-id` is the label that will appear in your
UEFI boot menu entry.

This particular step is specific to my machine's hardware, you might not need to
run this step. I need to add `pci=nommconf` to my kernel boot parameters in
`/etc/default/grub`, otherwise `tty` prints error messages continuously.

Now run to generate grub configuration file.

```bash
sudo grub-mkconfig -o /boot/grub/grub.cfg
```

If you encounter any errors related to `lvm` during installation of grub, then
follow these steps.

```bash
# come out of chroot
exit
mkdir /mnt/hostrun
mount --bind /run /mnt/hostrun

# back to chroot
arch-chroot /mnt
mkdir /run/lvm
mount --bind /hostrun/lvm /run/lvm
```

Now you can install `grub` without any errors.

## 11. Configure the network

By default, your current system cannot connect to the network in the current
state. I prefer to use
[NetworkManager](https://wiki.archlinux.org/index.php/NetworkManager) for my
network management, even when I am not using GNOME. For wireless networking,
install the following additional packages.

```bash
sudo pacman -S iw wpa_supplicant dialog networkmanager network-manager-applet dhclient
```

`NetworkManager` supports basic DHCP configuration. For full support, I have
installed `dhclient`. `NetworkManager` also supports automatic wired connection
detection and comes with curses based tool `nmtui` to setup wireless connection.

To enable NetworkManager to start at system startup

```bash
sudo systemctl enable NetworkManager.service
```

## 12. Reboot now

If you had performed the `lvm` troubleshooting steps during `grub` install, then

```bash
umount /run/lvm
```

Now exit from `chroot` by typing `exit` in the shell. Unmount all the mounted
partitions with:

```bash
umount -R /mnt
```

Finally, reboot your machine by typing `reboot` and remove the installation USB
drive. If you are not able to boot into your system at this point, boot from the
installation media again and attempt to fix the installation.

If you can see a terminal with a prompt for your username, congratulations! You
have completed the first step towards building your own system.

I will be writing about making your system usable and stable in the
[second](/blog/arch-linux-installation-part-2/) part of this guide.

Hope you enjoyed the post. Stay tuned :)
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[My Own Configuration Manager]]></title>
        <id>https://v2.yashagarwal.in/blog/my-own-configuration-manager</id>
        <link href="https://v2.yashagarwal.in/blog/my-own-configuration-manager"/>
        <updated>2018-01-21T05:53:23.000Z</updated>
        <content type="html"><![CDATA[
I have been using Linux since I was in my second year of undergraduate. My
experiments with the dotfiles (configuration files) also started at the same
time. For the uninformed, in Linux, it is common to configure a lot of settings
and configurations within dotfiles. Dotfiles are files in a Linux user's home
directory that begin with a dot or a full-stop character. This dot indicates to
the operating system that these files are used to store the settings of programs
like `vim` or shells like `bash` or `fish` to name a few.

In the beginning, I was keeping a manual backup of my dotfiles by copying them
to a folder from time to time. But the list soon started getting huge, that it
became complicated for me to keep track of the changes. Then I moved to
symlinks. I started symlinking all the dotfiles from my folder to their usual
locations. This setup worked perfectly fine, but as my collection of dotfiles
grew, It became very cumbersome for me to symlink every dotfile manually.

I also tried a few tools built for this particular purpose. Some of them are
`vcsh`, `mr`, and `stow`. These tools work just fine, but I was not willing to
learn new tools just for maintaining my dotfiles. At last, I decided to write my
tool to solve this problem. This way, there will not be any external dependency,
and this tool will also become part of my dotfiles.

## Design

The tool, in itself, is inspired by the
[UNIX tradition](https://en.wikipedia.org/wiki/Configuration_file#UNIX/Linux) of
keeping configuration files for the settings of the programs. This configuration
system uses a JSON formatted dotfile.

[Here](https://github.com/yashhere/ConMan) is the source code for the
configuration system. Let's have a look at the file structure of the repository.

```sh
|-- .backups
|   |-- 08-01-2018-15:47
|   |-- 08-01-2018-19:30
|   |-- ......
|-- configure.py
|-- current_status
|-- dotfiles
|   |-- dunst
|   |-- gtk-3.0
|   |-- i3
|   |-- ......
|-- dotfiles.json
|-- LICENSE
`-- README.md
```

During the initial setup, you need to edit the `dotfiles.json` file to suit your
setup. A relevant section of the JSON file is given below.

```json
{
  "pre": [
    {
      "name": "cloning repository",
      "command": "git",
      "subcommand": "clone",
      "argument": "https://github.com/yashhere/dotfiles.git"
    }
  ],
  "linking": [
    {
      "name": "bashrc",
      "src": "dotfiles/.bashrc",
      "dest": ".bashrc"
    },
    {
      "name": "bash_profile",
      "src": "dotfiles/.bash_profile",
      "dest": ".bash_profile"
    },
    {
      "name": "profile",
      "src": "dotfiles/.profile",
      "dest": ".profile"
    },
    {
      "name": "i3",
      "src": "dotfiles/i3",
      "dest": ".config/i3"
    }
  ]
}
```

As can be seen, the JSON file has an array variable `linking`, which can be used
to set the paths for each configuration file and folder. The `configure.py`
script also requires a `dotfiles` folder to be present in the current directory.
The folder can be created manually, or if it is already version controlled on
GitHub, then the script can clone it. For that, you can edit the `pre` section
in the `dotfiles.json`.

Your dotfiles and config folders go inside the `dotfiles` folder. You need to
copy all your current configurations to this folder to get started.

So, how does the script know where a file or folder will be linked? Simple, you
need to edit the `dotfiles.json` file and add source and destination locations.
For example, if you want to set up configurations of `i3` to its original
location (which is, `$HOME/.config/i3`), then you need to create a new JSON
object in the `linking` array, like this.

```json
{
  "name": "i3",
  "src": "dotfiles/i3",
  "dest": ".config/i3"
}
```

Here the `name` is used to identify the configuration file, the `src` parameter
is the location of your config file/folder in the dotfiles directory, and the
`dest` parameter is the final destination of the file/folder. Keen observers
would notice that I have not used `$HOME` anywhere. It is understood that the
configuration will go to the current user's home directory. So the `dest` is
relative to the user's home directory, and `src` is relative to the directory
from which the `configure.py` script is executed.

And you are done! Now, run `configure.py`, and all your dotfiles and folders
will be symlinked to their correct place.

The `current_status` file saves all the symlink locations that are being managed
by the script, for your easy reference and to debug any error.

## Behind the Scenes

A lot to cool things happen behind the scenes. The script will check if any
previous symlink exists at the given `dest` location. It removes any symlinks to
avoid redundancy. If the dest already has any dotfile or folder, then it backs
it up in the `.backups` under today's date and time before replacing it with a
symlink to avoid any potential data loss.

I hope the article was useful. Cheers :smile:
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[2017 - The Best Till Now]]></title>
        <id>https://v2.yashagarwal.in/blog/2017-the-best-till-now</id>
        <link href="https://v2.yashagarwal.in/blog/2017-the-best-till-now"/>
        <updated>2017-12-31T17:49:00.000Z</updated>
        <content type="html"><![CDATA[
If I have to define 2017 in one word, that would be amazing. This year has been
a life-changing year for me. I learned a lot of new things, had some excellent
experience in the company of amazing people, had a great time in my academic
life and SSL. 2017 has been a very significant year for me, and I want to record
this memory by documenting some of the most amazing things that I learned and
experienced this year.

## Grades

Although I cared very little for grades for the most of my college life, this
year changed my perception of grades. I finally understood that the grades are
also equally important. I started _2017_ with only one goal --- getting good
grades. I studied a lot in the first half of the year, and it is because of that
time, I hold an excellent command over Computer Networks. If I have to choose
any one semester for my placement, It would be 6th semester.

I invested most of my time for preparation of campus placements in the mid of
the year. Reading Data Structures and Algorithms have proven to be very
beneficial for me. However, the way I studied Data Structures, hasn't improved
my skills in real-world problem-solving skills.

I did not do exceptionally well in academics in the late half of the year.
Partly because of the _after placement_ and _"Dude, it is fourth year"_ type of
environment around me. My final year project did not go in the right direction,
and it is one of the very few disappointments for me in _2017_.

## Coding

It is one thing which I could never excel in my undergrad life. People say that
coding is a skill and it requires practice. However, to continue doing that
practice, one needs patience, that, unfortunately, I lack. This year continued
to be the same as 2016. I could not overcome my fear of coding. I tried doing
something different in the form of
[#100daysofcode](https://twitter.com/_100DaysOfCode), but couldn't continue it
after 20 days because of my preparations for campus placements. I have again
started writing code on a regular basis in late December. Looking forward to
code more frequently in 2018.

Recently I started working on Debian Packaging.
[Praveen](https://qa.debian.org/developer.php?login=praveen%40debian.org) sir
has always been very supportive of me and answered all my ludicrous questions
very patiently. My conversation with him about free software philosophy has been
very enlightening. Debian Packaging was a very satisfying experience to be able
to give something back to the community. Now, I hold
[one](https://qa.debian.org/developer.php?login=yashagarwaljpr@gmail.com)
package in the unstable Debian repository and
[two](https://qa.debian.org/developer.php?login=bansaly26@gmail.com) more
packages in the pipeline for approval.

![Working on my first Debian package](/images/posts/HackFest1.jpg "Working on my first Debian package")

![Praveen sir and team](/images/posts/HackFest2.jpg "Praveen sir and team")

## Placement

I joined NIT Calicut due to many
[reasons](https://dsanghi.blogspot.com/2011/05/my-2011-list-of-recommended-csit.html).
Placements were undoubtedly one of the most important of them. Fortunately, I
was among first few students to get placed in my batch. That moment came with a
great relief in my life.

![A private post on FB, now public](/images/posts/placement.png "A private post on FB, now public")

## Reading

I had started this year with an aim to read ten books and keep track of my
reading on [Goodreads](https://www.goodreads.com/user_challenges/8390620). In
the end, I could not finish my goal. I did occasionally try to meet my goal, but
my excessive reliance on soft copies of the books always distracted me. Now, it
is not a surprise that I am unable to read anything on a screen. I got three
hard copy books and finished two of them. However, I could not go past more than
20 pages of any digital book, that I bought on Kindle.

## Writing

I have not written for the most of the year. I do think about writing
occasionally and keep a note of all the ideas that I get. However, due to my
busy schedule and my usual procrastination, I do not write that often. In 2018,
I will try to write more often.

## Health

It is one issue where I do not put enough stress. I can divide my year into two
parts for this portion. Pre Birthday half and post Birthday half. I maintained a
daily exercise routine for the first half of the year. That helped me in many
ways. I felt more energetic, more productive and more resolute to troubles in
life. I slept at ten each day and woke up early morning. It resulted in
excellent health, which I had always lacked.

However, the second half of the year was disastrous. Due to weather and other
unavoidable circumstances, I could not keep up my routine; once I came back to
college. I started sleeping late again, and that resulted in me going to docter
very often in the last two months.

## Relations

I continued to feel bored in the company of people. It is somewhat strange that
after getting into college, year by year, my interest in public events has
decreased gradually. It may be because of the difference in my understanding of
happiness and that of others.

I built good relations with some faculties in the
[department](http://cse.nitc.ac.in/), my technical skills got me some admirers,
who eventually became my _friends_. I made some new friends from MCA also this
year. It has been a pleasant experience overall.

**_Looking forward to 2018 for, full of new experiences!_**
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Setting Up SSH Agent in i3]]></title>
        <id>https://v2.yashagarwal.in/blog/setting-up-ssh-agent-in-i3</id>
        <link href="https://v2.yashagarwal.in/blog/setting-up-ssh-agent-in-i3"/>
        <updated>2017-12-27T14:51:09.000Z</updated>
        <content type="html"><![CDATA[
In this post, I will write about the procedure to correctly setup SSH and GPG
agents in the i3 window manager. To follow this post, you need to have ssh-keys
and your private GPG keys ready. If you do not already have these keys with you,
I will describe the process of creating the keys.

## SSH

Generating an SSH key pair provides you with a public key and a private key. The
private key should never be given to anyone and public key, well the name itself
is self-explanatory.

To create a new key pair, open a terminal and paste the text below.

```sh
ssh-keygen -t rsa -b 4096 -C "your_email_address"
```

This command will create a new ssh key pair with the given email address as the
label. Press Enter for any question asked. When it asks for the passphrase, type
a strong passphrase, otherwise leave it blank to have no password.

## GPG

You might need to download the GPG command line tools before following the below
steps. Follow your distribution's documentation for more help.

Once you have downloaded the tools, open a terminal, and type the following
command.

```sh
gpg --gen-key
```

You will see something like this. Enter 1 to select the default key choice.

```text
gpg (GnuPG) 1.4.20; Copyright (C) 2015 Free Software Foundation, Inc.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

gpg: directory `/home/yash/.gnupg' created
gpg: new configuration file `/home/yash/.gnupg/gpg.conf' created
gpg: WARNING: options in `/home/yash/.gnupg/gpg.conf' are not yet active during this run
gpg: keyring `/home/yash/.gnupg/secring.gpg' created
gpg: keyring `/home/yash/.gnupg/pubring.gpg' created
Please select what kind of key you want:
   (1) RSA and RSA (default)
   (2) DSA and Elgamal
   (3) DSA (sign only)
   (4) RSA (sign only)
Your selection?
```

At the next prompt, enter the key size. It is recommended to use the maximum key
size of 4096 bits.

Enter the time duration for which the key should remain valid. Press Enter to
specify the default selection, indicating that the key does not expire.

After verifying the information, enter your user information and a strong
passphrase. Afterward, GPG will start generating your key. You will see:

```text
We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse,
utilize the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy.
```

You can now use the key (until it expires) to encrypt your data.

## Setting up SSH Agent

### Configuring i3

**Update (26/05/2018):** _As pointed out by
[Saksham](https://sakshamsharma.com/) in the comments below, this step is not
required for the setup of SSH in i3. This step can be safely ignored._

Open i3 configuration file and add an `exec_always` statement -

```sh
exec_always ~/.config/i3/scripts/gnome-keyring.sh
```

Obviously, you will need to change the path according to your OS. Now make a new
file in `~/.config/i3/scripts` with name `gnome-keyring.sh` and paste the below
text in it.

```sh
eval $(/usr/bin/gnome-keyring-daemon --start --components=gpg,pkcs11,secrets,ssh)
export GNOME_KEYRING_CONTROL GNOME_KEYRING_PID GPG_AGENT_INFO SSH_AUTH_SOCK
```

(Assuming that you already have installed gnome-keyring)

Now, reload the i3.

### Configuring SSH

**Update (26/05/2018):** _This step is also optional. Thanks to
[Saksham](https://sakshamsharma.com/) for pointing it out._

Open `~/.ssh/config` file and add following content to it -

```sh
Host *
  AddKeysToAgent yes
  IdentityFile /home/<your username>/.ssh/id_rsa
```

Replace \<your username\> accordingly.

### Setting up .bashrc

I am not using a login shell, and I could not find any suitable method to source
`~/.profile` or `~/.bash_profile` on login in i3. So I added my configuration to
`~/.bashrc` file. I know it is a hack, but it works well for me without much
headache.

Open `~/.bashrc` file and add following lines to the end of the file.

```bash
if [ -f ~/.ssh/agent.env ] ; then
    . ~/.ssh/agent.env > /dev/null
    if ! kill -0 $SSH_AGENT_PID > /dev/null 2>&1; then
        echo "Stale agent file found. Spawning a new agent. "
        eval `ssh-agent | tee ~/.ssh/agent.env`
        ssh-add
    fi
else
    echo "Starting ssh-agent"
    eval `ssh-agent | tee ~/.ssh/agent.env`
    ssh-add
fi
```

It will automatically start an `ssh-agent` if it is not already running.
Otherwise, it attaches to a previously running agent.

Now log out and log in again to see if ssh-agent works. Open a terminal and run
the command `ssh-add -l`. It will show you the hash value of your ssh-key, which
is loaded by the ssh-agent.

That is all for today. Thank you for reading!
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Setting up ALM Octane with Docker Compose]]></title>
        <id>https://v2.yashagarwal.in/blog/setting-up-alm-octane-with-docker-compose</id>
        <link href="https://v2.yashagarwal.in/blog/setting-up-alm-octane-with-docker-compose"/>
        <updated>2017-12-26T15:23:35.000Z</updated>
        <content type="html"><![CDATA[
Recently, I got a chance to set up ALM Octane on one of my university servers
for a course project. From the support page of ALM Octane:

> ALM Octane is a web-based application lifecycle management platform that
> enables teams to collaborate easily, manage the product delivery pipeline, and
> visualize the impact of changes.

## Precursor

My [department](http://cse.nitc.ac.in/) insists on using open-source software (a
plus point, indeed!). But ALM Octane has Oracle DB/MSSQL as a dependency. My
professor was not very enthusiastic about installing a proprietary database on
the server. So I came up with a different approach. I set up this database
([free version](https://www.oracle.com/database/technologies/appdev/xe.html) of
Oracle DB, the Oracle Database 11g Express Edition) in a Docker container. ALM
Octane has three components -- Oracle DB, Elastic Search, and the Octane Server
itself. The problem was to handle the condition that these three components
should be installed on different machines. I decided to use three separate
Docker containers for this isolation and then configured them to communicate
with each other with docker-compose.

### Wait ... Docker Compose?

(Skip this if already know about Docker and Compose)

> Docker-compose is a tool to define and run multi-container Docker
> applications. Compose uses a compose file to configure the services used by
> the applications. Then all the services and the application can be run by
> using a single command.

So before reading this article any further, if you do not know about
docker-compose, go and read about it.

## The Problem

Three primary services are required for the proper functioning of the Octane
Server -- Octane, Oracle DB and Elastic Search. The difficulty was to set up
adequate configuration options for these services and the appropriate setup for
communication between them. I searched on Docker Hub for any pre-built images.
Fortunately, I found some pre-built Docker images for my purpose. So I started
writing my config file.

## The Solution

Here is my config file for easy reference.

```yaml
version: "2"
services:
  octane_oracle:
    image: alexeiled/docker-oracle-xe-11g
    shm_size: 2g
    mem_limit: 4g
  octane_es:
    image: elasticsearch:2.4
    environment:
      - ES_HEAP_SIZE=4G
    mem_limit: 4g
  octane:
    image: hpsoftware/almoctane
    ports:
      - "8080:8080"
    volumes:
      - /opt/octane/conf:/opt/octane/conf
      - /opt/octane/log:/opt/octane/log
      - /opt/octane/repo:/opt/octane/repo
    links:
      - octane_oracle
      - octane_es
    mem_limit: 4g
    env_file:
      - ./octane.env
```

The configuration options in the code are for a system with RAM of 8GB. The
options must be tuned for the best performance before deploying on the
production server.

In the code, I have exposed port `8080` of the Octane Docker container to the
port 8080 of the host machine. It will make sure that we can access the Octane
application on `localhost:8080`. The `octane.env` file contains three variables
for easy site management.

```sh
SERVER_DOMAIN="your domain name"
ADMIN_PASSWORD="your password"
#This disables the minimum memory check to enable to run on smaller machines.
DISABLE_VALIDATOR_MEMORY=true
```

Now, if you try to run the container with `docker-compose up`, you will
encounter various validation errors. It is because, before starting the server,
you need to adjust some settings. If you noticed in the config file, there is a
section to define volumes. These volumes are persistent and are used to keep
changes saved between two docker-compose runs. I have mapped three volumes from
the Docker container to the host machine. So you can now edit the files in the
`/opt/octane/` folder on the host machine, and changes will reflect in the
Docker container. The file where you will have to make changes is
`/opt/octane/conf/setup.xml`.

You can read the documentation of ALM Octane to find out which settings to be
changed. Once you do the necessary changes, fire up the command
`docker-compose up` and wait for some time. Docker Compose will finish
processing, and the server can be accessed on
[http://localhost:8080](http://localhost:8080) on the host machine. While
deploying it on the production server, make sure that your network administrator
has opened the port 8080 for your server. Otherwise, the site will not be
accessible. Also, the docker-compose can be run in the background by issuing
command `docker-compose up -d`.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fixing Hindi Fonts in Arch Linux]]></title>
        <id>https://v2.yashagarwal.in/blog/fixing-hindi-fonts-in-arch-linux</id>
        <link href="https://v2.yashagarwal.in/blog/fixing-hindi-fonts-in-arch-linux"/>
        <updated>2017-10-17T16:25:53.000Z</updated>
        <content type="html"><![CDATA[
When viewing Hindi content in any browser in Arch Linux, the rendering looks
weird.

![before applying the fix](/images/posts/hindi_font_before.png "before applying the fix")

It doesn't look good, right! I'll try to fix this issue in this post. You might
need to install the appropriate
[font support](https://wiki.archlinux.org/index.php/fonts) in Arch Linux before
applying this fix. The suitable package for installing Indic Language support is
`ttf-indic-otf`.

Now go to `/usr/share/fonts/TTF` and take the backup of two fonts `FreeSans.ttf`
and `FreeSerif.ttf`. Now delete these two fonts from the directory. Restart the
browser and see the difference.

![after applying the fix](/images/posts/hindi_font_after.png "after applying the fix")

This bug is reported in
[this](https://bugs.launchpad.net/ubuntu/+source/chromium-browser/+bug/856736)
bug report in 2011. I don't know why nobody has fixed it yet. Or maybe I was not
able to find the proper solution. This workaround is also given in the same bug
report.

I hope this helps. :)
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mounting NTFS partitions on Arch Linux]]></title>
        <id>https://v2.yashagarwal.in/blog/mounting-ntfs-partitions-on-arch-linux</id>
        <link href="https://v2.yashagarwal.in/blog/mounting-ntfs-partitions-on-arch-linux"/>
        <updated>2017-03-14T10:30:36.000Z</updated>
        <content type="html"><![CDATA[
Yesterday I installed Arch Linux once again. A clean, bloat-free desktop with
Budgie Desktop environment with some must-have open source tools. Everything
worked fine except WiFi and some minor bugs in Budgie(I don't know whether it is
a bug in Budgie or just a wrong setting). I also faced the problem of mounting
Windows NTFS volumes on the user's wish. Arch Linux wiki has details about how
to automount partitions on start-up. Still, I had a tough time to find out what
exactly needs to be done to simulate the behavior of Ubuntu-like distribution on
the mounting of NTFS drives. I got a hint from Arch Linux Wiki about the Polkit
configuration setting, which can be used to allow a standard user to mount
partitions. Here is a solution that I found after a long search on various Arch
Linux Community pages.

You will need to install `ntfs-3g`, `polkit` and `udisks2` to use this code.
Please refer to [Arch Wiki](https://wiki.archlinux.org/index.php/Udisks).

I think when using Gentoo, you will also need to compile the support for the
NTFS file system in Kernel also. Please see
[here](https://wiki.gentoo.org/wiki/NTFS).

Add the following code to `/etc/polkit-1/rules.d/10-udisks2.rules` -

```vim
// Allow udisks2 to mount devices without authentication for users in the "wheel" group.
polkit.addRule(function(action, subject) {
    if ((action.id:= "org.freedesktop.udisks2.filesystem-mount-system" ||
        action.id:= "org.freedesktop.udisks2.filesystem-mount") &&
        subject.isInGroup("wheel")) {
            return polkit.Result.YES;
        }
    }
);

polkit.addRule(function(action, subject) {
   if ((action.id:= "org.freedesktop.udisks.filesystem-mount-system-internal") &&
        subject.isInGroup("wheel")) {
            return polkit.Result.YES;
        }
    }
);
```

Now you will be able to mount NTFS partition without any problem. :)
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[FOSSMeet'17]]></title>
        <id>https://v2.yashagarwal.in/blog/fossmeet-17</id>
        <link href="https://v2.yashagarwal.in/blog/fossmeet-17"/>
        <updated>2017-03-13T21:03:16.000Z</updated>
        <content type="html"><![CDATA[
One more edition of FOSSMeet'17 was successfully organized in NIT Calicut
recently. As an active member of the organizing team of this year's edition
(though I sidelined myself at the end) and a keen but silent observer, I want to
share my experience, ideas, and some observations through this post.

## Marketing Website

We started planning the next edition of FOSSMeet sometime around September. Not
many people were interested in planning. Anyway, Shrimadhav and I began working
on the marketing website. The first design was straightaway rejected by Piyush
and Simsar, which I feel, was fruitful. In the process, I learned some critical
insights about planning, team management, and design of a user-friendly website.
So I again started working on the site. The end product was clean, good looking,
and simple (at least I was happy with it :P).

In the meanwhile, Amal and I started thinking about ideas, how can we
restructure the FOSSCell, which had not seen a single activity (except those
trademark events which were conducted just for formality) in years. I now
understand that it was a mistake. It is a prerequisite about open source
contribution that you should contribute to the products which you use in day to
day life. When we started thinking about the FOSSCell, we didn't know about any
of these points. We conducted a formal test(more of a filtering process), then
we had a small meeting with the selected 2nd years about the FOSSCell, and we
discussed the plan for next semester. Then everyone left for winter vacations.

## A period of self-evaluation

In the winter holidays, we tried to have some IRC discussions, which again was
somewhat successful because of the efforts from Shrimadhav and Simsar. It was a
new experience for me also, but still, I tried to attend as much as I could. I
also took one session on Git and Vim, which again was an entirely new experience
for me.

In the winter vacation, I found some time to think about the purpose of FOSSMeet
and FOSSCell and in what direction we were heading. I somehow understood that I
was not qualified enough to guide someone about open source contribution or in
general FOSS ideology, because I, myself was not contributing anything to open
source community, and had no characteristic of a FOSS enthusiast. So I somehow
lost my interest in FOSSCell and even in Linux. Shrimadhav asked me my ideas
about FOSSCell activities, but I had no clue what to say. So that's how the
FOSSCell again died without achieving anything significant. I feel it was my
mistake. I still feel sad about this. :(

## FOSSMeet time

So as the FOSSMeet's dates came near, people started coming for _volunteering_.
It was good for the event, though. The funnel was already up last semester, and
we were getting some good proposals also. FOSSMeet also went superbly. All the
participants gave excellent reviews. There were some hiccups also, The Campus
Internet Connectivity being the most significant one. There were some issues in
SSL also, again, somewhere I hold an important responsibility. All in all,
everybody praised the event and organization of the event. This year, we tried
to reduce the use of plastics, and I feel that we were quite successful.

## My Observations

There were some issues about the event, which I didn't like at a personal level.
I sometimes think about what is the motive for conducting some activities in
colleges. An event like FOSSMeet which attract the attention of all FOSS
enthusiasts from all over Kerala has a huge potential of inspiring the young
folks of NIT Calicut. We somehow succeed in that motive, but what about the
situation after FOSSMeet. The enthusiasm about FOSS should not last just for two
days, but we cannot blame others for the condition. I don't have a proper idea
about the FOSS because there was no proper guidance from my senior batches. I
learned many things in the workshops organized by CSEA, in fact, I first learned
the proper use of Linux Shell in the Linux workshop conducted by CSEA (and
FOSSCell, at least for formality). But you can't ask them to do everything. I
think they are already overloaded. But there were no such workshops by FOSSCell.

Second, the curriculum of the NITC CSE department focuses more on the
theoretical side of Computer Science, which is good. But it negatively affects
student activities outside the classroom. That is one of the primary reasons why
we cannot produce more GSoC participants or why don't we have more open source
enthusiasts.

Third, one of the speakers in FOSSMeet mentioned one fundamental flaw in the
structure of the organizing team of FOSSMeet. It doesn't have any representation
from other branches. FOSSMeet has become an event for CSE folks, where people
from different departments do not take any interest. I think publicity was a
major issue here. I don't believe that there was any publicity done to explain
FOSSMeet to the students of other branches. (If I am wrong here, please correct
me).

Fourth, people are ready to _volunteer_ for organizing an event, but they do not
want to come and attend the workshops. FOSSMeet is held by individuals who have
no previous experience of FOSS and have no intention to dive into open source
community any time soon. FOSSMeet has become a tradition that is continued every
year because it happened the previous year also. I do not feel that enthusiasm
to promote FOSS in FOSSMeet because we are organizing it to keep the legacy. I
am not saying that whatever effort organizers put in conducting FOSSMeet'17 was
not significant. I am not the right person to blame them because I was also part
of the same team. But still, I feel that FOSSMeet has lost its original motive
to promote FOSS culture in NITC. It encourages more people from outside NITC,
but inside NITC, it is just one of those many events organized by random clubs.

## Conclusion

It's been an interesting one year for me after becoming SS Lab Admin because I
started taking part in department activities that I always wanted to do. Being a
member of the organizing team of FOSSMeet'17 was again a learning experience for
me. I learned many new things, in SSL and outside SSL too. I committed some
mistakes also in making the right decisions at the right moment, but that's how
I learn. So no regrets. :) I hope that I will find time next year for FOSSMeet,
although I would prefer to attend FOSSMeet as a participant observing everything
silently rather than being a part of the organizing team.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Setting up Hugo automatic deployment to Github with Wercker]]></title>
        <id>https://v2.yashagarwal.in/blog/setting-up-hugo-automatic-deployment-to-github-with-wercker</id>
        <link href="https://v2.yashagarwal.in/blog/setting-up-hugo-automatic-deployment-to-github-with-wercker"/>
        <updated>2017-02-22T08:07:56.000Z</updated>
        <content type="html"><![CDATA[
Recently, I again migrated my blog from Pelican to Hugo. So till now, I have
experimented with Wordpress, Jekyll, Pelican, and Hugo. Without any doubt, Hugo
is the simplest to set up. This time, I have setup Hugo in Windows, as I think,
in my system, I reinstall Windows OS much less frequently than the Linux. So
that way, it will be less painful for me to set up the blog again.

In this post, I will list all the process which I used to set up automatic
deployment of Hugo generated site to Github pages using Wercker. In the
beginning, I was trying to use Travis-CI, but then I read about Wercker
somewhere. I was impressed with the integration of Wercker with Hugo and the
availability of many its community-generated “steps” for the build and deploy
process.

[Hugo Docs](https://gohugo.io/getting-started/) already have a fantastic
[documentation](https://gohugo.io/hosting-and-deployment/deployment-with-wercker/)
for setting up Hugo with Wercker, but it is outdated. Other documentations
available on-line is also obsolete. Wercker has changed many functionalities in
its platform, which made it difficult for me to set up things correctly. But
after hours of trial and error cycle, I was able to build and deploy my static
files successfully.

Here I would like to share the issues I encountered and the tweaks I’ve made.
The source codes of this site can be found
[here](https://github.com/yashhere/yashhere.github.io).

## Project Pages or User Pages

Two types of sites are supported on Github Pages, User Site, and Project Site.
User Sites will serve the files stored in the master branch of the repository
`https://github.com/user_name/user_name.github.io` at the address
`https://user_name.github.io.` For the Project sites, everything under the
gh-pages will be served at the address `https://repo_name.github.io`.

My site is a User site, so I wanted all the static files to be saved in the
master branch. As Hugo generates all the static files under `public` directory,
I needed another branch to store my source files. So my made a new branch
`source`, which will save all the source files for my blog. Don’t forget to
remove the `.git` folder from the theme folder. Otherwise, the build will fail
at a later stage. You can try using the git submodule feature to avoid this
issue. I created a repository `yash2696.github.io` in Github also.

```sh
git init                       #initialized git repository in site root
git checkout -b source         #created new branch source
git remote add origin [https://github.com/yash2696/yash2696.github.io](https://github.com/yashhere/yashhere.github.io)
git add .
git commit -m "Initial Commit"
git push origin source
```

Then I initialized my master branch as a orphan branch.

```sh
git checkout --orphan master
git rm -rf .
rm -f '.gitignore'
echo "#Your repository name" > README.md
git add README.md
git commit -a -m "Initial Commit"
git push origin master
```

## Automatic deployment using Wrecker

It is straightforward to build a Hugo site. Invoke `hugo` command under your
root directory, Hugo will create a public folder which will contain all your
content, static files, etc. Then push this directory to Github, and voila, your
site is up!

What if a single push to `source` branch can trigger all the process for you
automatically. Here the magic of continuous integration(CI) comes into the
picture. A free Wercker account can be easily created and hooked to the Github
account and a new application from a chosen repository. After setting up
everything, a push to the development branch will automatically trigger the
Wercker. One of the most significant advantages of using Wercker is its
extensive collection of user-made and well documented "steps". In this post, I
will use two steps, `build hugo` and `deploy to Github`.

![Wercker → Registry → steps](/images/posts/wercker-steps.png "Wercker → Registry → steps")

The first task is to create a `wercker.yml` file. It will tell Wercker which all
actions, it should perform. Here is my
[wercker.yml](https://raw.githubusercontent.com/yash2696/yash2696.github.io/source/wercker.yml)
for reference. In this, I have used two pipelines, _build_ and _deploy_. Please
follow the official docs for the more detailed steps. I will list all the
problems which I face while setting up things properly.

### Build

Following the official guide, I used this
[step](https://github.com/ArjenSchwarz/wercker-step-hugo-build) to trigger Hugo
to build HTML pages. I had already removed git repository information from the
theme folder, so this step finished successfully. If you haven’t, you may add
the following piece of code in your build step.

```yml
- script:
    name: install git
    code: |
        apt-get update
        apt-get install git -y
    - script:
        name: initialize git submodules
        code: |
            git submodule update --init --recursive
```

### Deploy

There is no concept named "Add Deploy Target" in Wercker as of now. Most of the
on-line tutorials follow this process which is outdated. Now Wercker uses a
concept called "Workflows in Pipelines".

For new interface, even if you add a deploy stage in the `wercker.yml`, you will
have to create a new pipeline `deploy` under the Workflows tab. After creating
the pipeline, the "YML Pipeline name" must be set to the deploy stage name,
which in this case is `deploy`.

In `deploy` stage, I used this
[step](https://app.wercker.com/applications/55af22c5f32b86a9290ec706/tab/details/)(broken
link) to deploy the built site to Github. Each pipeline starts from scratch, so
for the deploy pipeline, the git package needs to be installed again. One also
has to set up the environment variable `$GIT_TOKEN` to each pipeline, acquired
from Github setting.

![Wercker Pipeline](/images/posts/wercker-pipeline.png "Wercker Pipeline")

You need to generate a new access token for your deploy stage from Github
settings.
![Github Access Token](/images/posts/wercker-access-token.png "Github Access Token")

After adding the deploy stage, add the token you obtained from the Github to
Environmental Variables in deploy pipeline.

![Wercker Token](/images/posts/wercker-token.png "Wercker Token")

On the next push to your development branch, Wercker will automatically build
the site and deploy it on Github Pages.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Setting up Python Development Environments]]></title>
        <id>https://v2.yashagarwal.in/blog/setting-up-python-development-environments</id>
        <link href="https://v2.yashagarwal.in/blog/setting-up-python-development-environments"/>
        <updated>2016-10-09T00:00:00.000Z</updated>
        <content type="html"><![CDATA[
Recently I was searching for Python projects on Github for contribution. Every
single project I found, had a thing common among them. In every project's
contribution guide, it was asked to set up the virtual environment for the
project. What the heck is this virtual environment and how does it work?

As a beginner to open source projects, the problem I faced, in the beginning,
was how to set up the development environments for the projects I was looking
at. I searched the Internet, I found some articles, but they were not complete.
So I decided to write this guide, which will be useful for me in future also.

Python uses `pip` for package management.

## Installing pip

`pip` depends on setuptools library, which is in official Ubuntu repositories.
To install it for python2 -

```sh
sudo apt-get install python-setuptools
```

Then install `pip` using -

```sh
sudo apt-get install python-pip
```

and for python3 -

```sh
sudo apt-get install python3-setuptools
```

Then install `pip` using -

```sh
sudo apt-get install python3-pip
```

It should install `pip` on your system for both python versions. `pip` is very
easy to use. It will take care of every single package you may require for your
project.

### Installing a package using pip

```sh
# it will search and install [package]
pip install [package]
pip install django
```

If you are using python3, then don't forget to use `pip3`.

`pip` can be used to install a specific version of package also.

```sh
# it will search and install [package] with [version]
pip install [package]==[version]
pip install django==1.6.5
```

### Uninstalling a package using pip

```sh
# it will search and uninstall [package]
pip uninstall [package]
pip uninstall django
```

### upgrading a package using pip

```sh
# it will upgrade [package] to latest version
pip install --upgrade [package]
pip install --upgrade django
```

### Creating list of all packages with pip

It is one of most used and most useful feature of `pip`. It allows you to make a
list of all the dependencies of your project.

```sh
# it will output the file to current directory
pip freeze > [file_name.txt]
```

All these commands above will install the packages globally. But that's not what
is desired. `virtualenv` comes to our rescue here.

## Virtualenv

`virtualenv` solves a very particular problem; it allows multiple python
projects that have different and often conflicting dependencies, to coexist on
the same system.

`virtualenv` solves this problem by creating different isolated development
environments for your projects. An environment is a folder which contains
everything; your project needs to work properly.

### Installing virtualenv

By default, if you install `virtualenv` using `pip`, it will use system's
default python to create virtual environments. To overcome this problem, we will
install `virtualenv` using ubuntu package manager.

```sh
sudo apt-get install python-virtualenv
```

### Installing virtualenvwrapper

`virtualenvwrapper` provides some set of commands which makes working with
virtual environments much easier.

To install it -

```sh
sudo pip install virtualenvwrapper
```

`pip`, `virtualenv` and `virtualenvwrapper` are the only packages which you will
need to install globally. All other per project packages will be installed in
respective virtual environments.

`virtualenvwrapper` also places all your virtual environments in one place. It
makes working with projects very easy.

Now open your `.bashrc` and add these two lines to the end -

```sh
# All your projects will be saved in python-dev folder
export PROJECT_HOME=~/python-dev

# ~/python-dev/virtualenvs will contains python interpreters for each project.
export WORKON_HOME=~/python-dev/virtualenvs

# source the virtualenvwrapper script
source /usr/local/bin/virtualenvwrapper.sh
```

You can change `python-dev` to any name you wish. Your virtual environments will
be created at that location.

Now restart your terminal to source the `.bashrc` or use -

```sh
source .bashrc
```

### Basic Usage

Create a virtual environment -

```sh
mkvirtualenv myproject
```

It will create `myproject` folder in the python-dev directory. To activate this
project -

```sh
workon myproject
```

Alternatively you can create project using `mkproject` command. It will create a
virtual environment as well as a project directory in the `$PROJECT_HOME`, which
is `cd`-ed into when you `workon` myproject.

Don't forget to deactivate current project when you switch between different
projects.

To deactivate a project -

```sh
deactivate
```

To delete a virtual environment -

```sh
rmvirtualenv myproject
```

List all environments -

```sh
lsvirtualenv
```

it will also list all virtual environments -

```sh
workon
```

Please refer to virtualenvwrapper documentation for
[full list of virtualenvwrapper commands](https://virtualenvwrapper.readthedocs.io/en/latest/command_ref.html).

virtualenvwrapper also provides the tab-completion feature which is very handy
when you have a lot of projects to work with.

That's it. Hope you liked the post. :smile:
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Custom Arch Linux setup with Openbox]]></title>
        <id>https://v2.yashagarwal.in/blog/custom-arch-linux-setup-with-openbox</id>
        <link href="https://v2.yashagarwal.in/blog/custom-arch-linux-setup-with-openbox"/>
        <updated>2016-06-09T10:20:36.000Z</updated>
        <content type="html"><![CDATA[
After my summer vacation started, I bought a new laptop, and the first thing I
did was to install Arch Linux on it. After a standard arch installation
procedure, I started putting together my desktop environment, beginning with
ArchLinux and Openbox, and then piecing all pieces together to build a proper
desktop environment. Building a desktop this way follows the Unix Methodology;
have software that each does one thing well, and when you put them together, you
get something amazing.

When I first installed Arch, I had several choices. I tried `xfce` and `gnome`
as my desktop environments. While both of them have their pros and cons, I ended
up liking none. The sole reason was the dependencies; these two software bring
with them. My only intention of installing Arch was to have something, which I
control, not like Ubuntu, where you are forced to use the preinstalled software
and when you try to uninstall something, you fear of breaking some other
program.

So I end up going the route of building something up from scratch using Openbox
as a base. At this point, I have a fast, lightweight desktop that is
exceptionally stable and is genuinely my desktop as I have built it from the
ground up, choosing every application.

![Openbox on ArchLinux](/images/posts/openbox_desktop.jpg "Openbox on ArchLinux")

## Window Manager

After the installation of Arch, the first thing I did was to install `openbox`,
a tiling window manager. You may also try other window managers like `awesome`,
`i3`, and `fluxbox`, etc. but I chose Openbox because it is used everywhere.
Thus there is a plethora of information out there about customizing it.

For our window manager to show up, it needs to be added either in a login
manager or user's `~/.xinitrx` file. There is a default version of this file
that contain some code which we may want to retain, so rather than making this
file from scratch, copy the default version of the file to the user's home
directory.

```sh
cp /etc/X11/xinit/xinitrc ~/.xinitrc
```

Now add the command `exec Openbox-session` to the end of the file. Remember that
the system will ignore the lines following this command. An Openbox session
should be able to be started by entering the command `startx`.

An openbox session can be started automatically upon login using shell's startup
script. Add following to the shell's startup script, `~/.bash_profile` for bash
and `~/.zprofile` for zsh.

```sh
[[ -z $DISPLAY && $XDG_VTNR -eq 1 ]] && exec startx
```

## Configuring Openbox

Setting up openbox is quite simple. Four files make the basis of openbox
configuration. They are `rc.xml`, `autostart`, `menu.xml` and `environment`.
These files controls everything about the window manager.

- **rc.xml**: Determine the behavior and settings of overall Openbox session
- **autostart**: Contains a list of applications to be launched with the window
  manager
- **menu.xml**: It makes the right-click context menu of the desktop
- **environment**: Can be used to export and set relevant environmental
  variables

For the configuration of Openbox, it is necessary to create a local Openbox
profile in the user's home directory. A global configuration file can be found
in `/etc/xdg/openbox`, which is well documented, and copying the global
configuration to the user's directory will give a good starting point to start
customizing.

```sh
cp -R /etc/xdg/openbox ~/.config/
```

These files can be edited by hand, although some graphical tools are also
available, use of these may be desired.

## Themes and Appearance

`obconf` and `lxappearance-obconf` can be used to configure appearance and theme
of openbox session. There are quite a few themes available in `openbox-themes`
package. My personal favorite is `Numix-themes` and
`Numix-icon-theme-git (AUR)`.

To see changes after editing a configuration file, the Openbox needs to be
refreshed. It can be done with the `reconfigure` command.

```sh
openbox --reconfigure
```

## Menus

The type and behavior of Openbox menus, accessible by right-clicking the
background, can be changed using `~/.config/openbox/menu.xml` file. Openbox
provides two kinds of menus, `Static`, and `Dynamic` menus (Piped and
Generators)

Static menus are hardcoded in XML and is stored in the `menu.xml` file. Whenever
you install a new application, you will have to update the XML file to update
the menu manually. It is a viable solution if the apps are not installed on a
day to day basis.

Pipe menus are the sections of the Openbox menu that Openbox creates on the fly
by running a generic script and using its plain text output as menu entries.
This scheme can be used in different ways, like adding a mail checker in the
menu or adding a weather forecast menu. You can check
[openbox pipe menu page](http://openbox.org/wiki/Openbox:Pipemenus) for more
information.

Generators are the most convenient type of menus. These can be found in most
desktop environments where applications show up in the menu automatically. If
applications are being installed regularly, then this will probably be the
preferred choice.

### Static Menus

The process of making these menus can be automated by static menu generator like
`obmenu`. It will generate static menus from installed applications by looking
into certain directories. Others available tools are `menumaker`, `obmenu` and
`xdg-menu`.

### Dynamic Menus

Dynamic menus give the same kind of functionality most people are used to. So it
was my preferred choice. They can be used to generate full, complex menus on the
fly. One of the most popular application for generating dynamic menus is
`obmenu-generator`. Though it is not officially connected to Openbox, it is
widely used.

In order to have `obmenu-generator` make a menu on demand, the `menu.xml` file
should contain the following code as the only entry.

```sh
<?xml version="1.0" encoding="UTF-8"?>
<openbox_menu>
    <menu id="root-menu" label="OpenBox 3" execute="/usr/bin/obmenu-generator"></menu>
</openbox_menu>
```

## Panels and Taskbars

You can get any panel like `xfce4-panel` or the simple and customizable `tint2`.
I chose tint2 because it very closely follows the openbox spirit of having easy
customization with plain configuration files. tint2 package also containg a
graphical tool `tint2conf` for customizing panel and you can obviously go right
to the tint2 configuration file and edit it there. This also means it is easy to
pick up your configuration file and move it to another computer, or restore an
old configuration since it is as simple as pasting a text document in the right
place. tint2 can also have sections for each individual desktop and has various
small widget like programs that can be used with it such as a calendar,
`gsimplecal`, a volume application, `volumeicon`, a battery indicator,
`cbatticon`, a network indicator like `wicd` which also have a system tray icon
and a mini task tray. To start tint2 with openbox, you need to add `tint2 &` to
the `autostart` file.

## File Manager

Some file managers deeply integrate into desktop environments, and when
installed with Openbox, they end up pulling multiple dependencies, which is
certainly not desired. Our aim behind building an Openbox set up was to have
minimum dependencies so that we can get a lightweight desktop. However, there
are several file managers available that fit into the Openbox very well. In my
choice, `pcmanfm` is the best choice here. pcmanfm is a lightweight and fast
file manager with network and thrash support. pcmanfm can also manage desktop
icons and wallpaper setting, although if you plan to use conky in your system,
then you may not want pcmanfm to manage desktop for you. The reason is that
pcmanfm treats desktop as a window, so when you switch to desktop, the conky
hides behind the desktop window. To get the icons and wallpaper, you can use
other standalone tools such as `idesk` and `feh` or `nitrogen`. To start pcmanfm
is the desktop mode, add the following to the autostart file.

```sh
pcmanfm --desktop &
```

and to stop it for managing desktop

```sh
pcmanfm --desktop-off &
```

Many functions present in modern file managers require the installation of a few
additional programs. `gvfs` gives you the ability to mount volumes and have
trash control. It is not mandatory to have, but it allows on-demand `mounting`
completely from within the file manager, as opposed to having to drop down to
the command line. A disk-volume manager such as `udisks2` will also be wanted,
and for auto-mounting removable disks, `udiskie` works well with Openbox.
udiskie can be added to Openbox's autostart file like any other application.

## Composition

Openbox does not provide native support for composition, although having a
compositor may prevent screen flickering and other distortion in applications
like `oblogout`. Some options work great with Openbox. The one which I am using
and quite happy with is `compton`. It can be used with or without any initial
configuration, although there are a lot of different configuration options if
you decide to customize the setup. To start compton in background with shadows,
use this in `autostart` file.

```sh
compton -b -c &
```

## Wrapping up

While setting up my desktop using Openbox ended up being much more work than I
could have with typical desktop environments. But now I have a much more stable
desktop, about which I know, what is running in my system, and that my system is
not cluttered with any software that I never use.

While it might not be for everybody having to configure every little bit of the
desktop, I genuinely feel I have ended up with excellent user experience, and a
system that is customized precisely to fit my needs.

## References

- [Arch Linux Wiki](https://wiki.archlinux.org/)
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[A good Sublime Text setup]]></title>
        <id>https://v2.yashagarwal.in/blog/a-good-sublime-text-setup</id>
        <link href="https://v2.yashagarwal.in/blog/a-good-sublime-text-setup"/>
        <updated>2016-04-14T10:55:35.000Z</updated>
        <content type="html"><![CDATA[
So, after a hectic day, good news finally came. I have been selected as a Lab
Administrator for the [Software Systems Lab](https://www.facebook.com/sslnitc/)
of my college. Cheers!!!

Let's come to our today's topic on configuring Sublime Text Settings.

There is just one rule you must follow while designing your own editor
preference configuration.

> Don't put any lines in your configuration that you don't understand.

You will find tons of online tutorials that contains all kinds of awesome hacks
to make your sublime text experience better but the worst way to make your
development environment better is just to borrow the configuration from someone
else.

Spending your time in actually understand what is happening behind the scenes in
the construction of your editor is immensely invaluable. It is similar to the
increased information retention that you experience when you copy something from
the board.

So first, take some background of what we are going to do today. I am using
Sublime Text 3 -- dev version, but most of the instructions are similar for
Sublime Text 2 also.

Okay, first open the sublime text, then go to `Preference → Settings → User`.

So this is your configuration file where you can put all your custom
preferences. There are other configuration files also, which can be found in
Preferences.

You can also find all settings for reference in `Settings → Default` file.

Here is my `Settings → User` file. Feel free to take insiparation from it, and
make your sublime text experience unmatchable. I have commented every setting
which is self-understandable.

{/* TODO: {{< gist yashhere dea6728f88865666c20ff1c35e90bd0e >}} */}

## Wrapping It Up

I still stand by my platitude that

> Don't put anything in your configuration file you don't understand!

That's all for today. Thanks for reading.
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Searching the goal]]></title>
        <id>https://v2.yashagarwal.in/blog/searching-the-goal</id>
        <link href="https://v2.yashagarwal.in/blog/searching-the-goal"/>
        <updated>2016-04-10T00:33:16.000Z</updated>
        <content type="html"><![CDATA[
A boy, probably of age 16, just cleared his 10th board exam. He saw people
working on computers, and that fascinated him. So he had only one ambition. You
got it, right? One fine day, suddenly his friend's mother asked, "So what about
the future? You are going to enter in class 11th. It is the right time to decide
about your future. What do you want to become, a doctor or an engineer?" The boy
had no clue how big that question was. What the cost would have been. He simply
nodded and said, "I like computers very much so I would go for engineering."

That's it. He decided his fate.

So here comes the day

## An accident

After that day, he got into a coaching institute which promised a good rank in
JEE. He was told that he would have to study consistently and regularly. The
boy, being a determined one, started studying day and night.

This continued for two years. Finally, after giving 12th board exams, he gave
JEE. Unfortunately, he didn't even get into extended merit list.

Devastated, he pledged not to give up. Oh, that stupid silly guy! He decided to
try for one more year.

He joined another institute in his city. Again the same routine, studying day
and night to fulfill _his_ dreams.

_Result_: Same, Fail!

But somehow he got a decent rank in JEE Mains thanks to his excellent
performance in board exams.

## A disaster

Now he had to face one more question. Which college and which branch? For him,
the answer was simple. Go to any South Indian college thanks to the influence of
his cousins on him (who were very successful in their lives, of course!). He
chose Computer Science and Engineering because

- He loved computers.
- Everybody said, "Bahut scope hai is branch me."
- Every top ranker of this country choose this branch.

So the decision was clear. He packed his bag and left home for a NIT situated
some 2200 kms far, the comp-sci branch.

## The coding disaster

He reached the college. He loved new people, new place, new environment,
everything was new, right!. Studies started. He got good grades initially until
the real coding and Computer Science related stuff started as courses. His
grades fell drastically, his morale too. He got good marks enough to pass the
courses. He tried giving his best, but all concepts seemed so alien to him as
they wouldn't stay inside his head.

That guy is now about to complete his 2nd year and just thinking what went wrong
with him. He is still trying to keep his journey on the right track. Whether he
will be able to finish it successfully or not, only time will tell.

At last one more year is coming, and it's story will also come here next year.

[Inspired by this Quora Post](https://www.quora.com/What-were-you-once-that-youll-never-be-again/answer/Nishant-Kumar-187?srid=8MaF&share=8df79cac)
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
    <entry>
        <title type="html"><![CDATA[Wanna get insulted by sudo]]></title>
        <id>https://v2.yashagarwal.in/blog/wanna-get-insulted-by-sudo</id>
        <link href="https://v2.yashagarwal.in/blog/wanna-get-insulted-by-sudo"/>
        <updated>2016-04-03T12:20:36.000Z</updated>
        <content type="html"><![CDATA[
You might have tried many Linux easters eggs for fun, but you are going to love
this hack which makes `sudo` insult you.

Confused what I am talking about? Here, take a look at this gif to get an idea
of how `sudo` can insult you for typing in the incorrect password.

![A terminal screen](/images/posts/insult.gif)

Now you might be thinking, why would anyone want to take insult? Afterall,
nobody likes being insulted. For me, it is just another way to have fun with
Linux, and anyway, this is way better than the plain "You entered a wrong
password" error message. So let's learn how to do this.

## Enable insults in sudo

You can enable the insults feature in `sudo` by modifying the `sudo`
configuration file. To open the `sudo` configuration file, launch a terminal and
type the following command.

```sh
sudo visudo
```

It will open `/etc/sudoers` configuration file in the terminal, in vim text
editor if you have configured it as your default editor. In distros like Ubuntu,
it will be opened in nano. Now you will have to find the section where the
defaults are listed. Most probably you will find it at the top. Now find the
line that starts with `Defaults` and append the word `insults` to the end of the
line (any addition to the line is comma separated). If this line is not present
then add the following line to the section

```vim
Defaults insults
```

(Always use `visudo` as it has a self-check system which will save you from
messing up things)

Now save the file. If you are using vim, then use `Ctrl+X` to save the file and
quit the editor and if you are using nano then use `Ctrl+X` to leave the editor.
At the time of quitting, it will ask you if you want to save the changes. To
keep the changes, press `Y`.

![Sample sudoers file](/images/posts/sudoers.png "Sample sudoers file")

Once you have saved the file, go to terminal and type the following command to
clear the old password from `sudo`'s cache.

```sh
sudo -k
```

That's all. Use any command with `sudo`. Deliberately type a wrong password and
enjoy abusing ...
]]></content>
        <author>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </author>
        <contributor>
            <name>Yash Agarwal</name>
            <email>yashagarwaljpr+blog@gmail.com</email>
            <uri>https://v2.yashagarwal.in</uri>
        </contributor>
    </entry>
</feed>